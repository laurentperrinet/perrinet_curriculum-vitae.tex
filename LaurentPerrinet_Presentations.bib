@comment{%% This BibTeX bibliography file was created using BibDesk.
%% http://bibdesk.sourceforge.net/


%% Created for Laurent Perrinet at 2019-03-04 23:05:12 +0100


%% Saved with string encoding Unicode (UTF-8)}

@comment{%% This BibTeX bibliography file was created using BibDesk. %% http://bibdesk.sourceforge.net/   %% Created for Laurent Perrinet at 2019-02-25 23:36:16 +0100    %% Saved with string encoding Unicode (UTF-8)}

@inproceedings{2006-01-01_neurocomp,
    abstract = {The quality of the representation of an object's motion is limited
by the noise in the sensory input as well as by an intrinsic ambiguity
due to the spatial limi- tation of the visual motion analyzers (aperture
prob- lem). Perceptual and oculomotor data demonstrate that motion
processing of extended ob jects is initially dominated by the local
1D motion cues orthogonal to the ob ject's edges, whereas 2D information
takes pro- gressively over and leads to the final correct represen-
tation of global motion. A Bayesian framework ac- counting for the
sensory noise and general expectancies for ob ject velocities has
proven successful in explaining several experimental findings concerning
early motion processing [1, 2, 3]. However, a complete functional
model, encompassing the dynamical evolution of ob- ject motion perception
is still lacking. Here we outline several experimental observations
concerning human smooth pursuit of moving ob jects and more particu-
larly the time course of its initiation phase. In addi- tion, we
propose a recursive extension of the Bayesian model, motivated and
constrained by our oculomotor data, to describe the dynamical integration
of 1D and 2D motion information.},
    author = {Perrinet, Laurent U and Barthélemy, Frédéric V. and Masson, Guillaume S},
    bdsk-url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2006_neurocomp},
    booktitle = {1ère conférence francophone NEUROsciences COMPutationnelles - NeuroComp},
    date-modified = {2019-02-25 09:53:36 +0100},
    keywords = { Aperture problem,Bayesian model,Object motion,recursive inference,Smooth pursuit eye movement,Temporal evolution.},
    note = {## from . Follows [[Publications/Perrinet06fens]] . See also [[Publications/Perrinet07neurocomp]] and [[Publications/Perrinet08areadne]]},
    rating = {5},
    title = {Input-output transformation in the visuo-oculomotor loop: modeling the ocular following response to center-surround stimulation in a probabilistic framework},
    topic = {edge},
    url = {http://invibe.net/LaurentPerrinet/Presentations/2006_neurocomp},
    year = {2006}
}

@inproceedings{2007-09-01_mipm,
    abstract = {I will illustrate in this talk how computational neuroscience may inspire and be inspired by mathematical image processing. Focusing on efficiently representing natural images in the primary visual cortex, we derive an event-based adaptive algorithm inspired by statistical inference, Matching Pursuit and Hebbian learning. This algorithm allows to learn efficient "edge-like" receptive fields similarly to Independent Components Analysis. The correlation-based inhibition has been shown to be a necessary condition for the fomation of this type of receptive fields and shows the putative functional role of lateral propagation of information in cortical layers. I'll first present state-of-the-art neural algorithms for this task, the results of a detailed analysis of this Sparse Hebbian Learning algorithm and finally draw a comparison with similar strategies.},
    author = {Perrinet, Laurent U},
    bdsk-url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2007-09_mipm},
    booktitle = {Mathematical image processing meeting (Marseille, France) September 5},
    date-added = {2007-10-29 16:22:21 +0100},
    date-modified = {2019-02-25 09:53:02 +0100},
    note = {* [[http://www.math.univ-paris13.fr/~malgouy/MIPM/Abstracts.html#Perrinet|advertisement]]},
    title = {Neural Codes for Adaptive Sparse Representations of Natural Images},
    url = {http://invibe.net/LaurentPerrinet/Presentations/2007-09_mipm},
    year = {2007}
}

@inproceedings{2007-12-01_rankprize,
    author = {Perrinet, Laurent U},
    bdsk-url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2007-12_rankprize},
    booktitle = {The Rank Prize Funds, Mini-Symposium on Representations of the Visual World in the Brain},
    date-modified = {2019-02-25 09:53:02 +0100},
    note = {* see SparseHebbianLearning * watch the [[attachment:perrinet07rankprize.pdf|presentation]]},
    title = {What efficient code for adaptive spiking representations?},
    url = {http://invibe.net/LaurentPerrinet/Presentations/2007-12_rankprize},
    year = {2007}
}

@inproceedings{2008-02-01_toledo,
    author = {Perrinet, Laurent U},
    bdsk-url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2008-02_toledo},
    booktitle = {Prisma workshop, Toledo (Spain), February 7, 2008},
    date-modified = {2019-02-25 09:53:02 +0100},
    note = {* see [[Publications/Perrinet08spie]] * get the [[attachment:perrinet08toledo.pdf|presentation (8.8 Mo)]]},
    title = {Modeling of spikes, sparseness and adaptation in the primary visual cortex: applications to imaging},
    url = {http://invibe.net/LaurentPerrinet/Presentations/2008-02_toledo},
    year = {2008}
}

@inproceedings{2008-04-01_incm,
    abstract = {Computational Neuroscience is a synthetic, inter-disciplinary approach aiming at
understanding cognition by analyzing the mechanisms underlying neural computations. We
present in this seminar our attempt in modeling low-level vision by bridging different
integration levels, from neural spiking activity to behavior. At the behavioral level, the Ocular
Following Response recorded in the laboratory reveals how the brain may integrate local
information (moving images on visual receptive fields) to produce a single behavioral
response (the movement of the eye). Using a probabilistic representation, we provide a
simple integrative mechanism that gives the ''ideal'' response to possibly noisy and
ambiguous information, similarly to a Bayesian approach. This fits well the performance
revealed by behavioral data and may act as a generic cortical ''module''. At the population
level, these mechanisms may indeed be implemented for the coding of natural images and
we will show the particular importance of spiking representations and lateral interactions for
efficient and rapid responses. In particular, we will present an original unsupervised learning
algorithm that we applied to a model of the primary visual cortex. Finally, at the neuronal
level, I will present work done in the team showing how certain mechanisms at the level of
the synapse and of the neuron are essential at the population level and how we may
understand these mechanisms at the population level. This illustrates the importance of
dynamical processes, distributed activity and recurrent connections to produce a cortical gain
control mechanism. As a conclusion, this approach provides useful applications for image
processing and possible valorization in future computer architectures. More generally, it
proves that the use of a probabilistic representation is a particularly efficient method for
bridging biological versus computational neuroscience and illustrates the advantage of such
an interdisciplinary approach.},
    author = {Perrinet, Laurent U},
    bdsk-url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2008-04_incm},
    booktitle = {Séminaires de l'INCM, April 11th, 2008},
    date-modified = {2019-02-25 23:30:49 +0100},
    projects = {facets},
    title = {From neural activity to behavior: computational neuroscience as a synthetic approach for understanding the neural code.},
    url = {http://invibe.net/LaurentPerrinet/Presentations/2008-04_incm},
    year = {2008}
}

@inproceedings{2008-06-01_Ulm,
    abstract = {The machinery behind the visual perception of motion and the subsequent
sensorimotor transformation, such as in Ocular Following Response (OFR),
is confronted to uncertainties which are efficiently resolved in the
primate's visual system. We may understand this response as an ideal
observer in a probabilistic framework by using Bayesian theory (Weiss et
al., 2002) which we previously proved to be successfully adapted to
model the OFR for different levels of noise with full field gratings or
with disk of various sizes and the effect of a flickering surround
(Perrinet and Masson, 2007).
More recent experiments of OFR have used disk gratings and bipartite
stimuli which are optimized to study the dynamics of center-surround
integration. We quantified two main characteristics of the global
spatial integration of motion from an intermediate map of possible local
translation velocities: (i) a finite optimal stimulus size for driving
OFR, surrounded by an antagonistic modulation and (ii) a direction
selective suppressive effect of the surround on the contrast gain
control of the central stimuli (Barthelemy et al., 2006, 2007).
Herein, we extended in the dynamical domain the ideal observer model to
simulate the spatial integration of the different local motion cues
within a probabilistic representation. We present analytical results
which show that the hypothesis of independence of local measures can
describe the initial segment of spatial integration of motion signal.
Within this framework, we successfully accounted for the dynamical
contrast gain control mechanisms observed in the behavioral data for
center-surround stimuli. However, another inhibitory mechanism had to be
added to account for suppressive effects of the surround. We explore
here an hypothesis where this could be understood as the effect of a
recurrent integration of information in the velocity map.

F. Barthelemy, L. U. Perrinet, E. Castet, and G. S. Masson. Dynamics of
distributed 1D and 2D motion representations for short-latency ocular
following. Vision Research, 48(4):501--22, feb 2007. doi:
10.1016/j.visres.2007.10.020.

F. V. Barthelemy, I. Vanzetta, and G. S. Masson. Behavioral receptive
field for ocular following in humans: Dynamics of spatial summation and
center-surround interactions. Journal of Neurophysiology,
(95):3712--26, Mar 2006. doi: 10.1152/jn.00112.2006.

L. U. Perrinet and G. S. Masson. Modeling spatial integration in the
ocular following response using a probabilistic framework. Journal of
Physiology (Paris), 2007. doi: 10.1016/j.jphysparis.2007.10.011.

Y. Weiss, E. P. Simoncelli, and E. H. Adelson. Motion illusions as
optimal percepts. Nature Neuroscience, 5(6):598--604, Jun 2002. doi:
10.1038/nn858.},
    author = {Perrinet, Laurent U and Masson, Guillaume S},
    bdsk-url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2008-06_Ulm},
    date-modified = {2019-02-25 23:30:49 +0100},
    note = {* see more : * on MotionPerception * in [[Publications/Perrinet08areadne]] * watch the [[attachment:perrinet08ulm.pdf|presentation]]},
    projects = {facets},
    title = {Decoding the population dynamics underlying ocular following response using a probabilistic framework},
    url = {http://invibe.net/LaurentPerrinet/Presentations/2008-06_Ulm},
    year = {2008}
}

@inproceedings{2009-04-01_INT,
    abstract = {
Moving the eyes rapidly to track a visual object moving in a cluttered environment is an essential
function. However, doing so rapidly and efficiently is constrained by a number of noise sources in the
visual system and by the fact that information is collected locally before giving raise to a global signal.
After reviewing some results made in the modeling of low-level sensory areas, I will expose a method
to decode low-level neural information as describing visual information using a probabilistic
representation. Decisions will therefore correspond to statistical inferences which are dynamically
resolving the veridical speed of a moving object. We will illustrate this method by showing how
ambiguous local information can be merged to give raise to a global response which resolves the
aperture problem. Using this theoretical approach "in computo", we will illustrate how we may better
understand results which are observed "in vivo" (optical imaging) as a neural code linking actively
sensation and behavior.},
    author = {Perrinet, Laurent U and Masson, Guillaume S},
    bdsk-url-1 = {http://invibe.net/LaurentPerrinet/Presentations/09-04_INT},
    date-modified = {2019-02-25 23:30:49 +0100},
    note = {* see more : * on MotionPerception * in [[Publications/Perrinet08areadne]] and [[Publications/Perrinet09cosyne]] * watch the [[attachment:perrinet09int.pdf|presentation|&do=get]] * LaTeX source code for the presentation: [[attachment:perrinet09int.tex||&do=get]], [[attachment:Context.tex||&do=get]], [[attachment:Motion.tex||&do=get]], [[attachment:Annex.tex||&do=get]] and glued by a [[attachment:Makefile||&do=get]]},
    projects = {facets},
    title = {Decoding low-level neural information to track visual motion},
    url = {http://invibe.net/LaurentPerrinet/Presentations/09-04_INT},
    year = {2009}
}

@inproceedings{2009-07-18_Kremkow09cnstalk,
    author = {Kremkow, Jens and Perrinet, Laurent U and Monier, Cyril and Fregnac, Yves and Masson, Guillaume S and Aertsen, Ad},
    bdsk-url-1 = {http://invibe.net/LaurentPerrinet/Publications/Kremkow09cnstalk},
    bdsk-url-2 = {https://doi.org/10.1186/1471-2202-10-S1-O21},
    booktitle = {Eighteenth Annual Computational Neuroscience Meeting: CNS*2009 Berlin, Germany. 18--23 July 2009},
    date-modified = {2019-02-25 23:30:49 +0100},
    doi = {doi:10.1186/1471-2202-10-S1-O21},
    note = {## from},
    pages = {Oral presentation, 10(Suppl 1):O21},
    projects = {facets},
    title = {Control of the temporal interplay between excitation and inhibition by the statistics of visual input},
    url = {http://invibe.net/LaurentPerrinet/Publications/Kremkow09cnstalk},
    year = {2009}
}

@inproceedings{2009-11-30_vss,
    abstract = {Short presentation of a large moving pattern elicits an ocular following response that exhibits many of the properties attributed to low-level motion processing such as spatial and temporal integration, contrast gain control and divisive interaction between competing motions. Similar mechanisms have been demonstrated in V1 cortical activity in response to center-surround gratings patterns measured with real-time optical imaging in awake monkeys (see poster of Reynaud et al., VSS09). Based on a previously developed Bayesian framework, we have developed an optimal statistical decoder of such an observed cortical population activity as recorded by optical imaging. This model aims at characterizing the statistical dependance between early neuronal activity and ocular responses and its performance was analyzed by comparing this neuronal read-out and the actual motor responses on a trial-by-trial basis. First, we show that relative performance of the behavioral contrast response function is similar to the best estimate obtained from the neural activity. In particular, we show that the latency of ocular response increases with low contrast conditions as well as with noisier instances of the behavioral task as decoded by the model. Then, we investigate the temporal dynamics of both neuronal and motor responses and show how motion information as represented by the model is integrated in space to improve population decoding over time. Lastly, we explore how a surrounding velocity non congruous with the central excitation information shunts the ocular response and how it is topographically represented in the cortical activity. Acknowledgement: European integrated project FACETS IST-15879.},
    author = {Perrinet, Laurent U and Reynaud, Alexandre and Chavane, Frédéric and Masson, Guillaume S},
    bdsk-url-1 = {http://invibe.net/LaurentPerrinet/Publications/Perrinet09vss},
    booktitle = {Macroscopic aspects of neuronal activity: ''Macroscopic models, LFP models and VSD models'' a FACETS workshop in Marseille, Nov. 30th /Dec. 1st},
    date-modified = {2019-02-25 23:30:49 +0100},
    note = {* see previous [[Publications/Perrinet09vss|poster]] <<EmbedObject(perrinet09vsd_talk.pdf,width=100%)>>},
    projects = {facets},
    title = {Reading out the dynamics of lateral interactions in the primary visual cortex from VSD data},
    url = {http://invibe.net/LaurentPerrinet/Publications/Perrinet09vss},
    year = {2009}
}

@inproceedings{2010-01-08_facets,
    author = {Perrinet, Laurent U and Masson, Guillaume S},
    bdsk-url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2010-01-08_facets},
    date-modified = {2019-02-25 09:53:36 +0100},
    keywords = { center-surround interactions,Bayesian model,dynamics,eye movements,motion detection,motion prediction},
    note = {* see this more recent [[Presentations/2012-01-12_VisionAtUcl|talk]] * see more : * on MotionPerception * on MotionParticles * watch the [[attachment:perrinet10facets_talk.pdf|presentation|&do=get]]},
    title = {Models of low-level vision: linking probabilistic models and neural masses},
    url = {http://invibe.net/LaurentPerrinet/Presentations/2010-01-08_facets},
    year = {2010}
}

@inproceedings{2010-12-17_TaucTalk,
    abstract = {Sensory informations such as visual images are inherently variable. We use probabilistic models to describe how the low-level visual system could describe superposed and ambiguous information. This allows to describe the interactions of neighboring populations of neurons as inference rules that dynamically build up the overall description of the visual scene. We focus here on temporal prediction, that is by the transport of information based on an estimate of local motion in the image.},
    author = {Perrinet, Laurent U},
    bdsk-url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2010-12-17_TaucTalk},
    booktitle = {LADISLAV TAUC & GDR MSPC NEUROSCIENCES CONFERENCE, From Mathematical Image Analysis to Neurogeometry of the Brain},
    date-modified = {2019-02-25 09:53:02 +0100},
    keywords = { center-surround interactions,Bayesian model,dynamics,eye movements,motion detection,motion prediction},
    note = {= * http://www.conftauc.cnrs-gif.fr/programme.php * watch the [[attachment:perrinet10tauc.pdf|presentation|&do=get]] (150 Mo with movies) * see the accompanying [[Publications/Khoei10tauc|poster]] * see this more recent [[Presentations/2012-01-12_VisionAtUcl|talk]] * see more : * on MotionPerception * on MotionParticles ||<width="50%"> attachment:sequence_DCBAline.gif||width=100%||<width="50%"> attachment:sequence_ABCDline.gif||width=100%|| |||| '''A predictive sequence is essential in resolving the aperture problem.''' ''(Top)'' In order to demonstrate that, I show in this sequence different apertures; for the aperture problem, motions are segregated (appear to be part of different objects) and still appear to be diagonal. ''(Right)'' However, if the same apertures are arranged in an order which is compatible with a predictive sequence, the horizontal motion appears as the most probable: prediction rotates the perception of the direction... ||},
    title = {Probabilistic models of the low-level visual system: the role of prediction in detecting motion},
    url = {http://invibe.net/LaurentPerrinet/Presentations/2010-12-17_TaucTalk},
    year = {2010}
}

@inproceedings{2011-07-02_NeuroMedTalk,
    abstract = {Sensory informations such as visual images are inherently variable. We use probabilistic models to describe how the low-level visual system could describe superposed and ambiguous information. This allows to describe the interactions of neighboring populations of neurons as inference rules that dynamically build up the overall description of the visual scene. We focus here on temporal prediction, that is by the transport of information based on an estimate of local motion in the image.},
    author = {Perrinet, Laurent U},
    bdsk-url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2011-07-02_NeuroMedTalk},
    booktitle = {Atelier Neurosciences Computationnelles, 2-3 Juillet 2011 Khemisset, Maroc},
    date-modified = {2019-02-25 09:53:02 +0100},
    keywords = { dynamics,Bayesian model,eye movements,motion detection,motion prediction},
    note = {= * La finalité de cette manifestation est de permettre à nos chercheurs de se réunir en groupes de travail et en ateliers afin de découvrir la thématique des neurosciences et son interdisciplinarité. La manifestation se tient dans le cadre des activités du laboratoire LAMS, de ABC MATHINFO, du GDRI NeurO et du réseau méditerranéen [[http://www.neuromedproject.eu/|NeuroMed]]. ## * une manifestation sponsorisée par le projet [[http://www.neuromedproject.eu/|NeuroMed]] * téléchargez la [[attachment:perrinet11khemisset.pdf|présentation|&do=get]] (150 Mo with movies) * ou un [[Publications/Khoei10tauc|poster]] * en savoir plus : * sur la [[MotionPerception| perception du mouvement]] * sur la [[MotionParticles| solution particulaire]] ##||<width="50%"> attachment:sequence_DCBAline.gif||width=30%|| ##||<width="50%"> attachment:sequence_ABCDline.gif||width=30%|| ##|||| '''A predictive sequence is essential in resolving the aperture problem.''' ''(Top)'' In order to demonstrate that, I show in this sequence different apertures; for the aperture problem, motions are segregated (appear to be part of different objects) and still appear to be diagonal. ''(Right)'' However, if the same apertures are arranged in an order which is compatible with a predictive sequence, the horizontal motion appears as the most probable: prediction rotates the perception of the direction... ||},
    title = {Propriétés émergentes d'un modèle de prédiction probabiliste utilisant un champ neural},
    url = {http://invibe.net/LaurentPerrinet/Presentations/2011-07-02_NeuroMedTalk},
    year = {2011}
}

@inproceedings{2011-09-28_ermites,
    abstract = {Oriented edges in images of natural scenes tend to be aligned in collinear or co-circular arrangements, with lines and smooth curves more common than other possible arrangements of edges (Geisler et al., Vis Res 41:711-24, 2001). The visual system appears to take advantage of this prior information, and human contour detection and grouping performance is well predicted by such an "association field" (Field et al., Vis Res 33:173-93, 1993). One possible candidate substrate for implementing an association field in mammals is the set of long-range lateral connections between neurons in the primary visual cortex (V1), which could act to facilitate detection of contours matching the association field, and/or inhibit detection of other contours (Choe and Miikkulainen, Biol Cyb 90:75-88, 2004). To fill this role, the lateral connections would need to be orientation specific and aligned along contours, and indeed such an arrangement has been found in tree shrew primary visual cortex (Bosking et al., J Neurosci 17:2112-27, 1997). However, it is not yet known whether these patterns develop as a result of visual experience, or are simply hard-wired to be appropriate for the statistics of natural scenes. To investigate this issue, we examined the properties of the visual environment of laboratory animals, to determine whether the observed connection patterns are more similar to the statistics of the rearing environment or of a natural habitat. Specifically, we analyzed the cooccurence statistics of edge elements in images of natural scenes, and compared them to corresponding statistics for images taken from within the rearing environment of the animals in the Bosking et al. (1997) study. We used a modified version of the algorithm from Geisler et al. (2001), with a more general edge extraction algorithm that uses sparse coding to avoid multiple responses to a single edge. Collinearity and co-circularity results for natural images replicated qualitatively the results from Geisler et al. (2001), confirming that prior information about continuations appeared consistently in natural images. However, we find that the largely man-made environment in which these animals were reared has a significantly higher probability of collinear edge elements. We thus predict that if the lateral connection patterns are due to visual experience, the patterns in wild-raised tree shrews would be very different from those measured by Bosking et al. (1997), with shorter-range correlations and less emphasis on collinear continuations. This prediction can be tested in future experiments on matching groups of animals reared in different environments.},
    author = {Perrinet, Laurent U and Fitzpatrick, David and Bednar, James A.},
    bdsk-url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2011-09-28_ermites},
    booktitle = {Proceedings of SfN, 2011},
    date-modified = {2019-02-25 23:17:47 +0100},
    event_url = {http://glotin.univ-tln.fr/ERMITES11/index.xhtml},
    keywords = {sparse coding},
    location = {Porquerolles la Perle des Iles d'Or - Var (France)},
    projects = {brain-scales},
    time_start = {2011-09-28T13:00:00},
    title = {Edge statistics in natural images versus laboratory animal environments: implications for understanding lateral connectivity in V1},
    url = {http://invibe.net/LaurentPerrinet/Presentations/2011-09-28_ermites},
    year = {2011}
}

@inproceedings{2011-10-05_BrainScalesESS,
    author = {Perrinet, Laurent U},
    bdsk-url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2011-10-05_BrainScalesESS},
    booktitle = {Using the ESS + Neuromorphic hardware Workshop},
    date-modified = {2019-02-25 23:17:47 +0100},
    event_url = {https://brainscales.kip.uni-heidelberg.de/jss/AttendMeeting?m=showAgenda&meetingID=15},
    keywords = {sparse coding},
    location = {TU Dresden, Germany},
    projects = {brain-scales},
    time_start = {2011-10-05T13:00:00},
    title = {Demo 1, Task4: Implementation of models showing emergence of cortical fields and maps},
    url = {http://invibe.net/LaurentPerrinet/Presentations/2011-10-05_BrainScalesESS},
    url_slides = {http://invibe.net/LaurentPerrinet/Presentations/2011-10-05_BrainScalesESS?action=AttachFile&do=get&target=perrinet11brainscales_talk.pdf},
    year = {2011}
}

@inproceedings{2011-11-15_sfn,
    abstract = {Oriented edges in images of natural scenes tend to be aligned in collinear or co-circular arrangements, with lines and smooth curves more common than other possible arrangements of edges (Geisler et al., Vis Res 41:711-24, 2001). The visual system appears to take advantage of this prior information, and human contour detection and grouping performance is well predicted by such an "association field" (Field et al., Vis Res 33:173-93, 1993). One possible candidate substrate for implementing an association field in mammals is the set of long-range lateral connections between neurons in the primary visual cortex (V1), which could act to facilitate detection of contours matching the association field, and/or inhibit detection of other contours (Choe and Miikkulainen, Biol Cyb 90:75-88, 2004). To fill this role, the lateral connections would need to be orientation specific and aligned along contours, and indeed such an arrangement has been found in tree shrew primary visual cortex (Bosking et al., J Neurosci 17:2112-27, 1997). However, it is not yet known whether these patterns develop as a result of visual experience, or are simply hard-wired to be appropriate for the statistics of natural scenes. To investigate this issue, we examined the properties of the visual environment of laboratory animals, to determine whether the observed connection patterns are more similar to the statistics of the rearing environment or of a natural habitat. Specifically, we analyzed the cooccurence statistics of edge elements in images of natural scenes, and compared them to corresponding statistics for images taken from within the rearing environment of the animals in the Bosking et al. (1997) study. We used a modified version of the algorithm from Geisler et al. (2001), with a more general edge extraction algorithm that uses sparse coding to avoid multiple responses to a single edge. Collinearity and co-circularity results for natural images replicated qualitatively the results from Geisler et al. (2001), confirming that prior information about continuations appeared consistently in natural images. However, we find that the largely man-made environment in which these animals were reared has a significantly higher probability of collinear edge elements. We thus predict that if the lateral connection patterns are due to visual experience, the patterns in wild-raised tree shrews would be very different from those measured by Bosking et al. (1997), with shorter-range correlations and less emphasis on collinear continuations. This prediction can be tested in future experiments on matching groups of animals reared in different environments.},
    author = {Perrinet, Laurent U and Fitzpatrick, David and Bednar, James A.},
    bdsk-url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2011-11-15_sfn},
    booktitle = {Society for Neuroscience Abstracts},
    date-modified = {2019-02-25 09:53:02 +0100},
    editor = {Society for Neuroscience, www.sfn.org},
    location = {Washington, DC},
    note = {Abstract Control Number: 17671 * Presentation Number: 530.04 * Presentation Time: 8:45am - 9:00am * session: * Session Type: Nanosymposium * Session Number: 530 * Session Title: Development of Motor and Sensory Systems},
    number = {Program No. 530.04},
    time_start = {2011-11-15T08:45:00},
    title = {Edge statistics in natural images versus laboratory animal environments: implications for understanding lateral connectivity in V1},
    url = {http://invibe.net/LaurentPerrinet/Presentations/2011-11-15_sfn},
    year = {2011}
}

@inproceedings{2012-01-12_VisionAtUcl,
    abstract = {In low-level sensory systems, it is still unclear how the noisy information collected locally by neurons may give rise to a coherent global percept. This is well demonstrated for the detection of motion in the aperture problem: as luminance of an elongated line is symmetrical along its axis, tangential velocity is ambiguous when measured locally. Here, we develop the hypothesis that motion-based predictive coding is sufficient to infer global motion. Our implementation is based on a context-dependent diffusion of a probabilistic representation of motion. We observe in simulations a progressive solution to the aperture problem similar to psychophysics and behavior. We demonstrate that this solution is the result of  two underlying mechanisms. First, we demonstrate the formation of a tracking behavior favoring temporally coherent features independently of their texture. Second, we observe that incoherent features are explained away while coherent information diffuses progressively to the global scale. Most previous models included ad-hoc mechanisms such as end-stopped cells or a selection layer to track specific luminance-based features. Here, we have proved that motion-based predictive coding, as it is  implemented in this functional model, is sufficient to solve the aperture problem. This simpler solution may give insights in the role of prediction underlying a large class of sensory computations.},
    author = {Perrinet, Laurent U},
    bdsk-url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2012-01-12_VisionAtUcl},
    booktitle = {Vision@UCL seminar},
    date-modified = {2019-02-25 23:17:47 +0100},
    keywords = { center-surround interactions,Bayesian model,dynamics,eye movements,motion detection,motion prediction},
    location = {Malet Place Eng Bldg 1.03 (first floor).},
    projects = {brain-scales},
    time_start = {2012-01-12T17:00:00},
    title = {Motion-based prediction is sufficient to solve the aperture problem},
    url = {http://invibe.net/LaurentPerrinet/Presentations/2012-01-12_VisionAtUcl},
    url_slides = {http://invibe.net/LaurentPerrinet/Presentations/2012-01-12_VisionAtUcl?action=AttachFile&do=get&target=perrinet12ucl_handout.pdf},
    year = {2012}
}

@inproceedings{2012-01-24_Edinburgh,
    abstract = {Oriented edges in images of natural scenes tend to be aligned in collinear or co-circular arrangements, with lines and smooth curves more common than other possible arrangements of edges (Geisler et al., Vis Res 41:711-24, 2001). The visual system appears to take advantage of this prior information, and human contour detection and grouping performance is well predicted by such an "association field" (Field et al., Vis Res 33:173-93, 1993). One possible candidate substrate for implementing an association field in mammals is the set of long-range lateral connections between neurons in the primary visual cortex (V1), which could act to facilitate detection of contours matching the association field, and/or inhibit detection of other contours (Choe and Miikkulainen, Biol Cyb 90:75-88, 2004). To fill this role, the lateral connections would need to be orientation specific and aligned along contours, and indeed such an arrangement has been found in tree shrew primary visual cortex (Bosking et al., J Neurosci 17:2112-27, 1997). However, it is not yet known whether these patterns develop as a result of visual experience, or are simply hard-wired to be appropriate for the statistics of natural scenes. To investigate this issue, we examined the properties of the visual environment of laboratory animals, to determine whether the observed connection patterns are more similar to the statistics of the rearing environment or of a natural habitat. Specifically, we analyzed the cooccurence statistics of edge elements in images of natural scenes, and compared them to corresponding statistics for images taken from within the rearing environment of the animals in the Bosking et al. (1997) study. We used a modified version of the algorithm from Geisler et al. (2001), with a more general edge extraction algorithm that uses sparse coding to avoid multiple responses to a single edge. Collinearity and co-circularity results for natural images replicated qualitatively the results from Geisler et al. (2001), confirming that prior information about continuations appeared consistently in natural images. However, we find that the largely man-made environment in which these animals were reared has a significantly higher probability of collinear edge elements. We thus predict that if the lateral connection patterns are due to visual experience, the patterns in wild-raised tree shrews would be very different from those measured by Bosking et al. (1997), with shorter-range correlations and less emphasis on collinear continuations. This prediction can be tested in future experiments on matching groups of animals reared in different environments.},
    author = {Perrinet, Laurent U and Fitzpatrick, David and Bednar, James A.},
    bdsk-url-1 = {http://invibe.net/cgi-bin/index.cgi/Presentations/2012-01-24_Edinburgh},
    booktitle = {A seminar from the Institute for Adaptive and Neural Computation (ANC)},
    date-modified = {2019-02-25 23:17:47 +0100},
    event_url = {http://www.anc.ed.ac.uk/events/anc-dtc-seminar-laurent-perrinet},
    location = {IF 4.31/4.33, Institute for Adaptive and Neural Computation (ANC) @ The University of Edinburgh},
    projects = {brain-scales},
    time_start = {2012-01-24T13:00:00},
    title = {Edge statistics in natural images versus laboratory animal environments: implications for understanding lateral connectivity in V1},
    url = {http://invibe.net/cgi-bin/index.cgi/Presentations/2012-01-24_Edinburgh},
    year = {2012}
}

@inproceedings{2012-01-27_FIL,
    abstract = {Moving objects generate sensory information that may be noisy and ambiguous, yet it is important to be able to reconstruct object speed as fast as possible. One unsolved question is to understand how the brain pools motion information to give an efficient response. I will present computational models of motion detection in the visual system that try to answer this question. First, sensory information is grabbed by pooling the information from different sensory neurons. This pooling is modulated by the precision of information and we will present some recent model-based behavioural results. Then I will focus on a novel model of motion-based prediction that allows to track objects on smooth trajectories. This model gives an economical description of neural mechanisms associated with the processing underlying motion detection. Finally, we will propose an exploratory hypothesis such that eye movements may be understood as the prospective response to this dynamical sensory response knowing oculomotor constraints such as delays. This line of research aims at showing that through the convergent use of models, electrophysiology or behavioural responses, the study of motion detection is an essential tool in our understanding of neural computations.},
    author = {Perrinet, Laurent U},
    bdsk-url-1 = {Presentations/2012-01-27_FIL},
    booktitle = {Brain meeting at FIL, London - Friday, January 27th, 2012},
    date-modified = {2019-02-25 23:17:47 +0100},
    keywords = { dynamics,Bayesian model,eye movements,free energy,motion detection,predictive coding},
    note = {= Time:: Jan 27, 2012, from 16:15 am to 17:00 pm Location:: Seminar room @ FIL, Queen's square, 4th floor.},
    projects = {brain-scales},
    title = {Grabbing, tracking and sniffing as models for motion detection and eye movements},
    url = {Presentations/2012-01-27_FIL},
    year = {2012}
}

@inproceedings{2012-03-22_Juelich,
    author = {Perrinet, Laurent U},
    bdsk-url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2012-03-22_Juelich},
    booktitle = {Second BrainScaleS plenary Meeting - WP4},
    date-modified = {2019-02-25 23:17:47 +0100},
    location = {Forschungszentrum Jülich},
    projects = {brain-scales},
    time_start = {2012-03-22T14:00:00},
    title = {motion-clouds: Model-based stimulus synthesis of natural-like random textures for the study of motion perception},
    url = {http://invibe.net/LaurentPerrinet/Presentations/2012-03-22_Juelich},
    url_slides = {http://invibe.net/LaurentPerrinet/Presentations/2012-03-22_Juelich?action=AttachFile&do=get&target=perrinet12wp4_handout.pdf},
    year = {2012}
}

@inproceedings{2012-03-23_Juelich,
    author = {Perrinet, Laurent U},
    bdsk-url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2012-03-23_Juelich},
    booktitle = {Second BrainScaleS plenary Meeting - WP5},
    date-modified = {2019-02-25 23:17:47 +0100},
    location = {Forschungszentrum Jülich},
    projects = {brain-scales},
    time_start = {2012-03-23T13:00:00},
    title = {Apparent motion in V1 - Probabilistic approaches},
    url = {http://invibe.net/LaurentPerrinet/Presentations/2012-03-23_Juelich},
    url_slides = {http://invibe.net/LaurentPerrinet/Presentations/2012-03-23_Juelich?action=AttachFile&do=get&target=perrinet12wp5_handout.pdf},
    year = {2012}
}

@inproceedings{2012-05-10_itwist,
    abstract = {Oriented edges in images of natural scenes tend to be aligned in collinear or co-circular arrangements, with lines and smooth curves more common than other possible arrangements of edges (Geisler et al., Vis Res 41:711-24, 2001). The visual system appears to take advantage of this prior information, and human contour detection and grouping performance is well predicted by such an "association field" (Field et al., Vis Res 33:173-93, 1993). One possible candidate substrate for implementing an association field in mammals is the set of long-range lateral connections between neurons in the primary visual cortex (V1), which could act to facilitate detection of contours matching the association field, and/or inhibit detection of other contours (Choe and Miikkulainen, Biol Cyb 90:75-88, 2004). To fill this role, the lateral connections would need to be orientation specific and aligned along contours, and indeed such an arrangement has been found in tree shrew primary visual cortex (Bosking et al., J Neurosci 17:2112-27, 1997). However, it is not yet known whether these patterns develop as a result of visual experience, or are simply hard-wired to be appropriate for the statistics of natural scenes. To investigate this issue, we examined the properties of the visual environment of laboratory animals, to determine whether the observed connection patterns are more similar to the statistics of the rearing environment or of a natural habitat. Specifically, we analyzed the cooccurence statistics of edge elements in images of natural scenes, and compared them to corresponding statistics for images taken from within the rearing environment of the animals in the Bosking et al. (1997) study. We used a modified version of the algorithm from Geisler et al. (2001), with a more general edge extraction algorithm that uses sparse coding to avoid multiple responses to a single edge. Collinearity and co-circularity results for natural images replicated qualitatively the results from Geisler et al. (2001), confirming that prior information about continuations appeared consistently in natural images. However, we find that the largely man-made environment in which these animals were reared has a significantly higher probability of collinear edge elements. We thus predict that if the lateral connection patterns are due to visual experience, the patterns in wild-raised tree shrews would be very different from those measured by Bosking et al. (1997), with shorter-range correlations and less emphasis on collinear continuations. This prediction can be tested in future experiments on matching groups of animals reared in different environments.},
    author = {Perrinet, Laurent U and Fitzpatrick, David and Bednar, James A.},
    bdsk-url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2012-05-10_itwist},
    booktitle = {iTWIST '12 workshop},
    date-modified = {2019-02-25 10:33:10 +0100},
    event_url = {https://sites.google.com/site/itwist1st/home},
    keywords = {sparse coding},
    time_start = {2012-05-10-18T13:00:00},
    title = {Edge statistics in natural images versus laboratory animal environments: implications for understanding lateral connectivity in V1},
    url = {https://laurentperrinet.github.io/talk/2012-05-10-itwist/},
    url_slides = {http://invibe.net/LaurentPerrinet/Presentations/2012-05-10?action=AttachFile&do=get&target=Perrinet12itwist.pdf},
    year = {2012}
}

@inproceedings{2013-03-21_Marseille,
    abstract = {This session aims at presenting new ideas that emerged during the first years of BrainScaleS. Indeed,
the collaborations that were initiated within the consortium led to the creation of novel tools as
planned in the proposal but also some of which were unforeseen, like the Motion Clouds that we
presented previously. We present here some prototypical and inspiring examples of such
collaborative work on: 1) tool chains from experimental (Davison), computational (Antolik) or integrative (Petrovici)
perspectives, 2) original methods inspired by novel types of analysis for propagating waves (Schmidt, Muller) or by
novel magnetrodes (Pannetier Lecoeur).},
    author = {Perrinet, Laurent U},
    bdsk-url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2013-03-21_Marseille},
    booktitle = {3rd BrainScaleS Plenary Meeting - Friday, March 21st, 2013},
    date-modified = {2019-02-25 23:17:47 +0100},
    note = {= Time:: March 21st, 2013 Location:: INT, Marseille.},
    projects = {brain-scales},
    title = {Why methods and tools are the key to artificial brain-like systems},
    url = {http://invibe.net/LaurentPerrinet/Presentations/2013-03-21_Marseille},
    year = {2013}
}

@inproceedings{2013-07-05_Cerco,
    author = {Perrinet, Laurent U and Fitzpatrick, David and Bednar, James A.},
    bdsk-url-1 = {http://invibe.net/cgi-bin/index.cgi/Presentations/2013-07-05_Cerco},
    booktitle = {CerCo 20th anniversary},
    date-modified = {2019-02-25 23:17:47 +0100},
    keywords = {Biologically Inspired Computer vision},
    location = {CerCo, Toulouse},
    projects = {brain-scales},
    time_start = {2013-07-05T13:00:00},
    title = {Edge co-occurrences and categorizing natural images},
    url = {http://invibe.net/cgi-bin/index.cgi/Presentations/2013-07-05_Cerco},
    url_slides = {http://invibe.net/LaurentPerrinet/Presentations/2013-07-05_Cerco?action=AttachFile&do=get&target=perrinet13cerco.pdf},
    year = {2013}
}

@inproceedings{2013-11-26_BrainScalesDemos,
    author = {Kaplan, Bernhard and Perrinet, Laurent U},
    bdsk-url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2013-11-26_BrainScalesDemos},
    booktitle = {Demo 1-3: Apparent Motion in V1/ MT/MST: Neural Implementation of Probabilistic Approaches},
    date-modified = {2019-02-25 23:17:47 +0100},
    note = {* Together with Bernhard Kaplan, we talked about how we aim at "compiling" a predictive motion-based approach as a spiking neural networks and then as a parallel wafer systems in the BrainscaleS project (Demo 1, Task4). * [[attachment:KaplanPerrinet13brainscales_talk.pdf|slides]] * (private to the consortium: [[https://brainscales.kip.uni-heidelberg.de/internal/jss/AttendMeeting?m=showMeetingInfoPage&meetingID=52|meeting info]] &[[https://brainscales.kip.uni-heidelberg.de/internal/jss/AttendMeeting?m=showAgenda&meetingID=52|Agenda]], including copies of the slides)},
    projects = {brain-scales},
    title = {Demo 1, Task4: Implementation of models showing emergence of cortical fields and maps},
    url = {http://invibe.net/LaurentPerrinet/Presentations/2013-11-26_BrainScalesDemos},
    year = {2013}
}

@inproceedings{2014-01-10_INTFest,
    abstract = {Moving objects generate sensory information that may be noisy and ambiguous, yet it is important to be able to reconstruct object speed as fast as possible. One unsolved question is to understand how the brain pools motion information to give an efficient response. I will present computational models of motion detection in the visual system that try to answer this question. First, sensory information is grabbed by pooling the information from different sensory neurons. This pooling is modulated by the precision of information and we will present some recent model-based behavioural results. Then I will focus on a novel model of motion-based prediction that allows to track objects on smooth trajectories. This model gives an economical description of neural mechanisms associated with the processing underlying motion detection. Finally, we will propose an exploratory hypothesis such that eye movements may be understood as the prospective response to this dynamical sensory response knowing oculomotor constraints such as delays. This line of research aims at showing that through the convergent use of models, electrophysiology or behavioural responses, the study of motion detection is an essential tool in our understanding of neural computations.},
    author = {Perrinet, Laurent U},
    bdsk-url-1 = {http://invibe.net/cgi-bin/index.cgi/Presentations/2014-01-10_INTFest},
    booktitle = {Marseille INT Fest, January 10th, 2014},
    date-modified = {2019-02-25 23:17:47 +0100},
    keywords = { dynamics,Bayesian model,eye movements,free energy,motion detection,predictive coding},
    note = {= ||<tablestyle="width: 40%; float: right; margin-left:20px; margin-right:20px; border-style: 0px; font-size: 8pt;"> [[MotionPerception|attachment:tsonga.png|Problem statement: optimal motor control under axonal delays.|width=100%,align="left"]] <<BR>> ''Problem statement: optimal motor control under axonal delays.'' The central nervous system has to contend with axonal delays, both at the sensory and the motor levels. For instance, in the human visuo-oculomotor system, it takes approximately $τ_s=50~\ms$ for the retinal image to reach the visual areas implicated in motion detection, and a further $τ_m=40~\ms $ to reach the oculomotor muscles. As a consequence, for a tennis player trying to intercept a ball at a speed of $20~\m· \s^-1$, the sensed physical position is $1~\m$ behind the true position (as represented here by $τ_s · ěcV$), while the position at the moment of emitting the motor command will be $.8~\m$ ahead of its execution ($τ_m · ̧̌V$). Note that while the actual position of the ball when its image hits photoreceptors on the retina is approximately at $45$ degrees of eccentricity (red dotted line), the player's gaze is directed to the ball at its \emphpresent position (red line), in anticipatory fashion. Optimal control directs action (future motion of the eye) to the expected position (red dashed line) of the ball in the future --- and the racket (black dashed line) to the expected position of the ball when motor commands reach the periphery (muscles). || Time:: January 10th, 2014, 11:30am Location:: CAV/LPP - 45 rue des Saints Pères - salle H432},
    projects = {brain-scales},
    title = {Axonal delays and on-time control of eye movements},
    url = {http://invibe.net/cgi-bin/index.cgi/Presentations/2014-01-10_INTFest},
    year = {2014}
}

@inproceedings{2014-03-20_Manchester,
    abstract = {The question how the visual system is able to create a coherent representation of a rapidly changing environment in the presence of neural delays is not fully resolved. In this paper we use an abstract probabilistic framework and a spiking neural network (SNN) implementation to investigate the role of motion-based prediction in estimating motion trajectories with delayed information sampling. In particular, we investigate how anisotropic diffusion of information may explain the development of anticipatory response in neural populations to an approaching stimulus. Inspired by a mechanism proposed by Nijhawan [2009], we use a Bayesian particle filter framework and introduce a diagonal motion-based prediction model which extrapolates the estimated response to delayed stimulus in the direction of the trajectory. In the SNN implementation, we have used anisotropic recurrent connections between excitatory cells as mechanism for motion-extrapolation. Consistent with recent experimental data collected in extracellular recordings of macaque primary visual cortex [Benvenuti et al 2011], we have simulated different trajectory lengths and have explored how anticipatory response may be dependent to the information accumulated along the trajectory. We show that both our probabilistic framework and the SNN can replicate the experimental data qualitatively. Most importantly, we highlight requirements for the development of a trajectory-dependent anticipatory response, and in particular the anisotropic nature of the diagonal motion extrapolation mechanism.},
    author = {Perrinet, Laurent U and Kaplan, Bernhard A and Khoei, Mina A. and Lansner, Anders and Masson, Guillaume S},
    bdsk-url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2014-03-20_Manchester},
    booktitle = {4th BrainScaleS Plenary meeting},
    date-modified = {2019-02-25 23:17:47 +0100},
    event_url = {https://brainscales.kip.uni-heidelberg.de/internal/jss/AttendMeeting?m=showAgenda&meetingID=45},
    location = {Manchester (UK)},
    projects = {brain-scales},
    time_start = {2014-03-20T13:00:00},
    title = {WP5 - Demo 1.3 : Spiking model of motion-based prediction},
    url = {http://invibe.net/LaurentPerrinet/Presentations/2014-03-20_Manchester},
    url_slides = {http://invibe.net/LaurentPerrinet/Presentations/2014-03-20_Manchester?action=AttachFile&do=get&target=14-03-20_BK_LP_MK_handout.pdf},
    year = {2014}
}

@inproceedings{2014-04-25_kaplan-beijing,
    author = {Kaplan, Bernhard A and Khoei, Mina A. and Lansner, Anders and Perrinet, Laurent U},
    bdsk-url-1 = {http://invibe.net/LaurentPerrinet/Publications/KaplanKhoei14},
    bdsk-url-2 = {https://doi.org/10.1109/IJCNN.2014.6889847},
    booktitle = {2014 International Joint Conference on Neural Networks (IJCNN)},
    date-modified = {2019-02-25 09:53:02 +0100},
    doi = {10.1109/IJCNN.2014.6889847},
    isbn = {978-1-4799-1484-5},
    keywords = { dynamics,Bayesian model,Biologically Inspired Computer vision,motion detection},
    location = {Beijing, China},
    note = {* see the corresponding [[Publications/KaplanKhoei14|paper]] ## from},
    pages = {3205--3212},
    posted-at = {2014-04-25 08:53:37},
    priority = {2},
    publisher = {IEEE},
    title = {Signature of an anticipatory response in area V1 as modeled by a probabilistic model and a spiking neural network},
    url = {http://invibe.net/LaurentPerrinet/Publications/KaplanKhoei14},
    year = {2014}
}

@inproceedings{2015-10-07_GDR-BioComp,
    abstract = {We stand at a point in history where our phones have become smart but lack a feature which prevails in most forms of living intelligence: vision. The ability to see is indeed an essential facet of intelligence which is developed in an autonomous manner even in young human infants. I will focus here on a particular problem: how do we estimate motion in a visual image? I will explain why for this problem, it is crucial to understand how the visual system might overcome temporal delays and will demonstrate at different levels of description ---from probabilistic models to neuromorphic hardware---  a surprising solution: The visual system models the world and uses the eye to probe this model.},
    author = {Perrinet, Laurent U},
    bdsk-url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2015-10-07_GDR-BioComp},
    booktitle = {First GDR BioComp workshop},
    date-modified = {2019-02-25 23:17:47 +0100},
    event_url = {http://gdr-biocomp.fr/colloque/},
    location = {Saint-Paul de Vence},
    projects = {brain-scales},
    time_start = {2015-10-07T13:00:00},
    title = {Motion-based prediction with neuromorphic hardware},
    url = {http://invibe.net/LaurentPerrinet/Presentations/2015-10-07_GDR-BioComp},
    url_slides = {http://invibe.net/LaurentPerrinet/Presentations/2015-10-07_GDR-BioComp?action=AttachFile&do=view&target=Perrinet15biocomp_slides.pdf},
    year = {2015}
}

@inproceedings{2015-11-05_Chile,
    abstract = {
We stand at a point in history where our phones have become smart but
lack a feature which prevails in most forms of living intelligence:
vision. The ability to see is indeed an essential facet of intelligence
which is developed in an autonomous manner even in young human infants.
I will focus here on a particular problem: how do we estimate motion in
a visual image? I will explain why for this problem, it is crucial to
understand how the visual system might overcome temporal delays and will
demonstrate at different levels of description ---from probabilistic
models to neuromorphic hardware---  a surprising solution: The visual
system models the world and uses the eye to probe this model},
    author = {Perrinet, Laurent U},
    bdsk-url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2015-11-05_Chile},
    booktitle = {Charla},
    date-modified = {2019-02-25 22:46:46 +0100},
    event_url = {http://www.eventos.usm.cl/evento/charla-motion-based-prediction-with-neuromorphic-hardware/},
    location = {Universidad Técnica Federico Santa Marı́a, Valpara\śo, Chile},
    projects = {anr-bala-v1},
    time_start = {2015-11-05T13:00:00},
    title = {Motion-based prediction with neuromorphic hardware},
    url = {http://invibe.net/LaurentPerrinet/Presentations/2015-11-05_Chile},
    year = {2015}
}

@inproceedings{2016-07-07_EDP-proba,
    author = {Perrinet, Laurent U},
    bdsk-url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2016-07-07_EDP-proba},
    booktitle = {Summer School: PDE and Probability for Life Sciences},
    date-modified = {2019-02-25 23:17:47 +0100},
    event_url = {http://scientific-events.weebly.com/prog-1426.html},
    location = {CIRM, Marseille},
    projects = {anr-bala-v1,brain-scales},
    time_start = {2016-07-07T13:00:00},
    title = {Modelling the dynamics of cognitive processes: from the Bayesian brain to particles},
    url = {http://invibe.net/LaurentPerrinet/Presentations/2016-07-07_EDP-proba},
    url_slides = {https://laurentperrinet.github.io/sciblog/files/2016-07-07_EDP-proba},
    year = {2016}
}

@inproceedings{2016-10-13_LAW,
    author = {Perrinet, Laurent U},
    bdsk-url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2016-10-13_LAW},
    booktitle = {Lyon Active inference Workshop (LAW)},
    date-modified = {2019-02-25 23:35:53 +0100},
    event_url = {https://law2016.sciencesconf.org/},
    location = {Lyon, France},
    projects = {anr-rem,pace-itn},
    time_start = {2016-10-13T10:00:00},
    title = {Eye movements as a model for active inference},
    url = {https://laurentperrinet.github.io/talk/2016-10-13-law/},
    url_slides = {https://laurentperrinet.github.io/sciblog/files/2016-10-13_LAW.html},
    year = {2016}
}

@inproceedings{2016-10-26_FillatreBarlaudPerrinet16EUVIP,
    author = {Fillatre, Lionel and Barlaud, Michel and Perrinet, Laurent U},
    bdsk-url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2016-10-26_FillatreBarlaudPerrinet16EUVIP},
    booktitle = {EUVIP Session 7: Biologically Inspired Computer Vision (Special Session)},
    date-modified = {2019-02-25 10:27:44 +0100},
    event_url = {http://invibe.net/LaurentPerrinet/Events/2016-10-26_EUVIP_BICV},
    keywords = {Biologically Inspired Computer vision},
    location = {Ecole Centrale Marseille},
    time_start = {2016-10-26T13:00:00},
    title = {Categorization of microscopy images using a biologically inspired edge co-occurrences descriptor},
    url = {http://invibe.net/LaurentPerrinet/Presentations/2016-10-26_FillatreBarlaudPerrinet16EUVIP},
    url_code = {https://hal-amu.archives-ouvertes.fr/hal-01461404},
    url_slides = {https://laurentperrinet.github.io/sciblog/files/2016-10-26_FillatreBarlaudPerrinet16EUVIP_talk.html},
    year = {2016}
}

@inproceedings{2016-10-26_Perrinet16EUVIP,
    author = {Perrinet, Laurent U},
    bdsk-url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2016-10-26_Perrinet16EUVIP},
    booktitle = {EUVIP Session 7: Biologically Inspired Computer Vision (Special Session)},
    date-modified = {2019-02-25 10:27:44 +0100},
    event_url = {http://invibe.net/LaurentPerrinet/Events/2016-10-26_EUVIP_BICV},
    keywords = {Biologically Inspired Computer vision},
    location = {Ecole Centrale Marseille},
    note = {Conference paper http://invibe.net/LaurentPerrinet/Presentations/2016-10-26_Perrinet16EUVIP},
    time_start = {2016-10-26T13:00:00},
    title = {Biologically-inspired characterization of sparseness in natural images},
    url = {http://invibe.net/LaurentPerrinet/Presentations/2016-10-26_Perrinet16EUVIP},
    url_code = {https://hal-amu.archives-ouvertes.fr/hal-01461404},
    url_slides = {https://laurentperrinet.github.io/sciblog/files/2016-10-26_Perrinet16EUVIP_talk.html},
    year = {2016}
}

@inproceedings{2016-11-03_gdr,
    author = {Damasse, Jean-Bernard and Perrinet, Laurent U and Jozefowiez, Jeremie and Madelain, Laurent and Montagnini, Anna},
    bdsk-url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2016-11-03_gdr},
    booktitle = {GDR Vision, Toulouse, Nov 3rd, 2016},
    date-modified = {2019-03-04 23:05:00 +0100},
    note = {Time:: Thursday, November 3rd, 2016 Location:: GDR-Vision 2016 - https://gdrvision2016.sciencesconf.org/ Abstract:: Natural environments potentially contain several interesting targets for goal-directed be- havior. Thus sensorimotor systems need to operate a competitive selection based on behav- iorally meaningful parameters. Recently, it has been observed that voluntary eye movements such as saccades and smooth pursuit can be considered as operant behaviors (Madelain et al, 2011). Indeed, parameters of saccades such as peak-velocity or latency (Montagnini et al, 2005) as well as smooth pursuit behavior during transient blanking (Madelain et al, 2003) or visually-guided pursuit of ambiguous stimuli (Sch ́'utz et al, 2015) can be modified by reinforcement contingencies. Here we address the question of whether expectancy-based anticipatory smooth pursuit can be modulated by reinforcement contingencies. When pre- dictive information is available, anticipatory smooth pursuit eye movements (aSPEM) is frequently observed before target appearance. Actions that occur at some distance in time from the reinforcement outcome, such as aSPEM -which occurs without any concurrent sen- sory feedback- suffer of the well-known credit assignment problem (Kaelbling et al, 1996). We designed a direction-bias task as a baseline and modified it by setting an implicit eye velocity criterion during anticipation. The nature of the following trial-outcome (reward or punishment) was contingent to the online criterion matching. We observed a dominant graded effect of motion-direction bias and a small modulational effect of reinforcement on aSPEM velocity. A yoked-control paradigm corroborated this result showing a strong reduc- tion in anticipatory behavior when the reward/punishment schedule was not contingent to behavior. An additional classical conditioning paradigm confirmed that reinforcement con- tingencies have to be operant to be effective and that they have a role in solving the credit assignment problem during aSPEM.},
    projects = {anr-rem,pace-itn},
    title = {Reinforcement contingencies modulate anticipatory smooth eye movements},
    url = {http://invibe.net/LaurentPerrinet/Presentations/2016-11-03_gdr},
    year = {2016}
}

@inproceedings{2016-11-03_SIGMA,
    author = {Perrinet, Laurent U},
    bdsk-url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2016-11-03_SIGMA},
    booktitle = {Workshop SIGMA'2016: Signal, Image, Geometry, Modelling, Approximation},
    date-modified = {2019-02-25 23:35:53 +0100},
    location = {CIRM},
    projects = {pace-itn},
    time_start = {2016-11-03T13:00:00},
    title = {The flash-lag effect as a motion-based predictive shift},
    url = {http://invibe.net/LaurentPerrinet/Presentations/2016-11-03_SIGMA},
    url_slides = {https://laurentperrinet.github.io/sciblog/files/2016-11-03_SIGMA.html},
    year = {2016}
}

@inproceedings{2017-01-18_LACONEU,
    author = {Perrinet, Laurent U},
    bdsk-url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2017-01-18_LACONEU},
    booktitle = {Workshop on Computational Neuroscience "New trends and challenges for 2030"},
    date-modified = {2019-02-25 23:10:19 +0100},
    event_url = {http://cinv.uv.cl/laconeu-workshop},
    location = {Valparaiso (Chile)},
    note = {http://laconeu.cl/wp-content/uploads/2018/04/Valparaiso-3.jpg},
    projects = {anr-trajectory},
    time_start = {2017-01-18T09:00:00},
    title = {Back to the present: how neurons deal with delays},
    url = {http://invibe.net/LaurentPerrinet/Presentations/2017-01-18_LACONEU},
    url_slides = {https://laurentperrinet.github.io/sciblog/files/2017-01-18_LACONEU.html},
    year = {2017}
}

@inproceedings{2017-01-19_LACONEU,
    author = {Perrinet, Laurent U},
    bdsk-url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2017-01-19_LACONEU},
    booktitle = {LACONEU 2017: 4th Latin-American Summer School in Computational Neuroscience},
    date-modified = {2019-02-25 23:10:19 +0100},
    event_url = {http://www.laconeu.cl},
    keywords = {Biologically Inspired Computer vision},
    location = {Valparaiso (Chile)},
    projects = {anr-trajectory},
    time_start = {2017-01-19T10:45:00},
    title = {Tutorial: Sparse optimization in neural computations},
    url = {http://invibe.net/LaurentPerrinet/Presentations/2017-01-19_LACONEU},
    url_slides = {https://laurentperrinet.github.io/sciblog/files/2017-01-19_LACONEU.html},
    year = {2017}
}

@inproceedings{2017-01-20_LACONEU,
    author = {Perrinet, Laurent U},
    bdsk-url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2017-01-20_LACONEU},
    booktitle = {LACONEU 2017: 4th Latin-American Summer School in Computational Neuroscience},
    date-modified = {2019-02-25 23:10:19 +0100},
    event_url = {http://www.laconeu.cl},
    location = {Valparaiso (Chile)},
    projects = {anr-trajectory},
    time_start = {2017-01-20T10:45:00},
    title = {Tutorial: Active inference for eye movements: Bayesian methods, neural inference, dynamics},
    url = {http://invibe.net/LaurentPerrinet/Presentations/2017-01-20_LACONEU},
    url_slides = {https://laurentperrinet.github.io/sciblog/files/2017-01-20_LACONEU.html},
    year = {2017}
}

@inproceedings{2017-06-28_Telluride,
    author = {Perrinet, Laurent U},
    bdsk-url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2017-06-28_Telluride},
    booktitle = {Workshop on Computational Neuroscience entitled "Neuromorphic Event-based Compound Eyes and Vision""},
    date-modified = {2019-02-25 09:53:02 +0100},
    event_url = {http://telluride.iniforum.ch/2017/workgroups/neuromorphic-event-based-compound-eyes-and-vision/},
    location = {Telluride, CO},
    time_start = {2017-06-28T13:00:00},
    title = {Back to the present: dealing with delays in biological and neuromorphic systems},
    url = {https://laurentperrinet.github.io/talk/2017-06-28-telluride},
    url_slides = {https://laurentperrinet.github.io/sciblog/files/2017-06-28_Telluride.html},
    year = {2017}
}

@inproceedings{2017-06-30_Telluride,
    author = {Perrinet, Laurent U},
    bdsk-url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2017-06-30_Telluride},
    booktitle = {Telluride Neuromorphic Workshop, Workgroup on Compound Eyes and Event-based Vision},
    date-modified = {2019-02-25 09:53:02 +0100},
    event_url = {http://telluride.iniforum.ch/2017/workgroups/neuromorphic-event-based-compound-eyes-and-vision/},
    location = {Telluride, CO},
    time_start = {2017-06-28T13:00:00},
    title = {Tutorial on predictive coding},
    url = {https://laurentperrinet.github.io/talk/2017-06-30-telluride},
    url_slides = {https://laurentperrinet.github.io/sciblog/files/2017-06-30_Telluride.html},
    year = {2017}
}

@inproceedings{2017-11-15_ColloqueMaster,
    abstract = {This seminar is an exercise to introduce the AMU masters into the format of international conferences. As such, we will try to introduce new concepts and results which will not be found in textbooks.},
    author = {Perrinet, Laurent U},
    bdsk-url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2017-11-15_ColloqueMaster},
    booktitle = {Colloque : "CODAGES ET REPRESENTATIONS", MASTER DE NEUROSCIENCES 2ème année; Comité d'organisation: Francesca SARGOLINI, Christian Bénar, Paolo GUBELLINI, Christian GESTREAU},
    date-modified = {2019-02-25 22:16:13 +0100},
    location = {Aix-Marseille Université, Campus Saint-Charles, Salle des voûtes},
    note = {References:: <<BR>> - unsupervised learning : [[Publications/Perrinet10shl|Perrinet (2010)]] <<BR>> - [[Publications/CristobalPerrinetKeil15bicv|Biologically inspired computer vision]] <<BR>> - supervised learning : https://www.nature.com/articles/srep11400 ([[http://invibe.net/LaurentPerrinet/Publications/PerrinetBednar15|more info]] ) <<BR>> - dynamics: Khoei et al (2017) - http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005068 ( [[Publications/KhoeiMassonPerrinet17|more info]] )},
    time_start = {2017-11-15T13:00:00},
    title = {What dynamic neural codes for efficient visual processing},
    url = {http://invibe.net/LaurentPerrinet/Presentations/2017-11-15_ColloqueMaster},
    url_slides = {https://laurentperrinet.github.io/sciblog/files/2017-11-15_ColloqueMaster.html},
    year = {2017}
}

@inproceedings{2017-11-24_NeurosciencesRobotique,
    author = {Boutin, Victor and Ruffier, Franck and Perrinet, Laurent U},
    bdsk-url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2017-11-24_NeurosciencesRobotique},
    date-modified = {2019-02-25 10:33:10 +0100},
    event_url = {http://www.isir.upmc.fr/index.php?op=view_page&id=1463&menuid=17},
    keywords = {sparse coding},
    location = {IMERA (Aix-Marseille Université)},
    note = {## http://www.laconeu.cl/images/Afiche_Workshop.jpg||align=right,width=50% Time:: November 24th, 2017 Venue:: Journee du GT 8 (Neurosciences - Robotique) Location:: Programme::},
    projects = {doc-2-amu},
    time_start = {2017-11-24T13:00:00},
    title = {Unsupervised learning applied to robotic vision},
    url = {http://invibe.net/LaurentPerrinet/Presentations/2017-11-24_NeurosciencesRobotique},
    year = {2017}
}

@inproceedings{2018-01-25_meetup-neuronautes,
    author = {Perrinet, Laurent U and Rey, Etienne},
    bdsk-url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2018-01-25_meetup-neuronautes},
    booktitle = {Meetup Art et Neurosciences, Association NeuroNautes},
    date-modified = {2019-02-25 10:27:44 +0100},
    event_url = {https://www.facebook.com/events/211121069456116/},
    keywords = {Biologically Inspired Computer vision},
    location = {Salle des voutes campus Saint Charles},
    time_start = {2018-01-25T13:00:00},
    title = {Expériences autour de la perception de la forme en art et science},
    url = {https://laurentperrinet.github.io/talk/2018-01-25-meetup-neuronautes/},
    url_slides = {https://laurentperrinet.github.io/sciblog/files/2018-01-25_meetup-neuronautes.html},
    year = {2018}
}

@inproceedings{2018-02-01_BCP_INVIBE_fest,
    author = {Perrinet, Laurent U and Pasturel, Chloé and Montagnini, Anna},
    bdsk-url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2018-02-01_BCP_INVIBE_fest},
    booktitle = {Visual motion Fest - Invibe Team -- INT / Marseille February 1 & 2, 2018},
    date-modified = {2019-03-04 23:05:00 +0100},
    note = {Quoi:: Visual motion Fest - Invibe Team -- INT / Marseille February 1 & 2, 2018 Quand:: 1/2/2018 Où:: INT Support visuel:: https://laurentperrinet.github.io/sciblog/files/2018-02-01_BCP_INVIBE_fest.html},
    title = {Estimating and anticipating a dynamic probabilistic bias in visual motion direction},
    url = {http://invibe.net/LaurentPerrinet/Presentations/2018-02-01_BCP_INVIBE_fest},
    year = {2018}
}

@inproceedings{2018-03-26_cours-NeuroComp_FEP,
    author = {Perrinet, Laurent U},
    bdsk-url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2018-03-26_cours-NeuroComp_FEP},
    booktitle = {Course in Computational Neuroscience @ PhD program},
    date-modified = {2019-02-25 09:53:02 +0100},
    event_url = {http://invibe.net/LaurentPerrinet/Presentations/2018-03-26_cours-NeuroComp},
    location = {INT, Marseille},
    time_start = {2018-03-26T13:00:00},
    title = {Probabilities, Bayes and the Free-energy principle},
    url = {https://laurentperrinet.github.io/talk/2018-03-26-cours-neuro-comp-fep/},
    url_code = {https://github.com/laurentperrinet/2018-03-26_cours-NeuroComp_FEP},
    url_slides = {https://laurentperrinet.github.io/2018-03-26_cours-NeuroComp_FEP},
    year = {2018}
}

@inproceedings{2018-04-05_BCP_talk,
    author = {Perrinet, Laurent U and Pasturel, Chloé and Anna Montagnini, INT},
    bdsk-url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2018-04-05_BCP_talk},
    booktitle = {Probabilities and Optimal Inference to Understand the Brain},
    date-modified = {2019-03-04 23:01:53 +0100},
    event_url = {http://invibe.net/cgi-bin/index.cgi/Events/2018-04-05_OptInferBrainWorkshop},
    location = {INT, Marseille (France)},
    projects = {pace-itn},
    time_start = {2018-04-05T14:00:00},
    title = {Principles and psychophysics of Active Inference in anticipating a dynamic, switching probabilistic bias},
    url = {https://laurentperrinet.github.io/talk/2018-04-05-bcp-talk/},
    url_code = {https://github.com/laurentperrinet/2018-04-05_BCP_talk/},
    url_slides = {https://laurentperrinet.github.io/2018-04-05_BCP_talk/},
    year = {2018}
}

@inproceedings{2019-01-14_LACONEU,
    author = {Perrinet, Laurent U},
    bdsk-url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2019-01-14_LACONEU},
    booktitle = {LACONEU 2019: 5th Latin-American Summer School in Computational Neuroscience},
    date-modified = {2019-02-25 22:52:33 +0100},
    event_url = {http://www.laconeu.cl},
    location = {Valparaiso (Chile)},
    projects = {anr-horizontal-v1},
    time_start = {2019-01-14T11:00:00},
    title = {Modelling spiking neural networks using Brian, Nest and pyNN},
    url = {http://invibe.net/LaurentPerrinet/Presentations/2019-01-14_LACONEU},
    url_code = {https://github.com/laurentperrinet/2019-01-14_LACONEU},
    url_slides = {https://laurentperrinet.github.io/2019-01-14_LACONEU},
    year = {2019}
}

@inproceedings{2019-01-16_LACONEU,
    author = {Perrinet, Laurent U},
    bdsk-url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2019-01-16_LACONEU},
    booktitle = {LACONEU 2019: 5th Latin-American Summer School in Computational Neuroscience},
    date-modified = {2019-02-25 22:52:33 +0100},
    event_url = {http://www.laconeu.cl},
    location = {Valparaiso (Chile)},
    projects = {anr-horizontal-v1},
    time_start = {2019-01-16T10:45:00},
    title = {Efficient coding of visual information in neural computations},
    url = {http://invibe.net/LaurentPerrinet/Presentations/2019-01-16_LACONEU},
    url_code = {https://github.com/laurentperrinet/2019-01-16_LACONEU/},
    url_slides = {https://laurentperrinet.github.io/2019-01-16_LACONEU/},
    year = {2019}
}

@inproceedings{2019-01-17_LACONEU,
    author = {Perrinet, Laurent U},
    bdsk-url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2019-01-17_LACONEU},
    booktitle = {LACONEU 2019: 5th Latin-American Summer School in Computational Neuroscience},
    date-modified = {2019-02-25 22:52:33 +0100},
    event_url = {http://www.laconeu.cl},
    location = {Valparaiso (Chile)},
    projects = {anr-horizontal-v1},
    time_start = {2019-01-17T10:45:00},
    title = {Role of dynamics in neural computations underlying visual processing},
    url = {http://invibe.net/LaurentPerrinet/Presentations/2019-01-17_LACONEU},
    url_code = {https://github.com/laurentperrinet/2019-01-17_LACONEU/},
    url_slides = {https://laurentperrinet.github.io/2019-01-17_LACONEU/},
    year = {2019}
}

@inproceedings{2019-03-25_RobinBaures,
    abstract = {Visual areas are essential in transforming the raw luminous signal into a representation which efficiently conveys information about the environment. This process is constrained by various factors such as a wide variety of changes in the characteristics of the visual image but also by the necessity to be able to respond as quickly as possible to the incoming sensory stream, for instance to drive a movement of the eyes to the location of a potential danger. To achieve this, it is believed that the visual system takes advantage of the existence of a priori knowledge in the structure of visual information, such as the regularity in the shape and motion of visual objects. As such, the predictive coding coding framework offers a unified theory to explain many of the mechanisms at the different levels of the visual system and which were unveiled by decades of study in neurophysiology and psychophysics.},
    author = {Perrinet, Laurent U},
    booktitle = {HDR Robin Baures},
    event_url = {https://www.jnlf.fr/agenda/jnlf-lille-2019},
    location = {Toulouse, France},
    projects = {anr-horizontal-v1},
    time_start = {2019-03-25T14:00:00},
    title = {From the retina to action: Predictive processing in the visual system},
    url = {https://laurentperrinet.github.io/talk/2019-03-25_RobinBaures},
    url_code = {https://github.com/laurentperrinet/2019-03-25_RobinBaures},
    url_slides = {https://laurentperrinet.github.io/2019-03-25_RobinBaures},
    year = {2019}
}

@inproceedings{2019-04-18_JNLF,
    abstract = {Les illusions visuelles sont des créations d'artistes, de scientifiques et plus récemment, grâce aux réseaux sociaux, du grand public qui proposent des situations souvent incongrues, dans lesquelles l'eau remonte une cascade, les personnes volent dans les airs ou des serpents se mettent à tourner. Au-delà de leur indéniable coté ludique, ces illusions nous apprennent beaucoup sur le fonctionnement du cerveau, notamment quand celles-ci se transforment en hallucinations visuelles, dépassant ainsi les limites des capacités de notre perception. En tant que chercheur en Neurosciences à l'Institut de Neurosciences de la Timone à Marseille, je vous dévoilerai des aspects du fonctionnement du cerveau qui sont souvent méconnus. En particulier, nous verrons pourquoi un magicien peut tromper nos sens ou comment des objets peuvent voyager dans le temps. Surtout nous essaierons de comprendre le fonctionnement de notre perception visuelle sur les bases d'une théorie de la vision non pas comme une simple caméra qui enregistre des images mais comme un processus actif en relation avec le monde qui nous entoure.},
    author = {Perrinet, Laurent U},
    bdsk-url-1 = {https://laurentperrinet.github.io/talk/2019-04-18_jnlf},
    booktitle = {JNLF 2019},
    date-modified = {2019-02-25 09:53:02 +0100},
    event_url = {https://www.jnlf.fr/agenda/jnlf-lille-2019},
    location = {Lille, France},
    note = {Summary: Mieux comprendre la fonction de la perception visuelle en explorant certaines limites; Mieux comprendre l'importance de l'aspect dynamique de la perception; Mieux comprendre le rôle de l'action dans la perception.},
    projects = {anr-horizontal-v1},
    time_start = {2019-04-18T13:00:00},
    title = {Des illusions aux hallucinations visuelles: une porte sur la perception},
    url = {https://laurentperrinet.github.io/talk/2019-04-18_jnlf},
    url_code = {https://github.com/laurentperrinet/2019-01-14_LACONEU},
    url_slides = {https://laurentperrinet.github.io/2019-01-14_LACONEU},
    year = {2019}
}

@inproceedings{2019-05-23_NeuroFrance,
    abstract = {Animal behavior has to constantly adapt to changes in the environment, for instance when a contextual probabilistic variable switches its state. For an agent interacting with this kind of volatile environment, it is important to respond to such switches accurately and with the shortest delay. However, this operation has in general to be performed in presence of noisy sensory inputs and solely based on the information accumulated at the present time. It has already been shown that human observers can accurately anticipate a target's motion direction with their eye movements throughout random sequences of rightward/leftward motions with a bias in direction probability. Here, we tested the ability of these observers to anticipate different random biases within random-length contextual blocks. Experimental results were compared to those of a probabilistic agent which is optimal with respect to this switching model. We found a better fit between the behaviorally observed anticipatory response with that of the probabilistic agent compared to other models such as a leaky integrator model. Moreover, we could similarly fit the level of confidence given by human observers with that provided by the model and draw a common marker for subject inter-variability, titrating their level of preference between exploration and exploitation. Such results provide evidence that human observers may efficiently represent an internal belief for motion direction bias, along with its precision, and use this representation for sensorimotor control as well as for explicit judgments. This work proposes a novel approach to more generically test human cognitive abilities in uncertain and dynamic environments.},
    annote = {
in french: Principes et psychophysique de l´Inférence Active dans l'estimation d'un biais dynamique et volatile de probabilité
SYMPOSIUM, Room 7
23.05.2019, 11:00 -- 13:00
Active Inference: Bridging theoretical and experimental neurosciences. / Inference Active: Un pont entre neurosciences théoriques et expérimentales.},
    author = {Perrinet, Laurent U and Pasturel, Chloé and Montagnini, Anna},
    booktitle = {Colloque international de la Société des Neurosciences 2019 (NeuroFrance 2019), Marseille (France)},
    date-modified = {2019-03-04 23:05:00 +0100},
    projects = {pace-itn},
    time_start = {2019-05-23T11:00:00},
    title = {Principles and psychophysics of Active Inference},
    url = {https://laurentperrinet.github.io/talk/2019-05-23-neuro-france},
    year = {2019}
}

@article{template,
    date-added = {2019-02-25 09:54:59 +0100},
    date-modified = {2019-02-25 23:17:47 +0100},
    keywords = {active inference,Aperture problem,area-v1,association field,Bayesian model,Biologically Inspired Computer vision,center-surround interactions,coding decoding,computational neuroscience,dynamics,eye movements,feed-forward_inhibition,free energy,gain control,homeostasis,Image texture,inhibition,large-scale_networks,lateral connections,log-gabor,matching pursuit,motion detection,motion prediction,motion-clouds,Object motion,predictive coding,psychophysics,pynn,rank-order-coding,receptive field,recursive inference,Retina,Smooth pursuit eye movement,sparse coding,sparse hebbian learning,sparselets,spike,staistics of natural images,stdp,Temporal evolution.,unsupervised learning,visual perception},
    projects = {anr-bala-v1,anr-causal,anr-horizontal-v1,anr-predicteye,anr-rem,anr-speed,anr-trajectory,brain-scales,codde,doc-2-amu,facets,facets-itn,pace-itn,phd-icn},
    time_start = {2019-04-18T13:00:00},
    year = {2019}
}

