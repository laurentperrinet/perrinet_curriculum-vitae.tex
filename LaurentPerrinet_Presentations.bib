%% This BibTeX bibliography file was created using BibDesk.
%% http://bibdesk.sourceforge.net/


%% Created for Laurent Perrinet at 2019-02-22 22:23:06 +0100 


%% Saved with string encoding Unicode (UTF-8) 



@inproceedings{2016-10-13_LAW,
	Author = {Perrinet, Laurent U.},
	Booktitle = {Lyon Active Inference Workshop (LAW) https://law2016.sciencesconf.org/ - October 13th, 2016},
	Note = {Time:: October 13th, 2016 Location:: The Lyon Active Inference Workshop (LAW) https://law2016.sciencesconf.org/ Slides:: https://laurentperrinet.github.io/sciblog/files/2016-10-13_LAW.html},
	Title = {Eye movements as a model for active inference},
	Url = {http://invibe.net/LaurentPerrinet/Presentations/2016-10-13_LAW},
	Year = {2016},
	Bdsk-Url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2016-10-13_LAW}}

@inproceedings{2016-10-26_Perrinet16EUVIP,
	Author = {Perrinet, Laurent U.},
	Booktitle = {EUVIP (Special Session): Biologically Inspired Computer Vision - October 16th, 2016},
	Note = {= ||<tablestyle="width: 96%; float: center; margin-left:20px; margin-right:20px; border-style: 0px; font-size: 10pt;">{{attachment:Publications/CristobalPerrinetKeil15bicv/1412243631.jpg|Compound eyes''|width="100%"}}|| ## / https://bicv.github.io/Perrinet16EUVIP/index.html Code:: https://github.com/bicv/Perrinet16EUVIP Date:: October 26th, 2016 Location:: Ecole Centrale Marseille Slides:: see [[https://laurentperrinet.github.io/sciblog/files/2016-10-26_Perrinet16EUVIP_talk.html|online]] Special Session:: [[Events/2016-10-26_EUVIP_BICV|Biologically Inspired Computer Vision]] Conference paper:: [[Publications/Perrinet16EUVIP|Perrinet16EUVIP]] Reprint:: [[https://hal-amu.archives-ouvertes.fr/hal-01461404|HAL]]},
	Title = {Biologically-inspired characterization of sparseness in natural images},
	Url = {http://invibe.net/LaurentPerrinet/Presentations/2016-10-26_Perrinet16EUVIP},
	Year = {2016},
	Bdsk-Url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2016-10-26_Perrinet16EUVIP}}

@inproceedings{2018-03-26_cours-NeuroComp_FEP,
	Author = {Laurent U Perrinet},
	Booktitle = {PhD program in Neuroscience, Marseille - March 27th, 2018},
	Note = {Quoi:: [[Presentations/2018-03-26_cours-NeuroComp|Course in Computational Neuroscience @ PhD program]] Quand:: March 27th, 2018 O{\`u}:: R+1, [[http://www.int.univ-amu.fr/contact|INT]], Marseille Support visuel:: https://laurentperrinet.github.io/2018-03-26_cours-NeuroComp_FEP Support computationnel:: https://github.com/laurentperrinet/2018-03-26_cours-NeuroComp_FEP},
	Title = {Probabilities, Bayes and the Free-energy principle},
	Url = {http://invibe.net/LaurentPerrinet/Presentations/2018-03-26_cours-NeuroComp_FEP},
	Year = {2018},
	Bdsk-Url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2018-03-26_cours-NeuroComp_FEP}}

@inproceedings{2014-04-25_kaplan-beijing,
	Author = {Kaplan, Bernhard A. and Khoei, Mina A. and Lansner, Anders and Perrinet, Laurent U.},
	Booktitle = {2014 International Joint Conference on Neural Networks (IJCNN)},
	Doi = {10.1109/IJCNN.2014.6889847},
	Isbn = {978-1-4799-1484-5},
	Keywords = {bayesian, bicv-motion, khoei14thesis, khoei15fle, models, neural\_delays},
	Location = {Beijing, China},
	Note = {* see the corresponding [[Publications/KaplanKhoei14|paper]] ## from},
	Pages = {3205--3212},
	Posted-At = {2014-04-25 08:53:37},
	Priority = {2},
	Publisher = {IEEE},
	Title = {Signature of an anticipatory response in area {V1} as modeled by a probabilistic model and a spiking neural network},
	Url = {http://invibe.net/LaurentPerrinet/Publications/KaplanKhoei14},
	Year = {2014},
	Bdsk-Url-1 = {http://invibe.net/LaurentPerrinet/Publications/KaplanKhoei14},
	Bdsk-Url-2 = {https://doi.org/10.1109/IJCNN.2014.6889847}}

@inproceedings{2014-01-10_INTFest,
	Abstract = {Moving objects generate sensory information that may be noisy and ambiguous, yet it is important to be able to reconstruct object speed as fast as possible. One unsolved question is to understand how the brain pools motion information to give an efficient response. I will present computational models of motion detection in the visual system that try to answer this question. First, sensory information is grabbed by pooling the information from different sensory neurons. This pooling is modulated by the precision of information and we will present some recent model-based behavioural results. Then I will focus on a novel model of motion-based prediction that allows to track objects on smooth trajectories. This model gives an economical description of neural mechanisms associated with the processing underlying motion detection. Finally, we will propose an exploratory hypothesis such that eye movements may be understood as the prospective response to this dynamical sensory response knowing oculomotor constraints such as delays. This line of research aims at showing that through the convergent use of models, electrophysiology or behavioural responses, the study of motion detection is an essential tool in our understanding of neural computations.},
	Author = {Perrinet, Laurent U.},
	Booktitle = {Marseille INT Fest, January 10th, 2014},
	Keywords = {eye movements, motion detection, probabilistic representation, predictive coding, temporal delays, free-energy},
	Note = {= ||<tablestyle="width: 40%; float: right; margin-left:20px; margin-right:20px; border-style: 0px; font-size: 8pt;"> [[MotionPerception|{{attachment:tsonga.png|Problem statement: optimal motor control under axonal delays.|width=100%,align="left"}}]] <<BR>> ''Problem statement: optimal motor control under axonal delays.'' The central nervous system has to contend with axonal delays, both at the sensory and the motor levels. For instance, in the human visuo-oculomotor system, it takes approximately $\tau_s=50~\ms$ for the retinal image to reach the visual areas implicated in motion detection, and a further $\tau_m=40~\ms $ to reach the oculomotor muscles. As a consequence, for a tennis player trying to intercept a ball at a speed of $20~\m\cdot \s^{-1}$, the sensed physical position is $1~\m$ behind the true position (as represented here by $\tau_s \cdot \vec{V}$), while the position at the moment of emitting the motor command will be $.8~\m$ ahead of its execution ($\tau_m \cdot \vec{V}$). Note that while the actual position of the ball when its image hits photoreceptors on the retina is approximately at $45$ degrees of eccentricity (red dotted line), the player's gaze is directed to the ball at its \emph{present} position (red line), in anticipatory fashion. Optimal control directs action (future motion of the eye) to the expected position (red dashed line) of the ball in the future --- and the racket (black dashed line) to the expected position of the ball when motor commands reach the periphery (muscles). || Time:: January 10th, 2014, 11:30am Location:: CAV/LPP - 45 rue des Saints P{\`e}res - salle H432},
	Title = {Axonal delays and on-time control of eye movements},
	Url = {http://invibe.net/cgi-bin/index.cgi/Presentations/2014-01-10_INTFest},
	Year = {2014},
	Bdsk-Url-1 = {http://invibe.net/cgi-bin/index.cgi/Presentations/2014-01-10_INTFest}}

@inproceedings{2016-11-03_gdr,
	Author = {Damasse, Jean-Bernard and Perrinet, Laurent and Jozefowiez, Jeremie and Madelain, Laurent and Montagnini, Anna},
	Booktitle = {GDR Vision, Toulouse, Nov 3rd, 2016},
	Note = {Time:: Thursday, November 3rd, 2016 Location:: GDR-Vision 2016 - https://gdrvision2016.sciencesconf.org/ Abstract:: Natural environments potentially contain several interesting targets for goal-directed be- havior. Thus sensorimotor systems need to operate a competitive selection based on behav- iorally meaningful parameters. Recently, it has been observed that voluntary eye movements such as saccades and smooth pursuit can be considered as operant behaviors (Madelain et al, 2011). Indeed, parameters of saccades such as peak-velocity or latency (Montagnini et al, 2005) as well as smooth pursuit behavior during transient blanking (Madelain et al, 2003) or visually-guided pursuit of ambiguous stimuli (Sch ÃÅ'utz et al, 2015) can be modified by reinforcement contingencies. Here we address the question of whether expectancy-based anticipatory smooth pursuit can be modulated by reinforcement contingencies. When pre- dictive information is available, anticipatory smooth pursuit eye movements (aSPEM) is frequently observed before target appearance. Actions that occur at some distance in time from the reinforcement outcome, such as aSPEM -which occurs without any concurrent sen- sory feedback- suffer of the well-known credit assignment problem (Kaelbling et al, 1996). We designed a direction-bias task as a baseline and modified it by setting an implicit eye velocity criterion during anticipation. The nature of the following trial-outcome (reward or punishment) was contingent to the online criterion matching. We observed a dominant graded effect of motion-direction bias and a small modulational effect of reinforcement on aSPEM velocity. A yoked-control paradigm corroborated this result showing a strong reduc- tion in anticipatory behavior when the reward/punishment schedule was not contingent to behavior. An additional classical conditioning paradigm confirmed that reinforcement con- tingencies have to be operant to be effective and that they have a role in solving the credit assignment problem during aSPEM.},
	Title = {Reinforcement contingencies modulate anticipatory smooth eye movements},
	Url = {http://invibe.net/LaurentPerrinet/Presentations/2016-11-03_gdr},
	Year = {2016},
	Bdsk-Url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2016-11-03_gdr}}

@inproceedings{2019-04-18_JNLF,
	Abstract = {Les illusions visuelles sont des cr{\'e}ations d'artistes, de scientifiques et plus r{\'e}cemment, gr{\^a}ce aux r{\'e}seaux sociaux, du grand public qui proposent des situations souvent incongrues, dans lesquelles l'eau remonte une cascade, les personnes volent dans les airs ou des serpents se mettent {\`a} tourner. Au-del{\`a} de leur ind{\'e}niable cot{\'e} ludique, ces illusions nous apprennent beaucoup sur le fonctionnement du cerveau, notamment quand celles-ci se transforment en hallucinations visuelles, d{\'e}passant ainsi les limites des capacit{\'e}s de notre perception. En tant que chercheur en Neurosciences {\`a} l'Institut de Neurosciences de la Timone {\`a} Marseille, je vous d{\'e}voilerai des aspects du fonctionnement du cerveau qui sont souvent m{\'e}connus. En particulier, nous verrons pourquoi un magicien peut tromper nos sens ou comment des objets peuvent voyager dans le temps. Surtout nous essaierons de comprendre le fonctionnement de notre perception visuelle sur les bases d'une th{\'e}orie de la vision non pas comme une simple cam{\'e}ra qui enregistre des images mais comme un processus actif en relation avec le monde qui nous entoure.},
	Author = {Laurent Perrinet},
	Booktitle = {JNLF 2019},
	Date-Modified = {2019-02-22 22:22:33 +0100},
	Event_Url = {https://www.jnlf.fr/agenda/jnlf-lille-2019},
	Location = {Lille, France},
	Note = {Summary: Mieux comprendre la fonction de la perception visuelle en explorant certaines limites; Mieux comprendre l'importance de l'aspect dynamique de la perception; Mieux comprendre le r{\^o}le de l'action dans la perception.},
	Projects = {anr-horizontal-v1},
	Time_Start = {2019-04-18T13:00:00},
	Title = {Des illusions aux hallucinations visuelles: une porte sur la perception},
	Url = {https://laurentperrinet.github.io/talk/2019-04-18_jnlf},
	Url_Code = {https://github.com/laurentperrinet/2019-01-14_LACONEU},
	Url_Slides = {https://laurentperrinet.github.io/2019-01-14_LACONEU},
	Year = {2019},
	Bdsk-Url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2019-01-14_LACONEU}}

@inproceedings{2019-01-14_LACONEU,
	Author = {Laurent Perrinet},
	Booktitle = {LACONEU 2019: 5th Latin-American Summer School in Computational Neuroscience, Valparaiso (Chile)},
	Note = {What:: talk @ the [[http://www.laconeu.cl|LACONEU 2019: 5th Latin-American Summer School in Computational Neuroscience]] Who:: Laurent Perrinet, INT When:: 14/1/2019 Where:: Valparaiso (Chile)},
	Title = {Modelling spiking neural networks using {Brian}, Nest and {pyNN}},
	Url = {http://invibe.net/LaurentPerrinet/Presentations/2019-01-14_LACONEU},
	Url_Code = {https://github.com/laurentperrinet/2019-01-14_LACONEU},
	Url_Slides = {https://laurentperrinet.github.io/2019-01-14_LACONEU},
	Year = {2019},
	Bdsk-Url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2019-01-14_LACONEU}}

@inproceedings{2011-07-02_NeuroMedTalk,
	Abstract = {Sensory informations such as visual images are inherently variable. We use probabilistic models to describe how the low-level visual system could describe superposed and ambiguous information. This allows to describe the interactions of neighboring populations of neurons as inference rules that dynamically build up the overall description of the visual scene. We focus here on temporal prediction, that is by the transport of information based on an estimate of local motion in the image.},
	Author = {Perrinet, Laurent},
	Booktitle = {Atelier Neurosciences Computationnelles, 2-3 Juillet 2011 Khemisset, Maroc},
	Keywords = {Neurosciences Computationnelles, mod{\`e}le Bay{\'e}sien, mouvements oculaires, perception du mouvement, champ neural, Navier-Stokes, filtre particulaire, propri{\'e}t{\'e}s {\'e}mergentes.},
	Note = {= * La finalit{\'e} de cette manifestation est de permettre {\`a} nos chercheurs de se r{\'e}unir en groupes de travail et en ateliers afin de d{\'e}couvrir la th{\'e}matique des neurosciences et son interdisciplinarit{\'e}. La manifestation se tient dans le cadre des activit{\'e}s du laboratoire LAMS, de ABC MATHINFO, du GDRI NeurO et du r{\'e}seau m{\'e}diterran{\'e}en [[http://www.neuromedproject.eu/|NeuroMed]]. ## * une manifestation sponsoris{\'e}e par le projet [[http://www.neuromedproject.eu/|NeuroMed]] * t{\'e}l{\'e}chargez la [[attachment:perrinet11khemisset.pdf|pr{\'e}sentation|&do=get]] (150 Mo with movies) * ou un [[Publications/Khoei10tauc|poster]] * en savoir plus : * sur la [[MotionPerception| perception du mouvement]] * sur la [[MotionParticles| solution particulaire]] ##||<width="50%"> {{attachment:sequence_DCBAline.gif||width=30%}}|| ##||<width="50%"> {{attachment:sequence_ABCDline.gif||width=30%}}|| ##|||| '''A predictive sequence is essential in resolving the aperture problem.''' ''(Top)'' In order to demonstrate that, I show in this sequence different apertures; for the aperture problem, motions are segregated (appear to be part of different objects) and still appear to be diagonal. ''(Right)'' However, if the same apertures are arranged in an order which is compatible with a predictive sequence, the horizontal motion appears as the most probable: prediction rotates the perception of the direction... ||},
	Title = {Propri{\'e}t{\'e}s {\'e}mergentes d'un mod{\`e}le de pr{\'e}diction probabiliste utilisant un champ neural},
	Url = {http://invibe.net/LaurentPerrinet/Presentations/2011-07-02_NeuroMedTalk},
	Year = {2011},
	Bdsk-Url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2011-07-02_NeuroMedTalk}}

@inproceedings{2016-10-26_FillatreBarlaudPerrinet16EUVIP,
	Author = {Lionel Fillatre and Michel Barlaud and Perrinet, Laurent U.},
	Booktitle = {EUVIP (Special Session): Biologically Inspired Computer Vision - October 16th, 2016},
	Note = {= ||<tablestyle="width: 96%; float: center; margin-left:20px; margin-right:20px; border-style: 0px; font-size: 10pt;">{{attachment:Publications/CristobalPerrinetKeil15bicv/1412243631.jpg|Compound eyes''|width="100%"}}|| Date:: October 26th, 2016 Location:: Ecole Centrale Marseille Slides:: see [[https://laurentperrinet.github.io/sciblog/files/2016-10-26_FillatreBarlaudPerrinet16EUVIP_talk.html|online]] Special Session:: [[Events/2016-10-26_EUVIP_BICV|Biologically Inspired Computer Vision]]},
	Title = {Categorization of microscopy images using a biologically inspired edge co-occurrences descriptor},
	Url = {http://invibe.net/LaurentPerrinet/Presentations/2016-10-26_FillatreBarlaudPerrinet16EUVIP},
	Year = {2016},
	Bdsk-Url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2016-10-26_FillatreBarlaudPerrinet16EUVIP}}

@inproceedings{2017-01-20_LACONEU,
	Author = {Perrinet, Laurent U.},
	Booktitle = {LACONEU2017: 4th Latin-American Summer School in Computational Neuroscience},
	Note = {Time:: January 20th, 2017 - 10:45 - 11:45 Location:: LACONEU2017: 4th Latin-American Summer School in Computational Neuroscience: http://www.laconeu.cl Slides:: https://laurentperrinet.github.io/sciblog/files/2017-01-20_LACONEU.html},
	Title = {Tutorial: Active inference for eye movements: Bayesian methods, neural inference, dynamics},
	Url = {http://invibe.net/LaurentPerrinet/Presentations/2017-01-20_LACONEU},
	Year = {2017},
	Bdsk-Url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2017-01-20_LACONEU}}

@inproceedings{2006_neurocomp,
	Abstract = {The quality of the representation of an object's motion is limited
by the noise in the sensory input as well as by an intrinsic ambiguity
due to the spatial limi- tation of the visual motion analyzers (aperture
prob- lem). Perceptual and oculomotor data demonstrate that motion
processing of extended ob jects is initially dominated by the local
1D motion cues orthogonal to the ob ject's edges, whereas 2D information
takes pro- gressively over and leads to the final correct represen-
tation of global motion. A Bayesian framework ac- counting for the
sensory noise and general expectancies for ob ject velocities has
proven successful in explaining several experimental findings concerning
early motion processing [1, 2, 3]. However, a complete functional
model, encompassing the dynamical evolution of ob- ject motion perception
is still lacking. Here we outline several experimental observations
concerning human smooth pursuit of moving ob jects and more particu-
larly the time course of its initiation phase. In addi- tion, we
propose a recursive extension of the Bayesian model, motivated and
constrained by our oculomotor data, to describe the dynamical integration
of 1D and 2D motion information. },
	Author = {Perrinet, Laurent and Barth{\'e}lemy, Fr{\'e}d{\'e}ric V. and Masson, Guillaume S.},
	Booktitle = {1{\`e}re conf{\'e}rence francophone NEUROsciences COMPutationnelles - NeuroComp},
	Keywords = {Object motion, Aperture problem, Smooth pursuit eye movement, Bayesian model, recursive inference, Temporal evolution.},
	Note = {## from . Follows [[Publications/Perrinet06fens]] . See also [[Publications/Perrinet07neurocomp]] and [[Publications/Perrinet08areadne]]},
	Rating = {5},
	Title = {Input-output transformation in the visuo-oculomotor loop: modeling the ocular following response to center-surround stimulation in a probabilistic framework},
	Topic = {edge},
	Url = {http://invibe.net/LaurentPerrinet/Presentations/2006_neurocomp},
	Year = {2006},
	Bdsk-Url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2006_neurocomp}}

@inproceedings{2010-12-17_TaucTalk,
	Abstract = {Sensory informations such as visual images are inherently variable. We use probabilistic models to describe how the low-level visual system could describe superposed and ambiguous information. This allows to describe the interactions of neighboring populations of neurons as inference rules that dynamically build up the overall description of the visual scene. We focus here on temporal prediction, that is by the transport of information based on an estimate of local motion in the image.},
	Author = {Perrinet, Laurent},
	Booktitle = {LADISLAV TAUC & GDR MSPC NEUROSCIENCES CONFERENCE, From Mathematical Image Analysis to Neurogeometry of the Brain},
	Keywords = {Neuronal representation, Bayesian modeling, ocular following response, center-surround stimulation, probabilistic framework, Motion perception, motion-based segmentation, PDE, neural masses, Navier-Stokes, particles, 2D Motion, center-surround integration, divisive normalization.},
	Note = {= * http://www.conftauc.cnrs-gif.fr/programme.php * watch the [[attachment:perrinet10tauc.pdf|presentation|&do=get]] (150 Mo with movies) * see the accompanying [[Publications/Khoei10tauc|poster]] * see this more recent [[Presentations/2012-01-12_VisionAtUcl|talk]] * see more : * on MotionPerception * on MotionParticles ||<width="50%"> {{attachment:sequence_DCBAline.gif||width=100%}}||<width="50%"> {{attachment:sequence_ABCDline.gif||width=100%}}|| |||| '''A predictive sequence is essential in resolving the aperture problem.''' ''(Top)'' In order to demonstrate that, I show in this sequence different apertures; for the aperture problem, motions are segregated (appear to be part of different objects) and still appear to be diagonal. ''(Right)'' However, if the same apertures are arranged in an order which is compatible with a predictive sequence, the horizontal motion appears as the most probable: prediction rotates the perception of the direction... ||},
	Title = {Probabilistic models of the low-level visual system: the role of prediction in detecting motion},
	Url = {http://invibe.net/LaurentPerrinet/Presentations/2010-12-17_TaucTalk},
	Year = {2010},
	Bdsk-Url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2010-12-17_TaucTalk}}

@inproceedings{2019-01-16_LACONEU,
	Author = {Laurent Perrinet, INT},
	Booktitle = {LACONEU 2019: 5th Latin-American Summer School in Computational Neuroscience, Valparaiso (Chile)},
	Note = {What:: talk @ the [[http://www.laconeu.cl|LACONEU 2019: 5th Latin-American Summer School in Computational Neuroscience]] Who:: Laurent Perrinet, INT When:: 16/1/2019 Where:: Valparaiso (Chile) Slides:: https://laurentperrinet.github.io/2019-01-16_LACONEU/ Code:: https://github.com/laurentperrinet/2019-01-16_LACONEU/},
	Title = {Efficient coding of visual information in neural computations},
	Url = {http://invibe.net/LaurentPerrinet/Presentations/2019-01-16_LACONEU},
	Year = {2019},
	Bdsk-Url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2019-01-16_LACONEU}}

@inproceedings{2018-04-05_BCP_talk,
	Author = {Laurent Perrinet and Chlo{\'e} Pasturel and Anna Montagnini, INT},
	Booktitle = {Probabilities and Optimal Inference to Understand the Brain, INT, Marseille (France)},
	Note = {What:: talk @ the [[Events/2018-04-05_OptInferBrainWorkshop|Probabilities and Optimal Inference to Understand the Brain]] Who:: Laurent Perrinet and Chlo{\'e} Pasturel and Anna Montagnini, INT When:: 5/4/2018 Where:: INT, Marseille (France) Slides:: https://laurentperrinet.github.io/2018-04-05_BCP_talk/ Code:: https://github.com/laurentperrinet/2018-04-05_BCP_talk/},
	Title = {Principles and psychophysics of Active Inference in anticipating a dynamic, switching probabilistic bias},
	Url = {http://invibe.net/LaurentPerrinet/Presentations/2018-04-05_BCP_talk},
	Year = {2018},
	Bdsk-Url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2018-04-05_BCP_talk}}

@inproceedings{2010-01-08_facets,
	Author = {Perrinet, Laurent and Guillaume S. Masson},
	Keywords = {Neuronal representation, bayesian modeling, ocular following response, center-surround stimulation, probabilistic framework, Motion perception, motion-based segmentation, PDE, neural masses, Navier-Stokes, particles, 2D Motion, center-surround integration, divisive normalization.},
	Note = {* see this more recent [[Presentations/2012-01-12_VisionAtUcl|talk]] * see more : * on MotionPerception * on MotionParticles * watch the [[attachment:perrinet10facets_talk.pdf|presentation|&do=get]]},
	Title = {Models of low-level vision: linking probabilistic models and neural masses},
	Url = {http://invibe.net/LaurentPerrinet/Presentations/2010-01-08_facets},
	Year = {2010},
	Bdsk-Url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2010-01-08_facets}}

@inproceedings{2007-12_rankprize,
	Author = {Perrinet, Laurent},
	Booktitle = {The Rank Prize Funds, Mini-Symposium on Representations of the Visual World in the Brain},
	Note = {* see SparseHebbianLearning * watch the [[attachment:perrinet07rankprize.pdf|presentation]]},
	Title = {What efficient code for adaptive spiking representations?},
	Url = {http://invibe.net/LaurentPerrinet/Presentations/2007-12_rankprize},
	Year = {2007},
	Bdsk-Url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2007-12_rankprize}}

@inproceedings{2009-11-30_vss,
	Abstract = {Short presentation of a large moving pattern elicits an ocular following response that exhibits many of the properties attributed to low-level motion processing such as spatial and temporal integration, contrast gain control and divisive interaction between competing motions. Similar mechanisms have been demonstrated in V1 cortical activity in response to center-surround gratings patterns measured with real-time optical imaging in awake monkeys (see poster of Reynaud et al., VSS09). Based on a previously developed Bayesian framework, we have developed an optimal statistical decoder of such an observed cortical population activity as recorded by optical imaging. This model aims at characterizing the statistical dependance between early neuronal activity and ocular responses and its performance was analyzed by comparing this neuronal read-out and the actual motor responses on a trial-by-trial basis. First, we show that relative performance of the behavioral contrast response function is similar to the best estimate obtained from the neural activity. In particular, we show that the latency of ocular response increases with low contrast conditions as well as with noisier instances of the behavioral task as decoded by the model. Then, we investigate the temporal dynamics of both neuronal and motor responses and show how motion information as represented by the model is integrated in space to improve population decoding over time. Lastly, we explore how a surrounding velocity non congruous with the central excitation information shunts the ocular response and how it is topographically represented in the cortical activity. Acknowledgement: European integrated project FACETS IST-15879.},
	Author = {Perrinet, Laurent U. and Reynaud, Alexandre and Chavane, Fr{\'e}d{\'e}ric and Masson, Guillaume S.},
	Booktitle = {Macroscopic aspects of neuronal activity: ''Macroscopic models, LFP models and VSD models'' a FACETS workshop in Marseille, Nov. 30th /Dec. 1st},
	Note = {* see previous [[Publications/Perrinet09vss|poster]] <<EmbedObject(perrinet09vsd_talk.pdf,width=100%)>>},
	Title = {Reading out the dynamics of lateral interactions in the primary visual cortex from {VSD} data},
	Url = {http://invibe.net/LaurentPerrinet/Publications/Perrinet09vss},
	Year = {2009},
	Bdsk-Url-1 = {http://invibe.net/LaurentPerrinet/Publications/Perrinet09vss}}

@inproceedings{2013-11-26_BrainScalesDemos,
	Author = {Bernhard Kaplan and Perrinet, Laurent},
	Booktitle = {Demo 1-3: Apparent Motion in V1/ MT/MST: Neural Implementation of Probabilistic Approaches},
	Note = {* Together with Bernhard Kaplan, we talked about how we aim at "compiling" a predictive motion-based approach as a spiking neural networks and then as a parallel wafer systems in the BrainscaleS project (Demo 1, Task4). * [[attachment:KaplanPerrinet13brainscales_talk.pdf|slides]] * (private to the consortium: [[https://brainscales.kip.uni-heidelberg.de/internal/jss/AttendMeeting?m=showMeetingInfoPage&meetingID=52|meeting info]] &[[https://brainscales.kip.uni-heidelberg.de/internal/jss/AttendMeeting?m=showAgenda&meetingID=52|Agenda]], including copies of the slides)},
	Title = {Demo 1, Task4: Implementation of models showing emergence of cortical fields and maps},
	Url = {http://invibe.net/LaurentPerrinet/Presentations/2013-11-26_BrainScalesDemos},
	Year = {2013},
	Bdsk-Url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2013-11-26_BrainScalesDemos}}

@inproceedings{2012-01-27_FIL,
	Abstract = {Moving objects generate sensory information that may be noisy and ambiguous, yet it is important to be able to reconstruct object speed as fast as possible. One unsolved question is to understand how the brain pools motion information to give an efficient response. I will present computational models of motion detection in the visual system that try to answer this question. First, sensory information is grabbed by pooling the information from different sensory neurons. This pooling is modulated by the precision of information and we will present some recent model-based behavioural results. Then I will focus on a novel model of motion-based prediction that allows to track objects on smooth trajectories. This model gives an economical description of neural mechanisms associated with the processing underlying motion detection. Finally, we will propose an exploratory hypothesis such that eye movements may be understood as the prospective response to this dynamical sensory response knowing oculomotor constraints such as delays. This line of research aims at showing that through the convergent use of models, electrophysiology or behavioural responses, the study of motion detection is an essential tool in our understanding of neural computations.},
	Author = {Perrinet, Laurent U.},
	Booktitle = {Brain meeting at FIL, London - Friday, January 27th, 2012},
	Keywords = {eye movements, motion detection, probabilistic representation, predictive coding, temporal delays, free-energy},
	Note = {= Time:: Jan 27, 2012, from 16:15 am to 17:00 pm Location:: Seminar room @ FIL, Queen's square, 4th floor.},
	Title = {Grabbing, tracking and sniffing as models for motion detection and eye movements},
	Url = {Presentations/2012-01-27_FIL},
	Year = {2012},
	Bdsk-Url-1 = {Presentations/2012-01-27_FIL}}

@inproceedings{2018-02-01_BCP_INVIBE_fest,
	Author = {Laurent Perrinet and Chlo{\'e} Pasturel and Anna Montagnini},
	Booktitle = {Visual motion Fest - Invibe Team -- INT / Marseille February 1 & 2, 2018},
	Note = {Quoi:: Visual motion Fest - Invibe Team -- INT / Marseille February 1 & 2, 2018 Quand:: 1/2/2018 O{\`u}:: INT Support visuel:: https://laurentperrinet.github.io/sciblog/files/2018-02-01_BCP_INVIBE_fest.html},
	Title = {Estimating and anticipating a dynamic probabilistic bias in visual motion direction},
	Url = {http://invibe.net/LaurentPerrinet/Presentations/2018-02-01_BCP_INVIBE_fest},
	Year = {2018},
	Bdsk-Url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2018-02-01_BCP_INVIBE_fest}}

@inproceedings{2017-11-24_NeurosciencesRobotique,
	Author = {Boutin, Victor and Ruffier, Franck and Perrinet, Laurent U.},
	Booktitle = {Journee du GT 8 (Neurosciences - Robotique)},
	Note = {## {{http://www.laconeu.cl/images/Afiche_Workshop.jpg||align=right,width=50%}} Time:: November 24th, 2017 Venue:: Journee du GT 8 (Neurosciences - Robotique) Location:: IMERA (Aix-Marseille Universit{\'e}) Organisateurs locaux:: Franck Ruffier, St{\'e}phane Viollet (ISM, CNRS - Aix-Marseille Universit{\'e}) Animateurs du GT8:: Alexandre Pitti, Ghil{\`e}s Mostafaoui, Beno{\^\i}t Girard, Mehdi Khamassi Programme:: http://www.isir.upmc.fr/index.php?op=view_page&id=1463&menuid=17},
	Title = {Unsupervised learning applied to robotic vision},
	Url = {http://invibe.net/LaurentPerrinet/Presentations/2017-11-24_NeurosciencesRobotique},
	Year = {2017},
	Bdsk-Url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2017-11-24_NeurosciencesRobotique}}

@inproceedings{2014-03-20_Manchester,
	Abstract = {    The question how the visual system is able to create a coherent representation of a rapidly changing environment in the presence of neural delays is not fully resolved.
In this paper we use an abstract probabilistic framework and a spiking neural network (SNN) implementation to investigate the role of motion-based prediction in estimating motion trajectories with delayed information sampling.
In particular, we investigate how anisotropic diffusion of information may explain the development of anticipatory response in neural populations to an approaching stimulus.
Inspired by a mechanism proposed by Nijhawan [2009], we use a
Bayesian particle filter framework and introduce a diagonal motion-based
prediction model which extrapolates the estimated response to delayed
stimulus in the direction of the trajectory.
In the SNN implementation, we have used anisotropic recurrent connections between excitatory cells as mechanism for motion-extrapolation.
Consistent with recent experimental data collected in extracellular recordings of macaque primary visual cortex [Benvenuti et al 2011], we have simulated different trajectory lengths and have explored how anticipatory response may be dependent to the information accumulated along the trajectory.
We show that both our probabilistic framework and the SNN can replicate the experimental data qualitatively.
Most importantly, we highlight requirements for the development of a trajectory-dependent anticipatory response, and in particular the anisotropic nature of the diagonal motion extrapolation mechanism. },
	Author = {Perrinet, Laurent U. and Bernhard A.~Kaplan and Mina A.~Khoei and Anders Lansner and Guillaume Masson},
	Booktitle = {4th BrainScaleS Plenary meeting - March 20th, 2014},
	Note = {= Time:: From Thu, 20 March 2014 until Fri, 21 March 2014 Location:: in Manchester (UK), get the [[https://brainscales.kip.uni-heidelberg.de/internal/jss/AttendMeeting?m=showAgenda&meetingID=45|program (internal link)]] Slides:: [[attachment:14-03-20_BK_LP_MK_talk.pdf|slides]], [[attachment:14-03-20_BK_LP_MK_handout.pdf|slides with notes]]},
	Title = {WP5 - Demo 1.3 : Spiking model of motion-based prediction},
	Url = {http://invibe.net/LaurentPerrinet/Presentations/2014-03-20_Manchester},
	Year = {2014},
	Bdsk-Url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2014-03-20_Manchester}}

@inproceedings{2009-04_INT,
	Abstract = {
Moving the eyes rapidly to track a visual object moving in a cluttered environment is an essential
function. However, doing so rapidly and efficiently is constrained by a number of noise sources in the
visual system and by the fact that information is collected locally before giving raise to a global signal.
After reviewing some results made in the modeling of low-level sensory areas, I will expose a method
to decode low-level neural information as describing visual information using a probabilistic
representation. Decisions will therefore correspond to statistical inferences which are dynamically
resolving the veridical speed of a moving object. We will illustrate this method by showing how
ambiguous local information can be merged to give raise to a global response which resolves the
aperture problem. Using this theoretical approach "in computo", we will illustrate how we may better
understand results which are observed "in vivo" (optical imaging) as a neural code linking actively
sensation and behavior. },
	Author = {Perrinet, Laurent and Guillaume S. Masson},
	Note = {* see more : * on MotionPerception * in [[Publications/Perrinet08areadne]] and [[Publications/Perrinet09cosyne]] * watch the [[attachment:perrinet09int.pdf|presentation|&do=get]] * LaTeX source code for the presentation: [[attachment:perrinet09int.tex||&do=get]], [[attachment:Context.tex||&do=get]], [[attachment:Motion.tex||&do=get]], [[attachment:Annex.tex||&do=get]] and glued by a [[attachment:Makefile||&do=get]]},
	Title = {Decoding low-level neural information to track visual motion},
	Url = {http://invibe.net/LaurentPerrinet/Presentations/09-04_INT},
	Year = {2009},
	Bdsk-Url-1 = {http://invibe.net/LaurentPerrinet/Presentations/09-04_INT}}

@inproceedings{2013-07-05_Cerco,
	Author = {Perrinet, Laurent and David Fitzpatrick and Bednar, James A.},
	Booktitle = {A seminar at the CerCo, Toulouse, France},
	Note = {= Time:: July 5th, 2013 Location:: !CerCo, Toulouse URL:: http://20anscerco.ups-tlse.fr/Programme%2020%20ans.pdf See also:: Talk on [[Presentations/2012-01-24_Edinburgh|edge statistics in natural images]] at ANC (Edinburgh) on Thursday, January 24th, 2012. Slides:: [[attachment:perrinet13cerco.pdf|slides]] - [[attachment:perrinet13cerco_notes.pdf|slides with notes]] ##See also:: [[Publications/Perrinet11sfn|related work]]},
	Title = {Edge co-occurrences and categorizing natural images},
	Url = {http://invibe.net/cgi-bin/index.cgi/Presentations/2013-07-05_Cerco},
	Year = {2013},
	Bdsk-Url-1 = {http://invibe.net/cgi-bin/index.cgi/Presentations/2013-07-05_Cerco}}

@inproceedings{2008-04_incm,
	Abstract = {Computational Neuroscience is a synthetic, inter-disciplinary approach aiming at
understanding cognition by analyzing the mechanisms underlying neural computations. We
present in this seminar our attempt in modeling low-level vision by bridging different
integration levels, from neural spiking activity to behavior. At the behavioral level, the Ocular
Following Response recorded in the laboratory reveals how the brain may integrate local
information (moving images on visual receptive fields) to produce a single behavioral
response (the movement of the eye). Using a probabilistic representation, we provide a
simple integrative mechanism that gives the ''ideal'' response to possibly noisy and
ambiguous information, similarly to a Bayesian approach. This fits well the performance
revealed by behavioral data and may act as a generic cortical ''module''. At the population
level, these mechanisms may indeed be implemented for the coding of natural images and
we will show the particular importance of spiking representations and lateral interactions for
efficient and rapid responses. In particular, we will present an original unsupervised learning
algorithm that we applied to a model of the primary visual cortex. Finally, at the neuronal
level, I will present work done in the team showing how certain mechanisms at the level of
the synapse and of the neuron are essential at the population level and how we may
understand these mechanisms at the population level. This illustrates the importance of
dynamical processes, distributed activity and recurrent connections to produce a cortical gain
control mechanism. As a conclusion, this approach provides useful applications for image
processing and possible valorization in future computer architectures. More generally, it
proves that the use of a probabilistic representation is a particularly efficient method for
bridging biological versus computational neuroscience and illustrates the advantage of such
an interdisciplinary approach.},
	Author = {Perrinet, Laurent},
	Booktitle = {S{\'e}minaires de l'INCM, April 11th, 2008},
	Title = {From neural activity to behavior: computational neuroscience as a synthetic approach for understanding the neural code.},
	Url = {http://invibe.net/LaurentPerrinet/Presentations/2008-04_incm},
	Year = {2008},
	Bdsk-Url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2008-04_incm}}

@inproceedings{2015-10-07_GDR-BioComp,
	Abstract = {

We stand at a point in history where our phones have become smart but
lack a feature which prevails in most forms of living intelligence:
vision. The ability to see is indeed an essential facet of intelligence
which is developed in an autonomous manner even in young human infants.
I will focus here on a particular problem: how do we estimate motion in
a visual image? I will explain why for this problem, it is crucial to
understand how the visual system might overcome temporal delays and will
demonstrate at different levels of description ---from probabilistic
models to neuromorphic hardware---  a surprising solution: The visual
system models the world and uses the eye to probe this model},
	Author = {Perrinet, Laurent U.},
	Booktitle = {First GDR BioComp workshop, Saint-Paul de Vence, October 7th, 2015},
	Note = {= ||<tablestyle="width: 38%; float: right; margin-left:20px; margin-right:20px; border-style: 0px; font-size: 8pt;">{{attachment:2015-10-07_Perrinet15biocomp.png|First GDR BioComp workshop, Saint-Paul de Vence |width="100%"}}|| Time:: October 7th, 2015 Location:: http://gdr-biocomp.fr/colloque/ Slides:: [[attachment:Perrinet15biocomp_slides.pdf|slides]]},
	Title = {Motion-based prediction with neuromorphic hardware},
	Url = {http://invibe.net/LaurentPerrinet/Presentations/2015-10-07_GDR-BioComp},
	Year = {2015},
	Bdsk-Url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2015-10-07_GDR-BioComp}}

@inproceedings{2008-06_Ulm,
	Abstract = {The machinery behind the visual perception of motion and the subsequent
sensorimotor transformation, such as in Ocular Following Response (OFR),
is confronted to uncertainties which are efficiently resolved in the
primate's visual system. We may understand this response as an ideal
observer in a probabilistic framework by using Bayesian theory (Weiss et
al., 2002) which we previously proved to be successfully adapted to
model the OFR for different levels of noise with full field gratings or
with disk of various sizes and the effect of a flickering surround
(Perrinet and Masson, 2007).
More recent experiments of OFR have used disk gratings and bipartite
stimuli which are optimized to study the dynamics of center-surround
integration. We quantified two main characteristics of the global
spatial integration of motion from an intermediate map of possible local
translation velocities: (i) a finite optimal stimulus size for driving
OFR, surrounded by an antagonistic modulation and (ii) a direction
selective suppressive effect of the surround on the contrast gain
control of the central stimuli (Barthelemy et al., 2006, 2007).
Herein, we extended in the dynamical domain the ideal observer model to
simulate the spatial integration of the different local motion cues
within a probabilistic representation. We present analytical results
which show that the hypothesis of independence of local measures can
describe the initial segment of spatial integration of motion signal.
Within this framework, we successfully accounted for the dynamical
contrast gain control mechanisms observed in the behavioral data for
center-surround stimuli. However, another inhibitory mechanism had to be
added to account for suppressive effects of the surround. We explore
here an hypothesis where this could be understood as the effect of a
recurrent integration of information in the velocity map.

F. Barthelemy, L. U. Perrinet, E. Castet, and G. S. Masson. Dynamics of
distributed 1D and 2D motion representations for short-latency ocular
following. Vision Research, 48(4):501--22, feb 2007. doi:
10.1016/j.visres.2007.10.020.

F. V. Barthelemy, I. Vanzetta, and G. S. Masson. Behavioral receptive
field for ocular following in humans: Dynamics of spatial summation and
center-surround interactions. Journal of Neurophysiology,
(95):3712--26, Mar 2006. doi: 10.1152/jn.00112.2006.

L. U. Perrinet and G. S. Masson. Modeling spatial integration in the
ocular following response using a probabilistic framework. Journal of
Physiology (Paris), 2007. doi: 10.1016/j.jphysparis.2007.10.011.

Y. Weiss, E. P. Simoncelli, and E. H. Adelson. Motion illusions as
optimal percepts. Nature Neuroscience, 5(6):598--604, Jun 2002. doi:
10.1038/nn858.
},
	Author = {Perrinet, Laurent and Guillaume S. Masson},
	Note = {* see more : * on MotionPerception * in [[Publications/Perrinet08areadne]] * watch the [[attachment:perrinet08ulm.pdf|presentation]]},
	Title = {Decoding the population dynamics underlying ocular following response using a probabilistic framework},
	Url = {http://invibe.net/LaurentPerrinet/Presentations/2008-06_Ulm},
	Year = {2008},
	Bdsk-Url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2008-06_Ulm}}

@inproceedings{2019-01-17_LACONEU,
	Author = {Laurent Perrinet, INT},
	Booktitle = {LACONEU 2019: 5th Latin-American Summer School in Computational Neuroscience, Valparaiso (Chile)},
	Note = {What:: talk @ the [[http://www.laconeu.cl|LACONEU 2019: 5th Latin-American Summer School in Computational Neuroscience]] Who:: Laurent Perrinet, INT When:: 17/1/2019 Where:: Valparaiso (Chile) Slides:: https://laurentperrinet.github.io/2019-01-17_LACONEU/ Code:: https://github.com/laurentperrinet/2019-01-17_LACONEU/},
	Title = {Role of dynamics in neural computations underlying visual processing},
	Url = {http://invibe.net/LaurentPerrinet/Presentations/2019-01-17_LACONEU},
	Year = {2019},
	Bdsk-Url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2019-01-17_LACONEU}}

@inproceedings{2018-04-05_ActiveInference,
	Author = {Laurent Perrinet and Chlo{\'e} Pasturel and Anna Montagnini, INT},
	Booktitle = {Probabilities and Optimal Inference to Understand the Brain, INT, Marseille (France)},
	Note = {Quoi:: [[https://opt-infer-brain.sciencesconf.org/|Probabilities and Optimal Inference to Understand the Brain]] Qui:: Laurent Perrinet and Chlo{\'e} Pasturel and Anna Montagnini, INT Quand:: 5/4/2018 O{\`u}:: INT, Marseille (France) Support visuel:: https://laurentperrinet.github.io/sciblog/files/2018-04-05_BCP_talk.html},
	Title = {Principles and psychophysics of Active Inference},
	Url = {http://invibe.net/LaurentPerrinet/Presentations/2018-04-05_ActiveInference},
	Year = {2018},
	Bdsk-Url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2018-04-05_ActiveInference}}

@inproceedings{2012-01-12_VisionAtUcl,
	Abstract = {In low-level sensory systems, it is still unclear how the noisy information collected locally by neurons may give rise to a coherent global percept. This is well demonstrated for the detection of motion in the aperture problem: as luminance of an elongated line is symmetrical along its axis, tangential velocity is ambiguous when measured locally. Here, we develop the hypothesis that motion-based predictive coding is sufficient to infer global motion. Our implementation is based on a context-dependent diffusion of a probabilistic representation of motion. We observe in simulations a progressive solution to the aperture problem similar to psychophysics and behavior. We demonstrate that this solution is the result of  two underlying mechanisms. First, we demonstrate the formation of a tracking behavior favoring temporally coherent features independently of their texture. Second, we observe that incoherent features are explained away while coherent information diffuses progressively to the global scale. Most previous models included ad-hoc mechanisms such as end-stopped cells or a selection layer to track specific luminance-based features. Here, we have proved that motion-based predictive coding, as it is  implemented in this functional model, is sufficient to solve the aperture problem. This simpler solution may give insights in the role of prediction underlying a large class of sensory computations.  },
	Author = {Perrinet, Laurent},
	Booktitle = {Vision@UCL seminar - Thursday, 12th January, 5pm},
	Keywords = {Neuronal representation, Bayesian modeling, ocular following response, center-surround stimulation, probabilistic framework, Motion perception, motion-based segmentation, PDE, neural masses, Navier-Stokes, particles, 2D Motion, center-surround integration, divisive normalization.},
	Note = {= Time:: Thursday, 12th January, 5pm Location:: [[http://maps.google.com/maps?q=Engineering+Building,+London,+United+Kingdom&hl=en&sll=51.521909,-0.13072&sspn=0.005748,0.014752&vpsrc=0&hq=Engineering+Building,&hnear=London,+United+Kingdom&t=h&z=19&iwloc=A|Malet Place Eng Bldg]] 1.03 (first floor). [[http://crf.casa.ucl.ac.uk/screenRoute.aspx?s=1181&d=105&w=False|Route from Russel square tube station]]. Slides:: [[attachment:perrinet12ucl.pdf|slides]], [[attachment:perrinet12ucl_handout.pdf|slides with notes]] * read more : * Laurent Perrinet, Guillaume S. Masson. '''Motion-based prediction is sufficient to solve the aperture problem.''' ''[[Publications/Perrinet12pred|Neural Computation]]'', 2012. * on MotionPerception * on MotionParticles ||<width="50%"> {{attachment:sequence_DCBA.gif||width=100%}}||<width="50%"> {{attachment:sequence_ABCD.gif||width=100%}}|| |||| '''A predictive sequence is essential in resolving the aperture problem.''' The sequence in which a set of local motion is shown is essential for the detection of global motion. we replicate here the experiments by Scott Watamaniuk and colleagues. They have shown behaviourally that a dot in noise is much more detectable when it follows a coherent trajectory, up to an order of magnitude of 10 times what would be predicted by the local components of the trajectory. ''(Left)'' In this first movie we observe white noise and at first sight, no information is detectable. In fact, there is a dot moving along some smooth linear trajectory, but we broke this trajectory into eight equal parts and shuffled their order in the movie. ''(Right)'' if we re-arrange these local motions to be compatible with a predictive sequence, it is much easier to see the dot (from left to right in the top 25% line of the image, a smooth, slow pursuit helps to catch it). This simple experiment shows that, even if local motion is similar in both movies, a coherent trajectory is more easy to track. Obviously, we may thus conclude that the whole trajectory is more that its individual parts, and that the independence hypothesis does not hold if we want to account for the predictive information in input sequences such as seems to be crucial for the AP. || ## from},
	Title = {Motion-based prediction is sufficient to solve the aperture problem},
	Url = {http://invibe.net/LaurentPerrinet/Presentations/2012-01-12_VisionAtUcl},
	Year = {2012},
	Bdsk-Url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2012-01-12_VisionAtUcl}}

@inproceedings{2007-09_mipm,
	Abstract = {I will illustrate in this talk how computational neuroscience may inspire and be inspired by mathematical image processing. Focusing on efficiently representing natural images in the primary visual cortex, we derive an event-based adaptive algorithm inspired by statistical inference, Matching Pursuit and Hebbian learning. This algorithm allows to learn efficient "edge-like" receptive fields similarly to Independent Components Analysis. The correlation-based inhibition has been shown to be a necessary condition for the fomation of this type of receptive fields and shows the putative functional role of lateral propagation of information in cortical layers. I'll first present state-of-the-art neural algorithms for this task, the results of a detailed analysis of this Sparse Hebbian Learning algorithm and finally draw a comparison with similar strategies.},
	Author = {Perrinet, Laurent},
	Booktitle = {Mathematical image processing meeting (Marseille, France) September 5},
	Date-Added = {2007-10-29 16:22:21 +0100},
	Date-Modified = {2007-10-29 16:36:57 +0100},
	Note = {* [[http://www.math.univ-paris13.fr/~malgouy/MIPM/Abstracts.html#Perrinet|advertisement]]},
	Title = {Neural Codes for Adaptive Sparse Representations of Natural Images},
	Url = {http://invibe.net/LaurentPerrinet/Presentations/2007-09_mipm},
	Year = {2007},
	Bdsk-Url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2007-09_mipm}}

@inproceedings{2016-11-03_SIGMA,
	Author = {Perrinet, Laurent U.},
	Booktitle = {Workshop SIGMA'2016: Signal, Image, Geometry, Modelling, Approximation},
	Note = {Time:: Thursday, November 3rd, 2016 Location:: Signal, Image, Geometry, Modelling, Approximation (SIGMA) https://www.ceremade.dauphine.fr/~peyre/sigma2016/ Slides:: https://laurentperrinet.github.io/sciblog/files/2016-11-03_SIGMA.html (takes a few seconds to load)},
	Title = {The flash-lag effect as a motion-based predictive shift},
	Url = {http://invibe.net/LaurentPerrinet/Presentations/2016-11-03_SIGMA},
	Year = {2016},
	Bdsk-Url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2016-11-03_SIGMA}}

@inproceedings{2012-03-23_Juelich,
	Author = {Perrinet, Laurent U.},
	Booktitle = {2nd BrainScaleS Plenary Meeting - Friday, March 23rd, 2012},
	Note = {= Time:: March 23rd, 2012, from 14:00 am to 14:15 pm Location:: Forschungszentrum J{\"u}lich. Slides:: [[attachment:perrinet12wp5_slides.pdf|slides]], [[attachment:perrinet12wp5_handout.pdf|slides with notes]]},
	Title = {Apparent motion in V1 - Probabilistic approaches},
	Url = {http://invibe.net/LaurentPerrinet/Presentations/2012-03-23_Juelich},
	Year = {2012},
	Bdsk-Url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2012-03-23_Juelich}}

@inproceedings{2017-01-19_LACONEU,
	Author = {Perrinet, Laurent U.},
	Booktitle = {LACONEU2017: 4th Latin-American Summer School in Computational Neuroscience},
	Note = {Time:: January 19th, 2017 - 10:45 - 11:45 Location:: LACONEU2017: 4th Latin-American Summer School in Computational Neuroscience: http://www.laconeu.cl Slides:: https://laurentperrinet.github.io/sciblog/files/2017-01-19_LACONEU.html},
	Title = {Tutorial: Sparse optimization in neural computations},
	Url = {http://invibe.net/LaurentPerrinet/Presentations/2017-01-19_LACONEU},
	Year = {2017},
	Bdsk-Url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2017-01-19_LACONEU}}

@inproceedings{2015-11-05_Chile,
	Abstract = {
We stand at a point in history where our phones have become smart but
lack a feature which prevails in most forms of living intelligence:
vision. The ability to see is indeed an essential facet of intelligence
which is developed in an autonomous manner even in young human infants.
I will focus here on a particular problem: how do we estimate motion in
a visual image? I will explain why for this problem, it is crucial to
understand how the visual system might overcome temporal delays and will
demonstrate at different levels of description ---from probabilistic
models to neuromorphic hardware---  a surprising solution: The visual
system models the world and uses the eye to probe this model},
	Author = {Perrinet, Laurent U.},
	Booktitle = {Universidad T{\'e}cnica Federico Santa Mar{\'\i}a, Valpara{\'\i}so, Chile, November 5th, 2015},
	Note = {= Time:: November 5th, 2015 Location:: http://www.eventos.usm.cl/evento/charla-motion-based-prediction-with-neuromorphic-hardware/ Slides:: [[attachment:Perrinet15chile.pdf|slides]]},
	Title = {Motion-based prediction with neuromorphic hardware},
	Url = {http://invibe.net/LaurentPerrinet/Presentations/2015-11-05_Chile},
	Year = {2015},
	Bdsk-Url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2015-11-05_Chile}}

@inproceedings{2012-03-22_Juelich,
	Author = {Perrinet, Laurent U.},
	Booktitle = {2nd BrainScaleS Plenary Meeting - Friday, March 22nd, 2012},
	Note = {= Time:: March 22nd, 2012, from 14:00 am to 14:15 pm Location:: Forschungszentrum J{\"u}lich. Slides:: [[attachment:perrinet12wp4.pdf|slides]], [[attachment:perrinet12wp4_handout.pdf|slides with notes]]},
	Title = {Motion Clouds: Model-based stimulus synthesis of natural-like random textures for the study of motion perception},
	Url = {http://invibe.net/LaurentPerrinet/Presentations/2012-03-22_Juelich},
	Year = {2012},
	Bdsk-Url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2012-03-22_Juelich}}

@inproceedings{2017-01-18_LACONEU,
	Author = {Perrinet, Laurent U.},
	Booktitle = {Workshop on Computational Neuroscience entitled "New trends and challenges for 2030"},
	Note = {||<tablestyle="width: 50%; float: right; margin-left:20px; margin-right:20px; border-style: 0px;">{{http://laconeu.cl/wp-content/uploads/2018/04/Valparaiso-3.jpg||width=100%}}|| Time:: January 18th, 2017, 09:00- 09:40 Location:: Workshop on Computational Neuroscience entitled [[http://cinv.uv.cl/laconeu-workshop|"New trends and challenges for 2030"]] Slides:: https://laurentperrinet.github.io/sciblog/files/2017-01-18_LACONEU.html},
	Title = {Back to the present: how neurons deal with delays},
	Url = {http://invibe.net/LaurentPerrinet/Presentations/2017-01-18_LACONEU},
	Year = {2017},
	Bdsk-Url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2017-01-18_LACONEU}}

@inproceedings{2011-11-15_sfn,
	Abstract = {Oriented edges in images of natural scenes tend to be aligned in collinear or co-circular arrangements, with lines and smooth curves more common than other possible arrangements of edges (Geisler et al., Vis Res 41:711-24, 2001). The visual system appears to take advantage of this prior information, and human contour detection and grouping performance is well predicted by such an "association field" (Field et al., Vis Res 33:173-93, 1993). One possible candidate substrate for implementing an association field in mammals is the set of long-range lateral connections between neurons in the primary visual cortex (V1), which could act to facilitate detection of contours matching the association field, and/or inhibit detection of other contours (Choe and Miikkulainen, Biol Cyb 90:75-88, 2004). To fill this role, the lateral connections would need to be orientation specific and aligned along contours, and indeed such an arrangement has been found in tree shrew primary visual cortex (Bosking et al., J Neurosci 17:2112-27, 1997). However, it is not yet known whether these patterns develop as a result of visual experience, or are simply hard-wired to be appropriate for the statistics of natural scenes.
To investigate this issue, we examined the properties of the visual environment of laboratory animals, to determine whether the observed connection patterns are more similar to the statistics of the rearing environment or of a natural habitat. Specifically, we analyzed the cooccurence statistics of edge elements in images of natural scenes, and compared them to corresponding statistics for images taken from within the rearing environment of the animals in the Bosking et al. (1997) study. We used a modified version of the algorithm from Geisler et al. (2001), with a more general edge extraction algorithm that uses sparse coding to avoid multiple responses to a single edge. Collinearity and co-circularity results for natural images replicated qualitatively the results from Geisler et al. (2001), confirming that prior information about continuations appeared consistently in natural images. However, we find that the largely man-made environment in which these animals were reared has a significantly higher probability of collinear edge elements. We thus predict that if the lateral connection patterns are due to visual experience, the patterns in wild-raised tree shrews would be very different from those measured by Bosking et al. (1997), with shorter-range correlations and less emphasis on collinear continuations. This prediction can be tested in future experiments on matching groups of animals reared in different environments.



W.H. Bosking and Y. Zhang and B. Schofield and D. Fitzpatrick (1997)
Orientation selectivity and the arrangement of horizontal connections
in tree shrew striate cortex
Journal of Neuroscience  17:2112-27.

E.M. Callaway and L.C. Katz (1990)
Emergence and refinement of clustered horizontal connections in cat striate cortex.
Journal of Neuroscience 10:1134--53.

Y. Choe and R. Miikkulainen (2004)
Contour integration and segmentation with self-organized lateral connections
Biological Cybernetics 90:75-88.

D.J. Field, A. Hayes, and R.F. Hess (1993)
Contour integration by the human visual system: Evidence for a local
"association field",
Vision Research 33:173--93.

W.S. Geisler, J.S. Perry, B.J. Super, and D.P. Gallogly (2001)
Edge co-occurrence in natural images predicts contour grouping performance.
Vision Research 41:711-24.
},
	Author = {Perrinet, Laurent and David Fitzpatrick and Bednar, James A.},
	Booktitle = {Society for Neuroscience Abstracts},
	Editor = {Washington, DC: Society for Neuroscience, www.sfn.org},
	Note = {See also:: Talk on [[Presentations/2012-01-24_Edinburgh|edge statistics in natural images]] at ANC (Edinburgh) on Thursday, January 24th, 2012. * abstract * Abstract Control Number: 17671 * Abstract Title: Edge statistics in natural images versus laboratory animal environments: Implications for understanding lateral connectivity in V1 * Presentation Number: 530.04 * Presentation Time: 8:45am - 9:00am * session: * Session Type: Nanosymposium * Session Number: 530 * Session Title: Development of Motor and Sensory Systems * Date and Time: Tuesday Nov 15, 2011 8:00 AM - 12:00 PM * Location: Walter E. Washington Convention Center:143ABC ||<width="50%"> ''Natural'' ||<width="50%"> ''Laboratory''|| ||<width="50%"> {{attachment:edgestats_vanilla_proba-angle_natural.png||width=100%}}||<width="50%"> {{attachment:edgestats_vanilla_proba-angle_laboratory.png||width=100%}}|| |||| '''Probability distribution function of "chevrons" in natural and laboratory images.''' By computing measures of the independence of the different variables, we found that the probability density function of the second-order statistics of edges factorizes with on one side distance and scale and on the other side the 2 angles. The first component proved to be quite similar across both classes and the greater difference is seen for different angle configuration. As it can be reduced to 2 dimensions, we can plot the full probability as shown here by different contrast values assigned to all possible chevrons configurations, for all possible "azimuth" values $\phi$ on the horizontal axis and difference of orientation $\theta$ on the vertical axis. Such a plot most strikingly shows the difference between these 2 classes. ||},
	Number = {Program No. 530.04},
	Title = {Edge statistics in natural images versus laboratory animal environments: implications for understanding lateral connectivity in {V1}},
	Url = {http://invibe.net/LaurentPerrinet/Presentations/2011-11-15_sfn},
	Year = {2011},
	Bdsk-Url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2011-11-15_sfn}}

@inproceedings{2009-07-18_Kremkow09cnstalk,
	Author = {Kremkow, Jens and Perrinet, Laurent and Monier, Cyril and Fregnac, Yves and Masson, Guillaume S. and Aertsen, Ad},
	Booktitle = {Eighteenth Annual Computational Neuroscience Meeting: CNS*2009 Berlin, Germany. 18--23 July 2009},
	Doi = {doi:10.1186/1471-2202-10-S1-O21},
	Note = {## from},
	Pages = {Oral presentation, 10(Suppl 1):O21},
	Title = {Control of the temporal interplay between excitation and inhibition by the statistics of visual input},
	Url = {http://invibe.net/LaurentPerrinet/Publications/Kremkow09cnstalk},
	Year = {2009},
	Bdsk-Url-1 = {http://invibe.net/LaurentPerrinet/Publications/Kremkow09cnstalk},
	Bdsk-Url-2 = {https://doi.org/10.1186/1471-2202-10-S1-O21}}

@inproceedings{2012-05-10_itwist,
	Abstract = {Oriented edges in images of natural scenes tend to be aligned in collinear or co-circular arrangements, with lines and smooth curves more common than other possible arrangements of edges (Geisler et al., Vis Res 41:711-24, 2001). The visual system appears to take advantage of this prior information, and human contour detection and grouping performance is well predicted by such an "association field" (Field et al., Vis Res 33:173-93, 1993). One possible candidate substrate for implementing an association field in mammals is the set of long-range lateral connections between neurons in the primary visual cortex (V1), which could act to facilitate detection of contours matching the association field, and/or inhibit detection of other contours (Choe and Miikkulainen, Biol Cyb 90:75-88, 2004). To fill this role, the lateral connections would need to be orientation specific and aligned along contours, and indeed such an arrangement has been found in tree shrew primary visual cortex (Bosking et al., J Neurosci 17:2112-27, 1997). However, it is not yet known whether these patterns develop as a result of visual experience, or are simply hard-wired to be appropriate for the statistics of natural scenes.
To investigate this issue, we examined the properties of the visual environment of laboratory animals, to determine whether the observed connection patterns are more similar to the statistics of the rearing environment or of a natural habitat. Specifically, we analyzed the cooccurence statistics of edge elements in images of natural scenes, and compared them to corresponding statistics for images taken from within the rearing environment of the animals in the Bosking et al. (1997) study. We used a modified version of the algorithm from Geisler et al. (2001), with a more general edge extraction algorithm that uses sparse coding to avoid multiple responses to a single edge. Collinearity and co-circularity results for natural images replicated qualitatively the results from Geisler et al. (2001), confirming that prior information about continuations appeared consistently in natural images. However, we find that the largely man-made environment in which these animals were reared has a significantly higher probability of collinear edge elements. We thus predict that if the lateral connection patterns are due to visual experience, the patterns in wild-raised tree shrews would be very different from those measured by Bosking et al. (1997), with shorter-range correlations and less emphasis on collinear continuations. This prediction can be tested in future experiments on matching groups of animals reared in different environments.



W.H. Bosking and Y. Zhang and B. Schofield and D. Fitzpatrick (1997)
Orientation selectivity and the arrangement of horizontal connections
in tree shrew striate cortex
Journal of Neuroscience  17:2112-27.

E.M. Callaway and L.C. Katz (1990)
Emergence and refinement of clustered horizontal connections in cat striate cortex.
Journal of Neuroscience 10:1134--53.

Y. Choe and R. Miikkulainen (2004)
Contour integration and segmentation with self-organized lateral connections
Biological Cybernetics 90:75-88.

D.J. Field, A. Hayes, and R.F. Hess (1993)
Contour integration by the human visual system: Evidence for a local
"association field",
Vision Research 33:173--93.

W.S. Geisler, J.S. Perry, B.J. Super, and D.P. Gallogly (2001)
Edge co-occurrence in natural images predicts contour grouping performance.
Vision Research 41:711-24.
},
	Author = {Perrinet, Laurent and David Fitzpatrick and Bednar, James A.},
	Booktitle = {iTWIST '12 workshop},
	Note = {This poster was presented at the [[https://sites.google.com/site/itwist1st/home|first i-TWIST workshop]]. See also:: Talk [[Presentations/Perrinet11sfn|at Sfn (Washington) in November 2011]] or [[Presentations/2012-01-24_Edinburgh|at ANC (Edinburgh) on Thursday, January 24th, 2012]]. Slides:: [[attachment:Perrinet12itwist.pdf|slides]] ||<width="50%"> ''Natural'' ||<width="50%"> ''Laboratory''|| ||<width="50%"> {{attachment:edgestats_vanilla_proba-angle_natural.png||width=100%}}||<width="50%"> {{attachment:edgestats_vanilla_proba-angle_laboratory.png||width=100%}}|| |||| '''Probability distribution function of "chevrons" in natural and laboratory images.''' By computing measures of the independence of the different variables, we found that the probability density function of the second-order statistics of edges factorizes with on one side distance and scale and on the other side the 2 angles. The first component proved to be quite similar across both classes and the greater difference is seen for different angle configuration. As it can be reduced to 2 dimensions, we can plot the full probability as shown here by different contrast values assigned to all possible chevrons configurations, for all possible "azimuth" values $\phi$ on the horizontal axis and difference of orientation $\theta$ on the vertical axis. Such a plot most strikingly shows the difference between these 2 classes. ||},
	Title = {Edge statistics in natural images versus laboratory animal environments: implications for understanding lateral connectivity in {V1}},
	Url = {http://invibe.net/LaurentPerrinet/Presentations/2012-05-10_itwist},
	Year = {2012},
	Bdsk-Url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2012-05-10_itwist}}

@inproceedings{2017-06-28_Telluride,
	Author = {Perrinet, Laurent U.},
	Booktitle = {Workshop on Computational Neuroscience entitled "New trends and challenges for 2030"},
	Note = {## {{http://www.laconeu.cl/images/Afiche_Workshop.jpg||align=right,width=50%}} Time:: June 28th, 2017 Location:: Workshop on Computational Neuroscience entitled [[http://telluride.iniforum.ch/2017/workgroups/neuromorphic-event-based-compound-eyes-and-vision/|Neuromorphic Event-based Compound Eyes and Vision"]] Slides:: https://laurentperrinet.github.io/sciblog/files/2017-06-28_Telluride.html},
	Title = {Back to the present: dealing with delays in biological and neuromorphic systems},
	Url = {http://invibe.net/LaurentPerrinet/Presentations/2017-06-28_Telluride},
	Year = {2017},
	Bdsk-Url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2017-06-28_Telluride}}

@inproceedings{2016-07-07_EDP-proba,
	Author = {Perrinet, Laurent U.},
	Booktitle = {Summer School: PDE and Probability for Life Sciences @ CIRM, Marseille - http://scientific-events.weebly.com/prog-1426.html - CIRM, July 7th, 2016},
	Note = {Time:: July 7th, 2016 Location:: Summer School: PDE and Probability for Life Sciences @ CIRM, Marseille - http://scientific-events.weebly.com/prog-1426.html Slides:: https://laurentperrinet.github.io/sciblog/files/2016-07-07_EDP-proba},
	Title = {Modelling the dynamics of cognitive processes: from the Bayesian brain to particles},
	Url = {http://invibe.net/LaurentPerrinet/Presentations/2016-07-07_EDP-proba},
	Year = {2016},
	Bdsk-Url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2016-07-07_EDP-proba}}

@inproceedings{2011-10-05_BrainScalesESS,
	Author = {Perrinet, Laurent},
	Booktitle = {Using the ESS + Neuromorphic hardware Workshop,5th Oktober, 2011 at TU Dresden, Germany},
	Note = {* Here, I talk about how we aim at "compiling" such models as neural networks and as parallel wafer systems in the BrainscaleS project (Demo 1, Task4). (1) I give 3 examples of models (Bayesian or neural) and how we may translate them in a pyNN + ESS compatible implementation (2) we will show how these can be validated by behavioral data collected at the lab but also do some predictions. * [[attachment:perrinet11brainscales_talk.pdf|slides]] * (private to the consortium: [[https://brainscales.kip.uni-heidelberg.de/internal/jss/AttendMeeting?m=showMeetingInfoPage&meetingID=15|meeting info]] &[[https://brainscales.kip.uni-heidelberg.de/internal/jss/AttendMeeting?m=showAgenda&meetingID=15|Agenda]], including copies of the slides)},
	Title = {Demo 1, Task4: Implementation of models showing emergence of cortical fields and maps},
	Url = {http://invibe.net/LaurentPerrinet/Presentations/2011-10-05_BrainScalesESS},
	Year = {2011},
	Bdsk-Url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2011-10-05_BrainScalesESS}}

@inproceedings{2011-09-28_ermites,
	Abstract = {Oriented edges in images of natural scenes tend to be aligned in collinear or co-circular arrangements, with lines and smooth curves more common than other possible arrangements of edges (Geisler et al., Vis Res 41:711-24, 2001). The visual system appears to take advantage of this prior information, and human contour detection and grouping performance is well predicted by such an "association field" (Field et al., Vis Res 33:173-93, 1993). One possible candidate substrate for implementing an association field in mammals is the set of long-range lateral connections between neurons in the primary visual cortex (V1), which could act to facilitate detection of contours matching the association field, and/or inhibit detection of other contours (Choe and Miikkulainen, Biol Cyb 90:75-88, 2004). To fill this role, the lateral connections would need to be orientation specific and aligned along contours, and indeed such an arrangement has been found in tree shrew primary visual cortex (Bosking et al., J Neurosci 17:2112-27, 1997). However, it is not yet known whether these patterns develop as a result of visual experience, or are simply hard-wired to be appropriate for the statistics of natural scenes.
To investigate this issue, we examined the properties of the visual environment of laboratory animals, to determine whether the observed connection patterns are more similar to the statistics of the rearing environment or of a natural habitat. Specifically, we analyzed the cooccurence statistics of edge elements in images of natural scenes, and compared them to corresponding statistics for images taken from within the rearing environment of the animals in the Bosking et al. (1997) study. We used a modified version of the algorithm from Geisler et al. (2001), with a more general edge extraction algorithm that uses sparse coding to avoid multiple responses to a single edge. Collinearity and co-circularity results for natural images replicated qualitatively the results from Geisler et al. (2001), confirming that prior information about continuations appeared consistently in natural images. However, we find that the largely man-made environment in which these animals were reared has a significantly higher probability of collinear edge elements. We thus predict that if the lateral connection patterns are due to visual experience, the patterns in wild-raised tree shrews would be very different from those measured by Bosking et al. (1997), with shorter-range correlations and less emphasis on collinear continuations. This prediction can be tested in future experiments on matching groups of animals reared in different environments.



W.H. Bosking and Y. Zhang and B. Schofield and D. Fitzpatrick (1997)
Orientation selectivity and the arrangement of horizontal connections
in tree shrew striate cortex
Journal of Neuroscience  17:2112-27.

E.M. Callaway and L.C. Katz (1990)
Emergence and refinement of clustered horizontal connections in cat striate cortex.
Journal of Neuroscience 10:1134--53.

Y. Choe and R. Miikkulainen (2004)
Contour integration and segmentation with self-organized lateral connections
Biological Cybernetics 90:75-88.

D.J. Field, A. Hayes, and R.F. Hess (1993)
Contour integration by the human visual system: Evidence for a local
"association field",
Vision Research 33:173--93.

W.S. Geisler, J.S. Perry, B.J. Super, and D.P. Gallogly (2001)
Edge co-occurrence in natural images predicts contour grouping performance.
Vision Research 41:711-24.
},
	Author = {Perrinet, Laurent and David Fitzpatrick and Bednar, James A.},
	Booktitle = {Proceedings of SfN, 2011},
	Note = {* http://glotin.univ-tln.fr/ERMITES11/index.xhtml * see a follow-up at [[Presentations/Perrinet11sfn|SfN]].},
	Title = {Edge statistics in natural images versus laboratory animal environments: implications for understanding lateral connectivity in {V1}},
	Url = {http://invibe.net/LaurentPerrinet/Presentations/2011-09-28_ermites},
	Year = {2011},
	Bdsk-Url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2011-09-28_ermites}}

@inproceedings{2018-01-25_meetup-neuronautes,
	Author = {Perrinet, Laurent U. and Etienne Rey},
	Booktitle = {Meetup Art et Neurosciences},
	Note = {Quoi:: Meetup Art et Neurosciences Qui:: [[https://www.facebook.com/events/211121069456116/|Association NeuroNautes]] Quand:: 25 Janvier 2018 O{\`u}:: Salle des voutes campus Saint Charles Support visuel:: https://laurentperrinet.github.io/sciblog/files/2018-01-25_meetup-neuronautes.html (notes: la pr{\'e}sentation fait ~200Mo et peut mettre un certain temps {\`a} charger. Une fois que le titre apparait, appuyer sur la touche "F" pour mettre en plein {\'e}cran) ||<tablestyle="width: 90%; float: center; margin-left:20px; margin-right:20px; border-style: 0px; font-size: 10pt;">{{http://www.lafriche.org/public_data/diapo/resident/1454686884/desk/2._elasticite_dynamique-etienne_rey-photoquentin_chevrier_pour_art2m_et_arcadi_ile_de_france.jpg|Elasticit{\'e} dynamique est compos{\'e}e des pi{\`e}ces Expansion, Trame et Lignes sonores. Volume hexagonal en miroir de 7 m{\`e}tres de diam{\`e}tre, Expansion fonctionne comme une chambre d'{\'e}cho. A l'int{\'e}rieur de ce volume se situe Trame. Constitu{\'e}e de 25 lames de miroir en rotation, cette pi{\`e}ce r{\'e}oriente continuellement le regard. Quant {\`a} Lignes sonores, elle est form{\'e}e de quatre monolithes orient{\'e}s vers Expansion et {\'e}met des sons qui se r{\'e}orientent en fonction du mouvement des lames. ({\copyright} Etienne Rey, Adagp Paris 2015)''|width="100%"}}Elasticit{\'e} dynamique est compos{\'e}e des pi{\`e}ces Expansion, Trame et Lignes sonores. <<BR>> Volume hexagonal en miroir de 7 m{\`e}tres de diam{\`e}tre, Expansion fonctionne comme une chambre d'{\'e}cho. A l'int{\'e}rieur de ce volume se situe Trame. Constitu{\'e}e de 25 lames de miroir en rotation, cette pi{\`e}ce r{\'e}oriente continuellement le regard. Quant {\`a} Lignes sonores, elle est form{\'e}e de quatre monolithes orient{\'e}s vers Expansion et {\'e}met des sons qui se r{\'e}orientent en fonction du mouvement des lames. <<BR>>({\copyright} Etienne Rey, Adagp Paris 2015)||},
	Title = {Exp{\'e}riences autour de la perception de la forme en art et science},
	Url = {http://invibe.net/LaurentPerrinet/Presentations/2018-01-25_meetup-neuronautes},
	Year = {2018},
	Bdsk-Url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2018-01-25_meetup-neuronautes}}

@inproceedings{2017-06-30_Telluride,
	Author = {Perrinet, Laurent U.},
	Booktitle = {Telluride Neuromorphic Workshop, Workgroup on Compound Eyes and Event-based Vision},
	Note = {## {{http://www.laconeu.cl/images/Afiche_Workshop.jpg||align=right,width=50%}} Time:: June 30, 2017 Location:: Telluride Neuromorphic Workshop [[http://telluride.iniforum.ch/2017/workgroups/neuromorphic-event-based-compound-eyes-and-vision/ | Workgroup on Compound Eyes and Event-based Vision]] Slides:: https://laurentperrinet.github.io/sciblog/files/2017-06-30_Telluride.html},
	Title = {Tutorial on predictive coding},
	Url = {http://invibe.net/LaurentPerrinet/Presentations/2017-06-30_Telluride},
	Year = {2017},
	Bdsk-Url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2017-06-30_Telluride}}

@inproceedings{2012-01-24_Edinburgh,
	Abstract = {Oriented edges in images of natural scenes tend to be aligned in collinear or co-circular arrangements, with lines and smooth curves more common than other possible arrangements of edges (Geisler et al., Vis Res 41:711-24, 2001). The visual system appears to take advantage of this prior information, and human contour detection and grouping performance is well predicted by such an "association field" (Field et al., Vis Res 33:173-93, 1993). One possible candidate substrate for implementing an association field in mammals is the set of long-range lateral connections between neurons in the primary visual cortex (V1), which could act to facilitate detection of contours matching the association field, and/or inhibit detection of other contours (Choe and Miikkulainen, Biol Cyb 90:75-88, 2004). To fill this role, the lateral connections would need to be orientation specific and aligned along contours, and indeed such an arrangement has been found in tree shrew primary visual cortex (Bosking et al., J Neurosci 17:2112-27, 1997). However, it is not yet known whether these patterns develop as a result of visual experience, or are simply hard-wired to be appropriate for the statistics of natural scenes.
To investigate this issue, we examined the properties of the visual environment of laboratory animals, to determine whether the observed connection patterns are more similar to the statistics of the rearing environment or of a natural habitat. Specifically, we analyzed the cooccurence statistics of edge elements in images of natural scenes, and compared them to corresponding statistics for images taken from within the rearing environment of the animals in the Bosking et al. (1997) study. We used a modified version of the algorithm from Geisler et al. (2001), with a more general edge extraction algorithm that uses sparse coding to avoid multiple responses to a single edge. Collinearity and co-circularity results for natural images replicated qualitatively the results from Geisler et al. (2001), confirming that prior information about continuations appeared consistently in natural images. However, we find that the largely man-made environment in which these animals were reared has a significantly higher probability of collinear edge elements. We thus predict that if the lateral connection patterns are due to visual experience, the patterns in wild-raised tree shrews would be very different from those measured by Bosking et al. (1997), with shorter-range correlations and less emphasis on collinear continuations. This prediction can be tested in future experiments on matching groups of animals reared in different environments.

W.H. Bosking and Y. Zhang and B. Schofield and D. Fitzpatrick (1997)
Orientation selectivity and the arrangement of horizontal connections
in tree shrew striate cortex
Journal of Neuroscience  17:2112-27.

E.M. Callaway and L.C. Katz (1990)
Emergence and refinement of clustered horizontal connections in cat striate cortex.
Journal of Neuroscience 10:1134--53.

Y. Choe and R. Miikkulainen (2004)
Contour integration and segmentation with self-organized lateral connections
Biological Cybernetics 90:75-88.

D.J. Field, A. Hayes, and R.F. Hess (1993)
Contour integration by the human visual system: Evidence for a local
"association field",
Vision Research 33:173--93.

W.S. Geisler, J.S. Perry, B.J. Super, and D.P. Gallogly (2001)
Edge co-occurrence in natural images predicts contour grouping performance.
Vision Research 41:711-24.
},
	Author = {Perrinet, Laurent and David Fitzpatrick and Bednar, James A.},
	Booktitle = {A seminar from the Institute for Adaptive and Neural Computation (ANC)},
	Note = {= Time:: Jan 24, 2012, from 11:00 am to 12:00 pm Location:: IF 4.31/4.33 URL:: http://www.anc.ed.ac.uk/events/anc-dtc-seminar-laurent-perrinet ## See also: [[Publications/Perrinet11sfn|related work]]},
	Title = {Edge statistics in natural images versus laboratory animal environments: implications for understanding lateral connectivity in {V1}},
	Url = {http://invibe.net/cgi-bin/index.cgi/Presentations/2012-01-24_Edinburgh},
	Year = {2012},
	Bdsk-Url-1 = {http://invibe.net/cgi-bin/index.cgi/Presentations/2012-01-24_Edinburgh}}

@inproceedings{2017-11-15_ColloqueMaster,
	Author = {Perrinet, Laurent U.},
	Booktitle = {Colloque : "CODAGES ET REPRESENTATIONS", MASTER DE NEUROSCIENCES 2{\`e}me ann{\'e}e},
	Note = {## {{http://www.laconeu.cl/images/Afiche_Workshop.jpg||align=right,width=50%}} This seminar is an exercise to introduce the AMU masters into the format of international conferences. As such, we will try to introduce new concepts and results which will not be found in textbooks. Time:: November 15th, 2017 Venue:: Colloque : "CODAGES ET REPRESENTATIONS", MASTER DE NEUROSCIENCES 2{\`e}me ann{\'e}e Location:: Aix-Marseille Universit{\'e}, Campus Saint-Charles, Salle des vo{\^u}tes Slides:: https://laurentperrinet.github.io/sciblog/files/2017-11-15_ColloqueMaster.html (INSTRUCTIONS: press ``f`` for full-screen, ``o`` for an overview, ``s`` to get speaker notes; click on the links in blue to go further in your readings) -- you can also directly look at the [[https://laurentperrinet.github.io/sciblog/files/2017-11-15_ColloqueMaster.html?showNotes=true|Slides with the notes]]. References:: <<BR>> - unsupervised learning : [[Publications/Perrinet10shl|Perrinet (2010)]] <<BR>> - [[Publications/CristobalPerrinetKeil15bicv|Biologically inspired computer vision]] <<BR>> - supervised learning : https://www.nature.com/articles/srep11400 ([[http://invibe.net/LaurentPerrinet/Publications/PerrinetBednar15|more info]] ) <<BR>> - dynamics: Khoei et al (2017) - http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005068 ( [[Publications/KhoeiMassonPerrinet17|more info]] ) Comit{\'e} d'organisation:: Francesca SARGOLINI, Christian B{\'e}nar, Paolo GUBELLINI, Christian GESTREAU},
	Title = {What dynamic neural codes for efficient visual processing},
	Url = {http://invibe.net/LaurentPerrinet/Presentations/2017-11-15_ColloqueMaster},
	Year = {2017},
	Bdsk-Url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2017-11-15_ColloqueMaster}}

@inproceedings{2008-02_toledo,
	Author = {Perrinet, Laurent},
	Booktitle = {Prisma workshop, Toledo (Spain), February 7, 2008},
	Note = {* see [[Publications/Perrinet08spie]] * get the [[attachment:perrinet08toledo.pdf|presentation (8.8 Mo)]]},
	Title = {Modeling of spikes, sparseness and adaptation in the primary visual cortex: applications to imaging},
	Url = {http://invibe.net/LaurentPerrinet/Presentations/2008-02_toledo},
	Year = {2008},
	Bdsk-Url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2008-02_toledo}}

@inproceedings{2013-03-21_Marseille,
	Abstract = {This session aims at presenting new ideas that emerged during the first years of BrainScaleS. Indeed,
the collaborations that were initiated within the consortium led to the creation of novel tools as
planned in the proposal but also some of which were unforeseen, like the Motion Clouds that we
presented previously. We present here some prototypical and inspiring examples of such
collaborative work on: 1) tool chains from experimental (Davison), computational (Antolik) or integrative (Petrovici)
perspectives, 2) original methods inspired by novel types of analysis for propagating waves (Schmidt, Muller) or by
novel magnetrodes (Pannetier Lecoeur).},
	Author = {Perrinet, Laurent U.},
	Booktitle = {3rd BrainScaleS Plenary Meeting - Friday, March 21st, 2013},
	Note = {= Time:: March 21st, 2013 Location:: INT, Marseille.},
	Title = {Why methods and tools are the key to artificial brain-like systems},
	Url = {http://invibe.net/LaurentPerrinet/Presentations/2013-03-21_Marseille},
	Year = {2013},
	Bdsk-Url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2013-03-21_Marseille}}
