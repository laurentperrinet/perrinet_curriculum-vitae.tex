@comment{%% This BibTeX bibliography file was created using BibDesk.
%% http://bibdesk.sourceforge.net/

%% Created for Laurent Perrinet at 2020-08-28 10:24:09 +0200


%% Saved with string encoding Unicode (UTF-8)}

@inproceedings{2006-01-01_neurocomp,
    abstract = {The quality of the representation of an object's motion is limited by the noise in the sensory input as well as by an intrinsic ambiguity due to the spatial limitation of the visual motion analyzers (aperture problem). Perceptual and oculomotor data demonstrate that motion processing of extended ob jects is initially dominated by the local 1D motion cues orthogonal to the ob ject's edges, whereas 2D information takes progressively over and leads to the final correct representation of global motion. A Bayesian framework accounting for the sensory noise and general expectancies for ob ject velocities has proven successful in explaining several experimental findings concerning early motion processing [1, 2, 3]. However, a complete functional model, encompassing the dynamical evolution of object motion perception is still lacking. Here we outline several experimental observations concerning human smooth pursuit of moving ob jects and more particularly the time course of its initiation phase. In addition, we propose a recursive extension of the Bayesian model, motivated and constrained by our oculomotor data, to describe the dynamical integration of 1D and 2D motion information.},
    author = {Perrinet, Laurent U and Barthélemy, Frédéric V and Masson, Guillaume S},
    bdsk-url-1 = {https://laurentperrinet.github.io/publication/perrinet-06-neurocomp/},
    booktitle = {1ère conférence francophone NEUROsciences COMPutationnelles - NeuroComp},
    date-modified = {2020-08-10 11:44:25 +0200},
    keywords = {Aperture problem,Bayesian model,Object motion,recursive inference,Smooth pursuit eye movement,Temporal evolution.},
    rating = {5},
    title = {Input-output transformation in the visuo-oculomotor loop: modeling the ocular following response to center-surround stimulation in a probabilistic framework},
    topic = {edge},
    url = {https://laurentperrinet.github.io/publication/perrinet-06-neurocomp/},
    year = {2006}
}

@inproceedings{2007-09-01_mipm,
    abstract = {I will illustrate in this talk how computational neuroscience may inspire and be inspired by mathematical image processing. Focusing on efficiently representing natural images in the primary visual cortex, we derive an event-based adaptive algorithm inspired by statistical inference, Matching Pursuit and Hebbian learning. This algorithm allows to learn efficient "edge-like" receptive fields similarly to Independent Components Analysis. The correlation-based inhibition has been shown to be a necessary condition for the fomation of this type of receptive fields and shows the putative functional role of lateral propagation of information in cortical layers. I'll first present state-of-the-art neural algorithms for this task, the results of a detailed analysis of this Sparse Hebbian Learning algorithm and finally draw a comparison with similar strategies.},
    author = {Perrinet, Laurent U},
    bdsk-url-1 = {https://laurentperrinet.github.io/talk/2007-09-01-mipm},
    booktitle = {Mathematical image processing meeting (Marseille, France) September 5},
    date-added = {2007-10-29 16:22:21 +0100},
    date-modified = {2020-08-10 11:44:25 +0200},
    title = {Neural Codes for Adaptive Sparse Representations of Natural Images},
    url = {https://laurentperrinet.github.io/talk/2007-09-01-mipm},
    year = {2007}
}

@inproceedings{2007-12-01_rankprize,
    author = {Perrinet, Laurent U},
    bdsk-url-1 = {https://laurentperrinet.github.io/talk/2007-12-01-rankprize/},
    booktitle = {The Rank Prize Funds, Mini-Symposium on Representations of the Visual World in the Brain},
    date-modified = {2020-08-10 11:44:25 +0200},
    title = {What efficient code for adaptive spiking representations?},
    url = {https://laurentperrinet.github.io/talk/2007-12-01-rankprize/},
    year = {2007}
}

@inproceedings{2008-02-01_toledo,
    author = {Perrinet, Laurent U},
    bdsk-url-1 = {https://laurentperrinet.github.io/talk/2008-02-01-toledo/},
    booktitle = {Prisma workshop, Toledo (Spain), February 7, 2008},
    date-modified = {2020-08-10 11:44:25 +0200},
    title = {Modeling of spikes, sparseness and adaptation in the primary visual cortex: applications to imaging},
    url = {https://laurentperrinet.github.io/talk/2008-02-01-toledo/},
    year = {2008}
}

@inproceedings{2008-04-01_incm,
    abstract = {Computational Neuroscience is a synthetic, inter-disciplinary approach aiming at
understanding cognition by analyzing the mechanisms underlying neural computations. We
present in this seminar our attempt in modeling low-level vision by bridging different
integration levels, from neural spiking activity to behavior. At the behavioral level, the Ocular
Following Response recorded in the laboratory reveals how the brain may integrate local
information (moving images on visual receptive fields) to produce a single behavioral
response (the movement of the eye). Using a probabilistic representation, we provide a
simple integrative mechanism that gives the ''ideal'' response to possibly noisy and
ambiguous information, similarly to a Bayesian approach. This fits well the performance
revealed by behavioral data and may act as a generic cortical ''module''. At the population
level, these mechanisms may indeed be implemented for the coding of natural images and
we will show the particular importance of spiking representations and lateral interactions for
efficient and rapid responses. In particular, we will present an original unsupervised learning
algorithm that we applied to a model of the primary visual cortex. Finally, at the neuronal
level, I will present work done in the team showing how certain mechanisms at the level of
the synapse and of the neuron are essential at the population level and how we may
understand these mechanisms at the population level. This illustrates the importance of
dynamical processes, distributed activity and recurrent connections to produce a cortical gain
control mechanism. As a conclusion, this approach provides useful applications for image
processing and possible valorization in future computer architectures. More generally, it
proves that the use of a probabilistic representation is a particularly efficient method for
bridging biological versus computational neuroscience and illustrates the advantage of such
an interdisciplinary approach.},
    author = {Perrinet, Laurent U},
    bdsk-url-1 = {https://laurentperrinet.github.io/talk/2008-04-01-incm/},
    booktitle = {Séminaires de l'INCM, April 11th, 2008},
    date-modified = {2020-08-10 11:44:25 +0200},
    grants = {facets},
    title = {From neural activity to behavior: computational neuroscience as a synthetic approach for understanding the neural code.},
    url = {https://laurentperrinet.github.io/talk/2008-04-01-incm/},
    year = {2008}
}

@inproceedings{2008-06-01_Ulm,
    abstract = {The machinery behind the visual perception of motion and the subsequent
sensorimotor transformation, such as in Ocular Following Response (OFR),
is confronted to uncertainties which are efficiently resolved in the
primate's visual system. We may understand this response as an ideal
observer in a probabilistic framework by using Bayesian theory (Weiss et
al., 2002) which we previously proved to be successfully adapted to
model the OFR for different levels of noise with full field gratings or
with disk of various sizes and the effect of a flickering surround
(Perrinet and Masson, 2007).
More recent experiments of OFR have used disk gratings and bipartite
stimuli which are optimized to study the dynamics of center-surround
integration. We quantified two main characteristics of the global
spatial integration of motion from an intermediate map of possible local
translation velocities: (i) a finite optimal stimulus size for driving
OFR, surrounded by an antagonistic modulation and (ii) a direction
selective suppressive effect of the surround on the contrast gain
control of the central stimuli (Barthelemy et al., 2006, 2007).
Herein, we extended in the dynamical domain the ideal observer model to
simulate the spatial integration of the different local motion cues
within a probabilistic representation. We present analytical results
which show that the hypothesis of independence of local measures can
describe the initial segment of spatial integration of motion signal.
Within this framework, we successfully accounted for the dynamical
contrast gain control mechanisms observed in the behavioral data for
center-surround stimuli. However, another inhibitory mechanism had to be
added to account for suppressive effects of the surround. We explore
here an hypothesis where this could be understood as the effect of a
recurrent integration of information in the velocity map.

F. Barthelemy, L. U. Perrinet, E. Castet, and G. S. Masson. Dynamics of
distributed 1D and 2D motion representations for short-latency ocular
following. Vision Research, 48(4):501--22, feb 2007. doi:
10.1016/j.visres.2007.10.020.

F. V. Barthelemy, I. Vanzetta, and G. S. Masson. Behavioral receptive
field for ocular following in humans: Dynamics of spatial summation and
center-surround interactions. Journal of Neurophysiology,
(95):3712--26, Mar 2006. doi: 10.1152/jn.00112.2006.

L. U. Perrinet and G. S. Masson. Modeling spatial integration in the
ocular following response using a probabilistic framework. Journal of
Physiology (Paris), 2007. doi: 10.1016/j.jphysparis.2007.10.011.

Y. Weiss, E. P. Simoncelli, and E. H. Adelson. Motion illusions as
optimal percepts. Nature Neuroscience, 5(6):598--604, Jun 2002. doi:
10.1038/nn858.},
    author = {Perrinet, Laurent U and Masson, Guillaume S},
    bdsk-url-1 = {https://laurentperrinet.github.io/talk/2008-06-01-ulm/},
    date-modified = {2020-08-10 11:44:25 +0200},
    grants = {facets},
    title = {Decoding the population dynamics underlying ocular following response using a probabilistic framework},
    url = {https://laurentperrinet.github.io/talk/2008-06-01-ulm/},
    year = {2008}
}

@inproceedings{2009-04-01_INT,
    abstract = {
Moving the eyes rapidly to track a visual object moving in a cluttered environment is an essential
function. However, doing so rapidly and efficiently is constrained by a number of noise sources in the
visual system and by the fact that information is collected locally before giving raise to a global signal.
After reviewing some results made in the modeling of low-level sensory areas, I will expose a method
to decode low-level neural information as describing visual information using a probabilistic
representation. Decisions will therefore correspond to statistical inferences which are dynamically
resolving the veridical speed of a moving object. We will illustrate this method by showing how
ambiguous local information can be merged to give raise to a global response which resolves the
aperture problem. Using this theoretical approach "in computo", we will illustrate how we may better
understand results which are observed "in vivo" (optical imaging) as a neural code linking actively
sensation and behavior.},
    author = {Perrinet, Laurent U and Masson, Guillaume S},
    bdsk-url-1 = {https://laurentperrinet.github.io/talk/2008-04-01-incm/},
    date-modified = {2020-08-10 11:44:25 +0200},
    grants = {facets},
    title = {Decoding low-level neural information to track visual motion},
    url = {https://laurentperrinet.github.io/talk/2008-04-01-incm/},
    year = {2009}
}

@inproceedings{2009-07-18_Kremkow09cnstalk,
    author = {Kremkow, Jens and Perrinet, Laurent U and Monier, Cyril and Frégnac, Yves and Masson, Guillaume S and Aertsen, Ad M},
    bdsk-url-1 = {https://doi.org/10.1186/1471-2202-10-S1-O21},
    bdsk-url-2 = {https://doi.org/10.1186/1471-2202-10-S1-O21},
    booktitle = {Eighteenth Annual Computational Neuroscience Meeting: CNS*2009 Berlin, Germany. 18--23 July 2009},
    date-modified = {2020-08-10 11:44:25 +0200},
    doi = {doi:10.1186/1471-2202-10-S1-O21},
    grants = {facets},
    pages = {Oral presentation, 10(Suppl 1):O21},
    title = {Control of the temporal interplay between excitation and inhibition by the statistics of visual input},
    year = {2009}
}

@inproceedings{2009-11-24_IntelligenceMecanique,
    abstract = {Nous parlerons de cette partie "mécanique" du cerveau animal ou humain qui permet de percevoir les mouvements et de ... survivre au sein de l'environnement. On verra, par exemple, que notre cerveau peut-être plus rapide que nous, qu'il y a des solutions "stupides" qui marchent remarquablement bien pour sortir d'un labyrinthe, et qui si la grenouille sait gober une mouche bien mieux qu'un robot ... elle n'est pas plus maligne ! Parce que ce qu'il ne faut pas confondre ici c'est la différence entre calculer et penser, entre intelligence et algorithmes. En comprenant cela, avec Alan Mathison Turing, le Gutenberg du XXème siècle, l'humanité a basculé des temps modernes à l'ère du numérique. },
    author = {Perrinet, Laurent U and Viéville, Thierry},
    bdsk-url-1 = {https://laurentperrinet.github.io/talk/2009-11-24-intelligence-mecanique/},
    booktitle = {Cycle de conférences organisé par l'Association Science Technologie Société - PACA ayant pour thème cette année : ``Biologie et civilisation : les chemins de l'intelligence''.},
    date-modified = {2020-08-10 11:44:25 +0200},
    event_url = {http://asts.paris/},
    location = {Marseille, France},
    projects = {tout-public},
    time_start = {2009-11-24T18:30:00},
    title = {Peut-on parler d'intelligence mécanique?},
    url = {https://laurentperrinet.github.io/talk/2009-11-24-intelligence-mecanique/},
    year = {2009}
}

@inproceedings{2009-11-30_vss,
    abstract = {Short presentation of a large moving pattern elicits an ocular following response that exhibits many of the properties attributed to low-level motion processing such as spatial and temporal integration, contrast gain control and divisive interaction between competing motions. Similar mechanisms have been demonstrated in V1 cortical activity in response to center-surround gratings patterns measured with real-time optical imaging in awake monkeys (see poster of Reynaud et al., VSS09). Based on a previously developed Bayesian framework, we have developed an optimal statistical decoder of such an observed cortical population activity as recorded by optical imaging. This model aims at characterizing the statistical dependance between early neuronal activity and ocular responses and its performance was analyzed by comparing this neuronal read-out and the actual motor responses on a trial-by-trial basis. First, we show that relative performance of the behavioral contrast response function is similar to the best estimate obtained from the neural activity. In particular, we show that the latency of ocular response increases with low contrast conditions as well as with noisier instances of the behavioral task as decoded by the model. Then, we investigate the temporal dynamics of both neuronal and motor responses and show how motion information as represented by the model is integrated in space to improve population decoding over time. Lastly, we explore how a surrounding velocity non congruous with the central excitation information shunts the ocular response and how it is topographically represented in the cortical activity. Acknowledgement: European integrated project FACETS IST-15879.},
    author = {Perrinet, Laurent U and Reynaud, Alexandre and Chavane, Frédéric Y and Masson, Guillaume S},
    bdsk-url-1 = {https://laurentperrinet.github.io/talk/2009-11-30-vss/},
    booktitle = {Macroscopic aspects of neuronal activity: ''Macroscopic models, LFP models and VSD models'' a FACETS workshop in Marseille, Nov. 30th /Dec. 1st},
    date-modified = {2020-08-10 11:44:25 +0200},
    grants = {facets},
    title = {Reading out the dynamics of lateral interactions in the primary visual cortex from VSD data},
    url = {https://laurentperrinet.github.io/talk/2009-11-30-vss/},
    year = {2009}
}

@inproceedings{2010-01-08_facets,
    author = {Perrinet, Laurent U and Masson, Guillaume S},
    bdsk-url-1 = {https://laurentperrinet.github.io/talk/2010-01-08-facets/},
    date-modified = {2020-08-10 11:44:25 +0200},
    keywords = {Bayesian model,center-surround interactions,dynamics,eye movements,motion detection,motion prediction},
    title = {Models of low-level vision: linking probabilistic models and neural masses},
    url = {https://laurentperrinet.github.io/talk/2010-01-08-facets/},
    year = {2010}
}

@inproceedings{2010-04-14_OndesParalleles,
    abstract = {En perception, les neurones « parlent » tous en même temps par de brèves impulsions électrochimiques, générant un mélange de signaux, un bruit. Pourtant c'est par eux que nous pensons, voyons, sentons. Les ordinateurs sont différents, plus rapides. Ils sont construits avec pour modèle la grammaire humaine autour d'une unité centrale, car on imaginait la cognition sous cet angle à leur invention. Le bit est le quantum d'un algorithme mécanique (thèse de Church-Turing). Une théorie tranche par rapport à la précédente, proposée par «von Neumann» : beaucoup d'unités sont présentes dans le cerveau. Comparée à la chaı̂ne logique du langage, dans cet algorithme, beaucoup d'autres cha\n̂es et logiques se mêlent. Comment vont-elles « parler » entre elles ? Existe-t-il des algorithmes biologiques ? },
    author = {Perrinet, Laurent U},
    bdsk-url-1 = {https://laurentperrinet.github.io/talk/2010-04-14-ondes-paralleles/},
    booktitle = {intervention autour du vernissage de "Diffraction monochromatique, spectre audiographique" d'Etienne Rey.},
    date-modified = {2020-08-10 11:44:25 +0200},
    event_url = {http://ondesparalleles.org/projets/vortex-polychromatique-diffraction/},
    location = {Aix-enProvence (France)},
    projects = {art-science,tout-public},
    time_start = {2010-04-14T19:00:00},
    title = {Diffraction monochromatique, spectre audiographique},
    url = {https://laurentperrinet.github.io/talk/2010-04-14-ondes-paralleles/},
    year = {2010}
}

@inproceedings{2010-12-17_TaucTalk,
    abstract = {Sensory informations such as visual images are inherently variable. We use probabilistic models to describe how the low-level visual system could describe superposed and ambiguous information. This allows to describe the interactions of neighboring populations of neurons as inference rules that dynamically build up the overall description of the visual scene. We focus here on temporal prediction, that is by the transport of information based on an estimate of local motion in the image.},
    author = {Perrinet, Laurent U},
    bdsk-url-1 = {https://laurentperrinet.github.io/talk/2010-12-17-tauc-talk/},
    booktitle = {LADISLAV TAUC and GDR MSPC NEUROSCIENCES CONFERENCE, From Mathematical Image Analysis to Neurogeometry of the Brain},
    date-modified = {2020-08-10 11:44:25 +0200},
    keywords = {Bayesian model,center-surround interactions,dynamics,eye movements,motion detection,motion prediction},
    title = {Probabilistic models of the low-level visual system: the role of prediction in detecting motion},
    url = {https://laurentperrinet.github.io/talk/2010-12-17-tauc-talk/},
    year = {2010}
}

@inproceedings{2011-07-02_NeuroMedTalk,
    abstract = {Sensory informations such as visual images are inherently variable. We use probabilistic models to describe how the low-level visual system could describe superposed and ambiguous information. This allows to describe the interactions of neighboring populations of neurons as inference rules that dynamically build up the overall description of the visual scene. We focus here on temporal prediction, that is by the transport of information based on an estimate of local motion in the image.},
    author = {Perrinet, Laurent U},
    bdsk-url-1 = {https://laurentperrinet.github.io/talk/2011-07-02-neuro-med-talk/},
    booktitle = {Atelier Neurosciences Computationnelles, 2-3 Juillet 2011 Khemisset, Maroc},
    date-modified = {2020-08-10 11:44:25 +0200},
    keywords = {Bayesian model,dynamics,eye movements,motion detection,motion prediction},
    title = {Propriétés émergentes d'un modèle de prédiction probabiliste utilisant un champ neural},
    url = {https://laurentperrinet.github.io/talk/2011-07-02-neuro-med-talk/},
    year = {2011}
}

@inproceedings{2011-09-28_ermites,
    abstract = {Oriented edges in images of natural scenes tend to be aligned in collinear or co-circular arrangements, with lines and smooth curves more common than other possible arrangements of edges (Geisler et al., Vis Res 41:711-24, 2001). The visual system appears to take advantage of this prior information, and human contour detection and grouping performance is well predicted by such an "association field" (Field et al., Vis Res 33:173-93, 1993). One possible candidate substrate for implementing an association field in mammals is the set of long-range lateral connections between neurons in the primary visual cortex (V1), which could act to facilitate detection of contours matching the association field, and/or inhibit detection of other contours (Choe and Miikkulainen, Biol Cyb 90:75-88, 2004). To fill this role, the lateral connections would need to be orientation specific and aligned along contours, and indeed such an arrangement has been found in tree shrew primary visual cortex (Bosking et al., J Neurosci 17:2112-27, 1997). However, it is not yet known whether these patterns develop as a result of visual experience, or are simply hard-wired to be appropriate for the statistics of natural scenes. To investigate this issue, we examined the properties of the visual environment of laboratory animals, to determine whether the observed connection patterns are more similar to the statistics of the rearing environment or of a natural habitat. Specifically, we analyzed the cooccurence statistics of edge elements in images of natural scenes, and compared them to corresponding statistics for images taken from within the rearing environment of the animals in the Bosking et al. (1997) study. We used a modified version of the algorithm from Geisler et al. (2001), with a more general edge extraction algorithm that uses sparse coding to avoid multiple responses to a single edge. Collinearity and co-circularity results for natural images replicated qualitatively the results from Geisler et al. (2001), confirming that prior information about continuations appeared consistently in natural images. However, we find that the largely man-made environment in which these animals were reared has a significantly higher probability of collinear edge elements. We thus predict that if the lateral connection patterns are due to visual experience, the patterns in wild-raised tree shrews would be very different from those measured by Bosking et al. (1997), with shorter-range correlations and less emphasis on collinear continuations. This prediction can be tested in future experiments on matching groups of animals reared in different environments.},
    author = {Perrinet, Laurent U and Fitzpatrick, David and Bednar, James A},
    bdsk-url-1 = {https://laurentperrinet.github.io/talk/2011-09-28-ermites/},
    booktitle = {Proceedings of SfN, 2011},
    date-modified = {2020-08-10 11:44:25 +0200},
    event_url = {http://glotin.univ-tln.fr/ERMITES11/index.xhtml},
    grants = {brain-scales},
    keywords = {sparse coding},
    location = {Porquerolles la Perle des Iles d'Or - Var (France)},
    time_start = {2011-09-28T13:00:00},
    title = {Edge statistics in natural images versus laboratory animal environments: implications for understanding lateral connectivity in V1},
    url = {https://laurentperrinet.github.io/talk/2011-09-28-ermites/},
    year = {2011}
}

@inproceedings{2011-10-05_BrainScalesESS,
    author = {Perrinet, Laurent U},
    bdsk-url-1 = {https://laurentperrinet.github.io/talk/2011-10-05-brain-scales-ess/},
    booktitle = {Using the ESS + Neuromorphic hardware Workshop},
    date-modified = {2020-08-10 11:44:25 +0200},
    event_url = {https://brainscales.kip.uni-heidelberg.de/jss/AttendMeeting?m=showAgenda&meetingID=15},
    grants = {brain-scales},
    keywords = {sparse coding},
    location = {TU Dresden, Germany},
    time_start = {2011-10-05T13:00:00},
    title = {Demo 1, Task4: Implementation of models showing emergence of cortical fields and maps},
    url = {https://laurentperrinet.github.io/talk/2011-10-05-brain-scales-ess/},
    year = {2011}
}

@inproceedings{2011-11-15_sfn,
    abstract = {Oriented edges in images of natural scenes tend to be aligned in collinear or co-circular arrangements, with lines and smooth curves more common than other possible arrangements of edges (Geisler et al., Vis Res 41:711-24, 2001). The visual system appears to take advantage of this prior information, and human contour detection and grouping performance is well predicted by such an "association field" (Field et al., Vis Res 33:173-93, 1993). One possible candidate substrate for implementing an association field in mammals is the set of long-range lateral connections between neurons in the primary visual cortex (V1), which could act to facilitate detection of contours matching the association field, and/or inhibit detection of other contours (Choe and Miikkulainen, Biol Cyb 90:75-88, 2004). To fill this role, the lateral connections would need to be orientation specific and aligned along contours, and indeed such an arrangement has been found in tree shrew primary visual cortex (Bosking et al., J Neurosci 17:2112-27, 1997). However, it is not yet known whether these patterns develop as a result of visual experience, or are simply hard-wired to be appropriate for the statistics of natural scenes. To investigate this issue, we examined the properties of the visual environment of laboratory animals, to determine whether the observed connection patterns are more similar to the statistics of the rearing environment or of a natural habitat. Specifically, we analyzed the cooccurence statistics of edge elements in images of natural scenes, and compared them to corresponding statistics for images taken from within the rearing environment of the animals in the Bosking et al. (1997) study. We used a modified version of the algorithm from Geisler et al. (2001), with a more general edge extraction algorithm that uses sparse coding to avoid multiple responses to a single edge. Collinearity and co-circularity results for natural images replicated qualitatively the results from Geisler et al. (2001), confirming that prior information about continuations appeared consistently in natural images. However, we find that the largely man-made environment in which these animals were reared has a significantly higher probability of collinear edge elements. We thus predict that if the lateral connection patterns are due to visual experience, the patterns in wild-raised tree shrews would be very different from those measured by Bosking et al. (1997), with shorter-range correlations and less emphasis on collinear continuations. This prediction can be tested in future experiments on matching groups of animals reared in different environments.},
    author = {Perrinet, Laurent U and Fitzpatrick, David and Bednar, James A},
    bdsk-url-1 = {https://laurentperrinet.github.io/talk/2011-11-15-sfn/},
    booktitle = {Society for Neuroscience Abstracts},
    date-modified = {2020-08-10 11:44:25 +0200},
    editor = {Society for Neuroscience, www.sfn.org},
    location = {Washington, DC},
    number = {Program No. 530.04},
    time_start = {2011-11-15T08:45:00},
    title = {Edge statistics in natural images versus laboratory animal environments: implications for understanding lateral connectivity in V1},
    url = {https://laurentperrinet.github.io/talk/2011-11-15-sfn/},
    year = {2011}
}

@inproceedings{2012-01-12_VisionAtUcl,
    abstract = {In low-level sensory systems, it is still unclear how the noisy information collected locally by neurons may give rise to a coherent global percept. This is well demonstrated for the detection of motion in the aperture problem: as luminance of an elongated line is symmetrical along its axis, tangential velocity is ambiguous when measured locally. Here, we develop the hypothesis that motion-based predictive coding is sufficient to infer global motion. Our implementation is based on a context-dependent diffusion of a probabilistic representation of motion. We observe in simulations a progressive solution to the aperture problem similar to psychophysics and behavior. We demonstrate that this solution is the result of  two underlying mechanisms. First, we demonstrate the formation of a tracking behavior favoring temporally coherent features independently of their texture. Second, we observe that incoherent features are explained away while coherent information diffuses progressively to the global scale. Most previous models included ad-hoc mechanisms such as end-stopped cells or a selection layer to track specific luminance-based features. Here, we have proved that motion-based predictive coding, as it is  implemented in this functional model, is sufficient to solve the aperture problem. This simpler solution may give insights in the role of prediction underlying a large class of sensory computations.},
    author = {Perrinet, Laurent U},
    bdsk-url-1 = {https://laurentperrinet.github.io/talk/2012-01-12-vision-at-ucl/},
    booktitle = {Vision@UCL seminar},
    date-modified = {2020-08-10 11:44:25 +0200},
    grants = {brain-scales},
    keywords = {Bayesian model,center-surround interactions,dynamics,eye movements,motion detection,motion prediction},
    location = {Malet Place Eng Bldg 1.03 (first floor).},
    time_start = {2012-01-12T17:00:00},
    title = {Motion-based prediction is sufficient to solve the aperture problem},
    url = {https://laurentperrinet.github.io/talk/2012-01-12-vision-at-ucl/},
    year = {2012}
}

@inproceedings{2012-01-24_Edinburgh,
    abstract = {Oriented edges in images of natural scenes tend to be aligned in collinear or co-circular arrangements, with lines and smooth curves more common than other possible arrangements of edges (Geisler et al., Vis Res 41:711-24, 2001). The visual system appears to take advantage of this prior information, and human contour detection and grouping performance is well predicted by such an "association field" (Field et al., Vis Res 33:173-93, 1993). One possible candidate substrate for implementing an association field in mammals is the set of long-range lateral connections between neurons in the primary visual cortex (V1), which could act to facilitate detection of contours matching the association field, and/or inhibit detection of other contours (Choe and Miikkulainen, Biol Cyb 90:75-88, 2004). To fill this role, the lateral connections would need to be orientation specific and aligned along contours, and indeed such an arrangement has been found in tree shrew primary visual cortex (Bosking et al., J Neurosci 17:2112-27, 1997). However, it is not yet known whether these patterns develop as a result of visual experience, or are simply hard-wired to be appropriate for the statistics of natural scenes. To investigate this issue, we examined the properties of the visual environment of laboratory animals, to determine whether the observed connection patterns are more similar to the statistics of the rearing environment or of a natural habitat. Specifically, we analyzed the cooccurence statistics of edge elements in images of natural scenes, and compared them to corresponding statistics for images taken from within the rearing environment of the animals in the Bosking et al. (1997) study. We used a modified version of the algorithm from Geisler et al. (2001), with a more general edge extraction algorithm that uses sparse coding to avoid multiple responses to a single edge. Collinearity and co-circularity results for natural images replicated qualitatively the results from Geisler et al. (2001), confirming that prior information about continuations appeared consistently in natural images. However, we find that the largely man-made environment in which these animals were reared has a significantly higher probability of collinear edge elements. We thus predict that if the lateral connection patterns are due to visual experience, the patterns in wild-raised tree shrews would be very different from those measured by Bosking et al. (1997), with shorter-range correlations and less emphasis on collinear continuations. This prediction can be tested in future experiments on matching groups of animals reared in different environments.},
    author = {Perrinet, Laurent U and Fitzpatrick, David and Bednar, James A},
    bdsk-url-1 = {https://laurentperrinet.github.io/talk/2012-01-24-edinburgh/},
    booktitle = {A seminar from the Institute for Adaptive and Neural Computation (ANC)},
    date-modified = {2020-08-10 11:44:25 +0200},
    event_url = {http://www.anc.ed.ac.uk/events/anc-dtc-seminar-laurent-perrinet},
    grants = {brain-scales},
    location = {Room IF 4.31/4.33, Institute for Adaptive and Neural Computation (ANC) at the University of Edinburgh},
    time_start = {2012-01-24T13:00:00},
    title = {Edge statistics in natural images versus laboratory animal environments: implications for understanding lateral connectivity in V1},
    url = {https://laurentperrinet.github.io/talk/2012-01-24-edinburgh/},
    year = {2012}
}

@inproceedings{2012-01-27_FIL,
    abstract = {Moving objects generate sensory information that may be noisy and ambiguous, yet it is important to be able to reconstruct object speed as fast as possible. One unsolved question is to understand how the brain pools motion information to give an efficient response. I will present computational models of motion detection in the visual system that try to answer this question. First, sensory information is grabbed by pooling the information from different sensory neurons. This pooling is modulated by the precision of information and we will present some recent model-based behavioural results. Then I will focus on a novel model of motion-based prediction that allows to track objects on smooth trajectories. This model gives an economical description of neural mechanisms associated with the processing underlying motion detection. Finally, we will propose an exploratory hypothesis such that eye movements may be understood as the prospective response to this dynamical sensory response knowing oculomotor constraints such as delays. This line of research aims at showing that through the convergent use of models, electrophysiology or behavioural responses, the study of motion detection is an essential tool in our understanding of neural computations.},
    author = {Perrinet, Laurent U},
    bdsk-url-1 = {Presentations/2012-01-27_FIL},
    booktitle = {Brain meeting at FIL, London - Friday, January 27th, 2012},
    date-modified = {2020-08-10 11:44:25 +0200},
    grants = {brain-scales},
    keywords = {Bayesian model,dynamics,eye movements,free energy,motion detection,predictive coding},
    title = {Grabbing, tracking and sniffing as models for motion detection and eye movements},
    url = {https://laurentperrinet.github.io/talk/2012-01-27-fil/},
    year = {2012}
}

@inproceedings{2012-03-22_Juelich,
    author = {Perrinet, Laurent U},
    bdsk-url-1 = {https://laurentperrinet.github.io/talk/2012-03-22-juelich/},
    booktitle = {Second BrainScaleS plenary Meeting - WP4},
    date-modified = {2020-08-10 11:44:25 +0200},
    grants = {brain-scales},
    keywords = {motion-clouds},
    location = {Forschungszentrum Jülich},
    projects = {open-science},
    time_start = {2012-03-22T14:00:00},
    title = {MotionClouds: Model-based stimulus synthesis of natural-like random textures for the study of motion perception},
    url = {https://laurentperrinet.github.io/talk/2012-03-22-juelich/},
    year = {2012}
}

@inproceedings{2012-03-23_Juelich,
    author = {Perrinet, Laurent U},
    bdsk-url-1 = {https://laurentperrinet.github.io/talk/2012-03-23-juelich/},
    booktitle = {Second BrainScaleS plenary Meeting - WP5},
    date-modified = {2020-08-10 11:44:25 +0200},
    grants = {brain-scales},
    location = {Forschungszentrum Jülich},
    time_start = {2012-03-23T13:00:00},
    title = {Apparent motion in V1 - Probabilistic approaches},
    url = {https://laurentperrinet.github.io/talk/2012-03-23-juelich/},
    year = {2012}
}

@inproceedings{2012-05-10_itwist,
    abstract = {Oriented edges in images of natural scenes tend to be aligned in collinear or co-circular arrangements, with lines and smooth curves more common than other possible arrangements of edges (Geisler et al., Vis Res 41:711-24, 2001). The visual system appears to take advantage of this prior information, and human contour detection and grouping performance is well predicted by such an "association field" (Field et al., Vis Res 33:173-93, 1993). One possible candidate substrate for implementing an association field in mammals is the set of long-range lateral connections between neurons in the primary visual cortex (V1), which could act to facilitate detection of contours matching the association field, and/or inhibit detection of other contours (Choe and Miikkulainen, Biol Cyb 90:75-88, 2004). To fill this role, the lateral connections would need to be orientation specific and aligned along contours, and indeed such an arrangement has been found in tree shrew primary visual cortex (Bosking et al., J Neurosci 17:2112-27, 1997). However, it is not yet known whether these patterns develop as a result of visual experience, or are simply hard-wired to be appropriate for the statistics of natural scenes. To investigate this issue, we examined the properties of the visual environment of laboratory animals, to determine whether the observed connection patterns are more similar to the statistics of the rearing environment or of a natural habitat. Specifically, we analyzed the cooccurence statistics of edge elements in images of natural scenes, and compared them to corresponding statistics for images taken from within the rearing environment of the animals in the Bosking et al. (1997) study. We used a modified version of the algorithm from Geisler et al. (2001), with a more general edge extraction algorithm that uses sparse coding to avoid multiple responses to a single edge. Collinearity and co-circularity results for natural images replicated qualitatively the results from Geisler et al. (2001), confirming that prior information about continuations appeared consistently in natural images. However, we find that the largely man-made environment in which these animals were reared has a significantly higher probability of collinear edge elements. We thus predict that if the lateral connection patterns are due to visual experience, the patterns in wild-raised tree shrews would be very different from those measured by Bosking et al. (1997), with shorter-range correlations and less emphasis on collinear continuations. This prediction can be tested in future experiments on matching groups of animals reared in different environments.},
    author = {Perrinet, Laurent U and Fitzpatrick, David and Bednar, James A},
    bdsk-url-1 = {https://laurentperrinet.github.io/talk/2012-05-10-itwist/},
    booktitle = {iTWIST '12 workshop},
    date-modified = {2020-08-10 11:44:25 +0200},
    event_url = {https://sites.google.com/site/itwist1st/home},
    keywords = {sparse coding},
    time_start = {2012-05-10-18T13:00:00},
    title = {Edge statistics in natural images versus laboratory animal environments: implications for understanding lateral connectivity in V1},
    url = {https://laurentperrinet.github.io/talk/2012-05-10-itwist/},
    year = {2012}
}

@inproceedings{2013-03-21_Marseille,
    abstract = {This session aims at presenting new ideas that emerged during the first years of BrainScaleS. Indeed,
the collaborations that were initiated within the consortium led to the creation of novel tools as
planned in the proposal but also some of which were unforeseen, like the Motion Clouds that we
presented previously. We present here some prototypical and inspiring examples of such
collaborative work on: 1) tool chains from experimental (Davison), computational (Antolik) or integrative (Petrovici)
perspectives, 2) original methods inspired by novel types of analysis for propagating waves (Schmidt, Muller) or by
novel magnetrodes (Pannetier Lecoeur).},
    author = {Perrinet, Laurent U},
    bdsk-url-1 = {https://laurentperrinet.github.io/talk/2013-03-21-marseille/},
    booktitle = {3rd BrainScaleS Plenary Meeting - Friday, March 21st, 2013},
    date-modified = {2020-08-10 11:44:25 +0200},
    grants = {brain-scales},
    note = {Location: INT, Marseille.},
    projects = {open-science},
    title = {Why methods and tools are the key to artificial brain-like systems},
    url = {https://laurentperrinet.github.io/talk/2013-03-21-marseille/},
    year = {2013}
}

@inproceedings{2013-07-05_Cerco,
    author = {Perrinet, Laurent U and Fitzpatrick, David and Bednar, James A},
    bdsk-url-1 = {https://laurentperrinet.github.io/talk/2013-07-05-cerco/},
    booktitle = {CerCo 20th anniversary},
    date-modified = {2020-08-10 11:44:25 +0200},
    grants = {brain-scales},
    keywords = {Biologically Inspired Computer vision},
    location = {CerCo, Toulouse},
    time_start = {2013-07-05T13:00:00},
    title = {Edge co-occurrences and categorizing natural images},
    url = {https://laurentperrinet.github.io/talk/2013-07-05-cerco/},
    year = {2013}
}

@inproceedings{2013-11-26_BrainScalesDemos,
    author = {Kaplan, Bernhard A and Perrinet, Laurent U},
    bdsk-url-1 = {https://laurentperrinet.github.io/talk/2013-11-26-brain-scales-demos/},
    booktitle = {Demo 1-3: Apparent Motion in V1/ MT/MST: Neural Implementation of Probabilistic Approaches},
    date-modified = {2020-08-10 11:44:25 +0200},
    grants = {brain-scales},
    projects = {open-science},
    title = {Demo 1, Task4: Implementation of models showing emergence of cortical fields and maps},
    url = {https://laurentperrinet.github.io/talk/2013-11-26-brain-scales-demos/},
    year = {2013}
}

@inproceedings{2014-01-10_INTFest,
    abstract = {Moving objects generate sensory information that may be noisy and ambiguous, yet it is important to be able to reconstruct object speed as fast as possible. One unsolved question is to understand how the brain pools motion information to give an efficient response. I will present computational models of motion detection in the visual system that try to answer this question. First, sensory information is grabbed by pooling the information from different sensory neurons. This pooling is modulated by the precision of information and we will present some recent model-based behavioural results. Then I will focus on a novel model of motion-based prediction that allows to track objects on smooth trajectories. This model gives an economical description of neural mechanisms associated with the processing underlying motion detection. Finally, we will propose an exploratory hypothesis such that eye movements may be understood as the prospective response to this dynamical sensory response knowing oculomotor constraints such as delays. This line of research aims at showing that through the convergent use of models, electrophysiology or behavioural responses, the study of motion detection is an essential tool in our understanding of neural computations.},
    author = {Perrinet, Laurent U},
    bdsk-url-1 = {https://laurentperrinet.github.io/talk/2014-01-10-int-fest/},
    booktitle = {Marseille INT Fest, January 10th, 2014},
    date-modified = {2020-08-10 11:44:25 +0200},
    grants = {brain-scales},
    keywords = {Bayesian model,dynamics,eye movements,free energy,motion detection,predictive coding},
    title = {Axonal delays and on-time control of eye movements},
    url = {https://laurentperrinet.github.io/talk/2014-01-10-int-fest/},
    year = {2014}
}

@inproceedings{2014-03-20_Manchester,
    abstract = {The question how the visual system is able to create a coherent representation of a rapidly changing environment in the presence of neural delays is not fully resolved. In this paper we use an abstract probabilistic framework and a spiking neural network (SNN) implementation to investigate the role of motion-based prediction in estimating motion trajectories with delayed information sampling. In particular, we investigate how anisotropic diffusion of information may explain the development of anticipatory response in neural populations to an approaching stimulus. Inspired by a mechanism proposed by Nijhawan [2009], we use a Bayesian particle filter framework and introduce a diagonal motion-based prediction model which extrapolates the estimated response to delayed stimulus in the direction of the trajectory. In the SNN implementation, we have used anisotropic recurrent connections between excitatory cells as mechanism for motion-extrapolation. Consistent with recent experimental data collected in extracellular recordings of macaque primary visual cortex [Benvenuti et al 2011], we have simulated different trajectory lengths and have explored how anticipatory response may be dependent to the information accumulated along the trajectory. We show that both our probabilistic framework and the SNN can replicate the experimental data qualitatively. Most importantly, we highlight requirements for the development of a trajectory-dependent anticipatory response, and in particular the anisotropic nature of the diagonal motion extrapolation mechanism.},
    author = {Perrinet, Laurent U and Kaplan, Bernhard A and Khoei, Mina A and Lansner, Anders and Masson, Guillaume S},
    bdsk-url-1 = {https://laurentperrinet.github.io/talk/2014-03-20-manchester/},
    booktitle = {4th BrainScaleS Plenary meeting},
    date-modified = {2020-08-10 11:44:25 +0200},
    event_url = {https://brainscales.kip.uni-heidelberg.de/internal/jss/AttendMeeting?m=showAgenda&meetingID=45},
    grants = {brain-scales},
    location = {Manchester (UK)},
    projects = {open-science},
    time_start = {2014-03-20T13:00:00},
    title = {WP5 - Demo 1.3 : Spiking model of motion-based prediction},
    url = {https://laurentperrinet.github.io/talk/2014-03-20-manchester/},
    year = {2014}
}

@inproceedings{2014-04-25_kaplan-beijing,
    author = {Kaplan, Bernhard A and Khoei, Mina A and Lansner, Anders and Perrinet, Laurent U},
    bdsk-url-1 = {https://doi.org/10.1109/IJCNN.2014.6889847},
    booktitle = {2014 International Joint Conference on Neural Networks (IJCNN)},
    date-modified = {2020-08-10 11:44:25 +0200},
    doi = {10.1109/IJCNN.2014.6889847},
    isbn = {978-1-4799-1484-5},
    keywords = {Bayesian model,Biologically Inspired Computer vision,dynamics,motion detection},
    location = {Beijing, China},
    pages = {3205--3212},
    posted-at = {2014-04-25 08:53:37},
    priority = {2},
    publisher = {IEEE},
    title = {Signature of an anticipatory response in area V1 as modeled by a probabilistic model and a spiking neural network},
    url = {https://laurentperrinet.github.io/talk/2014-04-25-kaplan-beijing/},
    year = {2014}
}

@inproceedings{2015-10-07_GDR-BioComp,
    abstract = {We stand at a point in history where our phones have become smart but lack a feature which prevails in most forms of living intelligence: vision. The ability to see is indeed an essential facet of intelligence which is developed in an autonomous manner even in young human infants. I will focus here on a particular problem: how do we estimate motion in a visual image? I will explain why for this problem, it is crucial to understand how the visual system might overcome temporal delays and will demonstrate at different levels of description, from probabilistic models to neuromorphic hardware,  a surprising solution: The visual system models the world and uses the eye to probe this model.},
    author = {Perrinet, Laurent U},
    bdsk-url-1 = {https://laurentperrinet.github.io/talk/2015-10-07-gdr-bio-comp/},
    booktitle = {First GDR BioComp workshop},
    date-modified = {2020-08-10 11:44:25 +0200},
    event_url = {http://gdr-biocomp.fr/colloque/},
    grants = {brain-scales},
    location = {Saint-Paul de Vence},
    time_start = {2015-10-07T13:00:00},
    title = {Motion-based prediction with neuromorphic hardware},
    url = {https://laurentperrinet.github.io/talk/2015-10-07-gdr-bio-comp/},
    year = {2015}
}

@inproceedings{2015-11-05_Chile,
    abstract = {We stand at a point in history where our phones have become smart but
lack a feature which prevails in most forms of living intelligence:
vision. The ability to see is indeed an essential facet of intelligence
which is developed in an autonomous manner even in young human infants.
I will focus here on a particular problem: how do we estimate motion in
a visual image? I will explain why for this problem, it is crucial to
understand how the visual system might overcome temporal delays and will
demonstrate at different levels of description, from probabilistic
models to neuromorphic hardware,  a surprising solution: The visual
system models the world and uses the eye to probe this model},
    author = {Perrinet, Laurent U},
    bdsk-url-1 = {https://laurentperrinet.github.io/talk/2015-11-05-chile/},
    booktitle = {Charla},
    date-modified = {2020-08-10 11:44:25 +0200},
    event_url = {http://www.eventos.usm.cl/evento/charla-motion-based-prediction-with-neuromorphic-hardware/},
    grants = {anr-bala-v1},
    location = {Universidad Tecnica Federico Santa Maria, Valparaiso (Chile)},
    time_start = {2015-11-05T13:00:00},
    title = {Motion-based prediction with neuromorphic hardware},
    url = {https://laurentperrinet.github.io/talk/2015-11-05-chile/},
    year = {2015}
}

@inproceedings{2016-04-25_PollyMaggoo,
    abstract = {Ce lundi 25 avril de 9h à 12h, je suis venu échanger au côté de Serge
Dentin autour de films traitant du rapport fiction/réel, des illusion
visuelles (" Qu'est ce qu'une image? "), des rapports d'échelles, de la
perception, ... et qui sont projetés lors de la séance, avec des élèves
de 4e lors d'une séance Cinésciences au collège Clair Soleil, 53
Boulevard Charles Moretti, 13014 Marseille. Une occasion aussi de parler
du métier de chercheur.},
    author = {Perrinet, Laurent U},
    bdsk-url-1 = {https://laurentperrinet.github.io/sciblog/files/2016-04-25_pollymagoo/},
    booktitle = {Cinésciences, collège Clair Soleil (Marseille)},
    date-modified = {2020-08-10 11:44:25 +0200},
    event_url = {http://www.pollymaggoo.org/},
    location = {Marseille, France},
    projects = {tout-public},
    time_start = {2016-04-25T09:00:00},
    title = {Les illusions visuelles, un révélateur du fonctionnement de notre cerveau},
    url = {https://laurentperrinet.github.io/sciblog/files/2016-04-25_pollymagoo/},
    year = {2016}
}

@inproceedings{2016-04-28_Mejanes,
    abstract = {Les illusions visuelles sont des créations d'artistes, de
scientifiques et plus récemment, grâce aux réseaux sociaux, du grand
public qui proposent des situations souvent incongrues, dans
lesquelles l'eau remonte une cascade, les personnes volent dans les
airs ou des serpents se mettent à tourner. Au-delà de leur
indéniable coté ludique, ces illusions nous apprennent beaucoup sur
le fonctionnement du cerveau. En tant que chercheur en Neurosciences
à l'Institut de Neurosciences de la Timone à Marseille, je vous
dévoilerai des aspects du fonctionnement du cerveau qui sont
souvent méconnus. En particulier, nous verrons pourquoi un magicien
peut tromper nos sens ou comment des objets peuvent voyager dans le
temps. Surtout nous essaierons de comprendre le fonctionnement de
notre perception visuelle sur les bases d'une théorie de la vision
non pas comme une simple caméra qui enregistre des images mais comme
un processus actif en relation avec le monde qui nous entoure.},
    author = {Perrinet, Laurent U},
    bdsk-url-1 = {https://laurentperrinet.github.io/sciblog/files/2016-04-28_mejanes/},
    booktitle = {Cycle de conférences "Tous connectés", Bibliothèque de Méjanes},
    date-modified = {2020-08-10 11:44:25 +0200},
    location = {Marseille, France},
    projects = {tout-public},
    time_start = {2016-04-28T18:30:00},
    title = {Les illusions visuelles, un révélateur du fonctionnement de notre cerveau},
    url = {https://laurentperrinet.github.io/sciblog/files/2016-04-28_mejanes/},
    year = {2016}
}

@inproceedings{2016-07-07_EDP-proba,
    author = {Perrinet, Laurent U},
    bdsk-url-1 = {https://laurentperrinet.github.io/talk/2016-07-07-edp-proba/},
    booktitle = {Summer School: PDE and Probability for Life Sciences},
    date-modified = {2020-08-10 11:44:25 +0200},
    event_url = {http://scientific-events.weebly.com/prog-1426.html},
    grants = {anr-bala-v1,brain-scales},
    location = {CIRM, Marseille},
    time_start = {2016-07-07T13:00:00},
    title = {Modelling the dynamics of cognitive processes: from the Bayesian brain to particles},
    url = {https://laurentperrinet.github.io/talk/2016-07-07-edp-proba/},
    url_slides = {https://laurentperrinet.github.io/sciblog/files/2016-07-07_EDP-proba},
    year = {2016}
}

@inproceedings{2016-10-13_LAW,
    author = {Perrinet, Laurent U},
    bdsk-url-1 = {https://laurentperrinet.github.io/talk/2016-10-13-law/},
    booktitle = {Lyon Active inference Workshop (LAW)},
    date-modified = {2020-08-10 11:44:25 +0200},
    event_url = {https://law2016.sciencesconf.org/},
    grants = {anr-rem,pace-itn},
    location = {Lyon, France},
    time_start = {2016-10-13T10:00:00},
    title = {Eye movements as a model for active inference},
    url = {https://laurentperrinet.github.io/talk/2016-10-13-law/},
    url_slides = {https://laurentperrinet.github.io/sciblog/files/2016-10-13_LAW.html},
    year = {2016}
}

@inproceedings{2016-10-26_FillatreBarlaudPerrinet16EUVIP,
    author = {Fillatre, Lionel and Barlaud, Michel and Perrinet, Laurent U},
    bdsk-url-1 = {https://laurentperrinet.github.io/talk/2016-10-26-fillatre-barlaud-perrinet-16-euvip/},
    booktitle = {EUVIP Session 7: Biologically Inspired Computer Vision (Special Session)},
    date-modified = {2020-08-10 11:44:25 +0200},
    event_url = {https://laurentperrinet.github.io/post/2016-10-26_euvip-bicv/},
    keywords = {Biologically Inspired Computer vision},
    location = {Ecole Centrale Marseille},
    time_start = {2016-10-26T13:00:00},
    title = {Categorization of microscopy images using a biologically inspired edge co-occurrences descriptor},
    url = {https://laurentperrinet.github.io/talk/2016-10-26-fillatre-barlaud-perrinet-16-euvip/},
    url_code = {https://hal-amu.archives-ouvertes.fr/hal-01461404},
    url_slides = {https://laurentperrinet.github.io/sciblog/files/2016-10-26_FillatreBarlaudPerrinet16EUVIP_talk.html},
    year = {2016}
}

@inproceedings{2016-10-26_Perrinet16EUVIP,
    author = {Perrinet, Laurent U},
    bdsk-url-1 = {https://laurentperrinet.github.io/publication/perrinet-16-euvip/},
    booktitle = {EUVIP Session 7: Biologically Inspired Computer Vision (Special Session)},
    date-modified = {2020-08-10 11:44:25 +0200},
    event_url = {https://laurentperrinet.github.io/post/2016-10-26_euvip-bicv/},
    keywords = {Biologically Inspired Computer vision},
    location = {Ecole Centrale Marseille},
    time_start = {2016-10-26T13:00:00},
    title = {Biologically-inspired characterization of sparseness in natural images},
    url = {https://laurentperrinet.github.io/publication/perrinet-16-euvip/},
    url_code = {https://hal-amu.archives-ouvertes.fr/hal-01461404},
    url_slides = {https://laurentperrinet.github.io/sciblog/files/2016-10-26_Perrinet16EUVIP_talk.html},
    year = {2016}
}

@inproceedings{2016-11-03_gdr,
    abstract = {Natural environments potentially contain several interesting targets for goal-directed behavior. Thus sensorimotor systems need to operate a competitive selection based on behaviorally meaningful parameters. Recently, it has been observed that voluntary eye movements such as saccades and smooth pursuit can be considered as operant behaviors (Madelain et al, 2011). Indeed, parameters of saccades such as peak-velocity or latency (Montagnini et al, 2005) as well as smooth pursuit behavior during transient blanking (Madelain et al, 2003) or visually-guided pursuit of ambiguous stimuli (Schutz et al, 2015) can be modified by reinforcement contingencies. Here we address the question of whether expectancy-based anticipatory smooth pursuit can be modulated by reinforcement contingencies. When predictive information is available, anticipatory smooth pursuit eye movements (aSPEM) is frequently observed before target appearance. Actions that occur at some distance in time from the reinforcement outcome, such as aSPEM -which occurs without any concurrent sensory feedback suffer of the well-known credit assignment problem (Kaelbling et al, 1996). We designed a direction-bias task as a baseline and modified it by setting an implicit eye velocity criterion during anticipation. The nature of the following trial-outcome (reward or punishment) was contingent to the online criterion matching. We observed a dominant graded effect of motion-direction bias and a small modulational effect of reinforcement on aSPEM velocity. A yoked-control paradigm corroborated this result showing a strong reduction in anticipatory behavior when the reward/punishment schedule was not contingent to behavior. An additional classical conditioning paradigm confirmed that reinforcement contingencies have to be operant to be effective and that they have a role in solving the credit assignment problem during aSPEM.},
    author = {Damasse, Jean-Bernard and Perrinet, Laurent U and Jozefowiez, Jeremie and Madelain, Laurent and Montagnini, Anna},
    bdsk-url-1 = {https://laurentperrinet.github.io/talk/2016-11-03-gdr/},
    booktitle = {GDR Vision, Toulouse, Nov 3rd, 2016},
    date-modified = {2020-08-10 11:44:25 +0200},
    grants = {anr-rem,pace-itn},
    title = {Reinforcement contingencies modulate anticipatory smooth eye movements},
    url = {https://laurentperrinet.github.io/talk/2016-11-03-gdr/},
    year = {2016}
}

@inproceedings{2016-11-03_SIGMA,
    author = {Perrinet, Laurent U},
    bdsk-url-1 = {https://laurentperrinet.github.io/talk/2016-11-03-sigma/},
    booktitle = {Workshop SIGMA'2016: Signal, Image, Geometry, Modelling, Approximation},
    date-modified = {2020-08-10 11:44:25 +0200},
    grants = {pace-itn},
    location = {CIRM},
    time_start = {2016-11-03T13:00:00},
    title = {The flash-lag effect as a motion-based predictive shift},
    url = {https://laurentperrinet.github.io/talk/2016-11-03-sigma/},
    url_slides = {https://laurentperrinet.github.io/sciblog/files/2016-11-03_SIGMA.html},
    year = {2016}
}

@inproceedings{2016-11-20_PollyMaggoo,
    author = {Perrinet, Laurent U},
    bdsk-url-1 = {https://laurentperrinet.github.io/talk/2016-11-20-polly-maggoo/},
    booktitle = {Rencontres Internationales Sciences Et Cinémas},
    date-modified = {2020-08-10 11:44:25 +0200},
    event_url = {http://www.pollymaggoo.org/},
    location = {Marseille, France},
    projects = {tout-public},
    time_start = {2016-11-20T09:00:00},
    title = {Participation au jury et entretien avec Clara Delmon},
    url = {https://laurentperrinet.github.io/talk/2016-11-20-polly-maggoo/},
    year = {2016}
}

@inproceedings{2017-01-18_LACONEU,
    author = {Perrinet, Laurent U},
    bdsk-url-1 = {https://laurentperrinet.github.io/talk/2017-01-18-laconeu/},
    booktitle = {Workshop on Computational Neuroscience "New trends and challenges for 2030"},
    date-modified = {2020-08-10 11:44:25 +0200},
    event_url = {http://cinv.uv.cl/laconeu-workshop},
    grants = {anr-trajectory},
    location = {Valparaiso (Chile)},
    time_start = {2017-01-18T09:00:00},
    title = {Back to the present: how neurons deal with delays},
    url = {https://laurentperrinet.github.io/talk/2017-01-18-laconeu/},
    url_slides = {https://laurentperrinet.github.io/sciblog/files/2017-01-18_LACONEU.html},
    year = {2017}
}

@inproceedings{2017-01-19_LACONEU,
    author = {Perrinet, Laurent U},
    bdsk-url-1 = {https://laurentperrinet.github.io/talk/2017-01-19-laconeu/},
    booktitle = {LACONEU 2017: 4th Latin-American Summer School in Computational Neuroscience},
    date-modified = {2020-08-10 11:44:25 +0200},
    event_url = {http://www.laconeu.cl},
    grants = {anr-trajectory},
    keywords = {Biologically Inspired Computer vision},
    location = {Valparaiso (Chile)},
    projects = {courses,open-science},
    time_start = {2017-01-19T10:45:00},
    title = {Tutorial: Sparse optimization in neural computations},
    url = {https://laurentperrinet.github.io/talk/2017-01-19-laconeu/},
    url_slides = {https://laurentperrinet.github.io/sciblog/files/2017-01-19_LACONEU.html},
    year = {2017}
}

@inproceedings{2017-01-20_LACONEU,
    author = {Perrinet, Laurent U},
    bdsk-url-1 = {https://laurentperrinet.github.io/talk/2017-01-20-laconeu/},
    booktitle = {LACONEU 2017: 4th Latin-American Summer School in Computational Neuroscience},
    date-modified = {2020-08-10 11:44:25 +0200},
    event_url = {http://www.laconeu.cl},
    grants = {anr-trajectory},
    location = {Valparaiso (Chile)},
    projects = {courses,open-science},
    time_start = {2017-01-20T10:45:00},
    title = {Tutorial: Active inference for eye movements: Bayesian methods, neural inference, dynamics},
    url = {https://laurentperrinet.github.io/talk/2017-01-20-laconeu/},
    url_slides = {https://laurentperrinet.github.io/sciblog/files/2017-01-20_LACONEU.html},
    year = {2017}
}

@inproceedings{2017-06-28_Telluride,
    author = {Perrinet, Laurent U},
    bdsk-url-1 = {https://laurentperrinet.github.io/talk/2017-06-28-telluride},
    booktitle = {Workshop on Computational Neuroscience entitled "Neuromorphic Event-based Compound Eyes and Vision""},
    date-modified = {2020-08-10 11:44:25 +0200},
    event_url = {http://telluride.iniforum.ch/2017/workgroups/neuromorphic-event-based-compound-eyes-and-vision/},
    location = {Telluride, CO},
    time_start = {2017-06-28T13:00:00},
    title = {Back to the present: dealing with delays in biological and neuromorphic systems},
    url = {https://laurentperrinet.github.io/talk/2017-06-28-telluride},
    url_slides = {https://laurentperrinet.github.io/sciblog/files/2017-06-28_Telluride.html},
    year = {2017}
}

@inproceedings{2017-06-30_Telluride,
    author = {Perrinet, Laurent U},
    bdsk-url-1 = {https://laurentperrinet.github.io/talk/2017-06-30-telluride},
    booktitle = {Telluride Neuromorphic Workshop, Workgroup on Compound Eyes and Event-based Vision},
    date-modified = {2020-08-10 11:44:25 +0200},
    event_url = {http://telluride.iniforum.ch/2017/workgroups/neuromorphic-event-based-compound-eyes-and-vision/},
    location = {Telluride, CO},
    time_start = {2017-06-28T13:00:00},
    title = {Tutorial on predictive coding},
    url = {https://laurentperrinet.github.io/talk/2017-06-30-telluride},
    url_slides = {https://laurentperrinet.github.io/sciblog/files/2017-06-30_Telluride.html},
    year = {2017}
}

@inproceedings{2017-11-15_ColloqueMaster,
    abstract = {This seminar is an exercise to introduce the AMU masters into the format of international conferences. As such, we will try to introduce new concepts and results which will not be found in textbooks.},
    author = {Perrinet, Laurent U},
    bdsk-url-1 = {https://laurentperrinet.github.io/talk/2017-11-15-colloque-master/},
    booktitle = {Colloque : "CODAGES ET REPRESENTATIONS", MASTER DE NEUROSCIENCES 2ème année; Comité d'organisation: Francesca SARGOLINI, Christian Bénar, Paolo GUBELLINI, Christian GESTREAU},
    date-modified = {2020-08-10 11:44:25 +0200},
    location = {Aix-Marseille Université, Campus Saint-Charles, Salle des voûtes},
    time_start = {2017-11-15T13:00:00},
    title = {What dynamic neural codes for efficient visual processing},
    url = {https://laurentperrinet.github.io/talk/2017-11-15-colloque-master/},
    url_slides = {https://laurentperrinet.github.io/sciblog/files/2017-11-15_ColloqueMaster.html},
    year = {2017}
}

@inproceedings{2017-11-17_FestivalInterferences,
    author = {Perrinet, Laurent U},
    bdsk-url-1 = {https://laurentperrinet.github.io/talk/2017-11-17-festival-interferences/},
    booktitle = {Festival Interférences - Cinéma Documentaire et Débat Public},
    date-modified = {2020-08-10 11:44:25 +0200},
    event_url = {http://www.lacitedoc.com/interferences-programmation​},
    location = {Lyon, France},
    projects = {tout-public},
    time_start = {2017-11-17T18:30:00},
    title = {Participation au jury},
    url = {https://laurentperrinet.github.io/talk/2017-11-17-festival-interferences/},
    year = {2017}
}

@inproceedings{2017-11-24_NeurosciencesRobotique,
    author = {Boutin, Victor and Ruffier, Franck and Perrinet, Laurent U},
    bdsk-url-1 = {https://laurentperrinet.github.io/talk/2017-11-24-neurosciences-robotique/},
    date-modified = {2020-08-10 11:44:25 +0200},
    event_url = {http://www.isir.upmc.fr/index.php?op=view_page&id=1463&menuid=17},
    grants = {doc-2-amu},
    keywords = {sparse coding},
    location = {IMERA (Aix-Marseille Université)},
    time_start = {2017-11-24T13:00:00},
    title = {Unsupervised learning applied to robotic vision},
    url = {https://laurentperrinet.github.io/talk/2017-11-24-neurosciences-robotique/},
    year = {2017}
}

@inproceedings{2018-01-25_meetup-neuronautes,
    author = {Perrinet, Laurent U and Rey, Etienne},
    bdsk-url-1 = {https://laurentperrinet.github.io/talk/2018-01-25-meetup-neuronautes/},
    booktitle = {Meetup Art et Neurosciences, Association NeuroNautes},
    date-modified = {2020-08-10 11:44:25 +0200},
    event_url = {https://www.facebook.com/events/211121069456116/},
    keywords = {Biologically Inspired Computer vision},
    location = {Salle des voutes campus Saint Charles},
    projects = {art-science,tout-public},
    time_start = {2018-01-25T18:30:00},
    title = {Expériences autour de la perception de la forme en art et science},
    url = {https://laurentperrinet.github.io/talk/2018-01-25-meetup-neuronautes/},
    url_slides = {https://laurentperrinet.github.io/sciblog/files/2018-01-25_meetup-neuronautes.html},
    year = {2018}
}

@inproceedings{2018-02-01_BCP_INVIBE_fest,
    author = {Perrinet, Laurent U and Pasturel, Chloé and Montagnini, Anna},
    bdsk-url-1 = {https://laurentperrinet.github.io/talk/2018-02-01-bcp-invibe-fest/},
    booktitle = {Visual motion Fest - Invibe Team -- INT / Marseille February 1 and 2, 2018},
    date-modified = {2020-08-10 11:44:25 +0200},
    title = {Estimating and anticipating a dynamic probabilistic bias in visual motion direction},
    url = {https://laurentperrinet.github.io/talk/2018-02-01-bcp-invibe-fest/},
    year = {2018}
}

@inproceedings{2018-03-26_cours-NeuroComp_FEP,
    author = {Perrinet, Laurent U},
    bdsk-url-1 = {https://laurentperrinet.github.io/talk/2018-03-26-cours-neuro-comp-fep/},
    booktitle = {Course in Computational Neuroscience @ PhD program},
    date-modified = {2020-08-10 11:44:25 +0200},
    event_url = {https://laurentperrinet.github.io/post/2018-03-26-cours-neuro-comp-fep/},
    location = {INT, Marseille},
    projects = {courses,open-science},
    time_start = {2018-03-26T13:00:00},
    title = {Probabilities, Bayes and the Free-energy principle},
    url = {https://laurentperrinet.github.io/talk/2018-03-26-cours-neuro-comp-fep/},
    url_code = {https://github.com/laurentperrinet/2018-03-26_cours-NeuroComp_FEP},
    url_slides = {https://laurentperrinet.github.io/2018-03-26_cours-NeuroComp_FEP},
    year = {2018}
}

@inproceedings{2018-04-05_BCP_talk,
    author = {Perrinet, Laurent U and Pasturel, Chloé and Montagnini, Anna},
    bdsk-url-1 = {https://laurentperrinet.github.io/talk/2018-04-05-bcp-talk/},
    booktitle = {Probabilities and Optimal Inference to Understand the Brain},
    date-modified = {2020-08-10 11:44:25 +0200},
    event_url = {https://laurentperrinet.github.io/post/2018-04-05_optimal-inference-brain-workshop/},
    grants = {pace-itn},
    location = {INT, Marseille (France)},
    time_start = {2018-04-05T14:00:00},
    title = {Principles and psychophysics of Active Inference in anticipating a dynamic, switching probabilistic bias},
    url = {https://laurentperrinet.github.io/talk/2018-04-05-bcp-talk/},
    url_code = {https://github.com/laurentperrinet/2018-04-05_BCP_talk/},
    url_slides = {https://laurentperrinet.github.io/2018-04-05_BCP_talk/},
    year = {2018}
}

@inproceedings{2018-10-10_PollyMaggoo,
    author = {Perrinet, Laurent U},
    bdsk-url-1 = {https://laurentperrinet.github.io/talk/2018-10-10-polly-maggoo/},
    booktitle = {FÊTE DE LA SCIENCE 2018 : Alcazar / MERLAN},
    date-modified = {2020-08-10 11:44:25 +0200},
    event_url = {http://www.pollymaggoo.org/},
    location = {Marseille, France},
    projects = {tout-public},
    time_start = {2018-10-10T18:30:00},
    title = {Intervention fête de la science 2018},
    url = {https://laurentperrinet.github.io/talk/2018-10-10-polly-maggoo/},
    year = {2018}
}

@inproceedings{2018-10-11_BioMorphisme,
    author = {Perrinet, Laurent U},
    bdsk-url-1 = {https://laurentperrinet.github.io/sciblog/files/2018-10-11_BioMorphisme.html},
    booktitle = {in 'La modélisation de la genèse physico-mathématique du vivant' / BIOMORPHISME ET CREATION ARTISTIQUE Session 3},
    date-modified = {2020-08-10 11:44:25 +0200},
    event_url = {http://lesa.univ-amu.fr/?q=node/391},
    location = {Marseille, France},
    projects = {courses,tout-public},
    time_start = {2018-10-11T18:30:00},
    title = {La modélisation biomorphique de la perception visuelle},
    url = {https://laurentperrinet.github.io/sciblog/files/2018-10-11_BioMorphisme.html},
    year = {2018}
}

@inproceedings{2019-01-10_PollyMaggoo,
    abstract = {Le jeudi 10 janvier 2019, je suis venu échanger au côté de Serge Dentin
autour de films traitant du rapport fiction/réel, des illusion visuelles
(" Qu'est ce qu'une image? "), des rapports d'échelles, de la
perception, ... et qui sont projetés lors de la séance, avec les élèves
de deux classes de 4ème. Une occasion aussi de parler du métier de
chercheur.},
    author = {Perrinet, Laurent U},
    bdsk-url-1 = {https://laurentperrinet.github.io/talk/2019-01-10-polly-maggoo/},
    booktitle = {Cinéma et sciences : rencontre avec les collégiens marseillais},
    date-modified = {2020-08-10 11:44:25 +0200},
    event_url = {http://www.pollymaggoo.org/},
    location = {Marseille, France},
    projects = {tout-public},
    time_start = {2019-01-10T09:30:00},
    title = {Rencontre avec les collégiens marseillais},
    url = {https://laurentperrinet.github.io/talk/2019-01-10-polly-maggoo/},
    year = {2019}
}

@inproceedings{2019-01-14_LACONEU,
    author = {Perrinet, Laurent U},
    bdsk-url-1 = {https://laurentperrinet.github.io/talk/2019-01-14-laconeu/},
    booktitle = {LACONEU 2019: 5th Latin-American Summer School in Computational Neuroscience},
    date-modified = {2020-08-10 11:44:25 +0200},
    event_url = {http://www.laconeu.cl},
    grants = {anr-horizontal-v1},
    location = {Valparaiso (Chile)},
    projects = {courses,open-science},
    time_start = {2019-01-14T11:00:00},
    title = {Modelling spiking neural networks using Brian, Nest and pyNN},
    url = {https://laurentperrinet.github.io/talk/2019-01-14-laconeu/},
    url_code = {https://github.com/laurentperrinet/2019-01-14_LACONEU},
    url_slides = {https://laurentperrinet.github.io/2019-01-14_LACONEU},
    year = {2019}
}

@inproceedings{2019-01-16_LACONEU,
    author = {Perrinet, Laurent U},
    bdsk-url-1 = {https://laurentperrinet.github.io/talk/2019-01-16-laconeu/},
    booktitle = {LACONEU 2019: 5th Latin-American Summer School in Computational Neuroscience},
    date-modified = {2020-08-10 11:44:25 +0200},
    event_url = {http://www.laconeu.cl},
    grants = {anr-horizontal-v1},
    location = {Valparaiso (Chile)},
    time_start = {2019-01-16T10:45:00},
    title = {Efficient coding of visual information in neural computations},
    url = {https://laurentperrinet.github.io/talk/2019-01-16-laconeu/},
    url_code = {https://github.com/laurentperrinet/2019-01-16_LACONEU/},
    url_slides = {https://laurentperrinet.github.io/2019-01-16_LACONEU/},
    year = {2019}
}

@inproceedings{2019-01-17_LACONEU,
    author = {Perrinet, Laurent U},
    bdsk-url-1 = {https://laurentperrinet.github.io/talk/2019-01-17-laconeu/},
    booktitle = {LACONEU 2019: 5th Latin-American Summer School in Computational Neuroscience},
    date-modified = {2020-08-10 11:44:25 +0200},
    event_url = {http://www.laconeu.cl},
    grants = {anr-horizontal-v1},
    location = {Valparaiso (Chile)},
    time_start = {2019-01-17T10:45:00},
    title = {Role of dynamics in neural computations underlying visual processing},
    url = {https://laurentperrinet.github.io/talk/2019-01-17-laconeu/},
    url_code = {https://github.com/laurentperrinet/2019-01-17_LACONEU/},
    url_slides = {https://laurentperrinet.github.io/2019-01-17_LACONEU/},
    year = {2019}
}

@inproceedings{2019-01-18_LACONEU,
    author = {Perrinet, Laurent U},
    bdsk-url-1 = {https://laurentperrinet.github.io/talk/2019-01-18-laconeu/},
    booktitle = {LACONEU 2019: 5th Latin-American Summer School in Computational Neuroscience},
    date-modified = {2020-08-10 11:44:25 +0200},
    event_url = {http://www.laconeu.cl},
    grants = {anr-horizontal-v1},
    location = {Valparaiso (Chile)},
    time_start = {2019-01-18T10:45:00},
    title = {Should I stay or should I go? Adaption of human observers to the volatility of visual inputs},
    url = {https://laurentperrinet.github.io/talk/2019-01-18-laconeu/},
    url_code = {https://github.com/laurentperrinet/2019-01-18_LACONEU/},
    url_slides = {https://laurentperrinet.github.io/2019-01-18_LACONEU/},
    year = {2019}
}

@inproceedings{2019-03-25_HDR_RobinBaures,
    abstract = {Visual areas are essential in transforming the raw luminous signal into a representation which efficiently conveys information about the environment. This process is constrained by various factors such as a wide variety of changes in the characteristics of the visual image but also by the necessity to be able to respond as quickly as possible to the incoming sensory stream, for instance to drive a movement of the eyes to the location of a potential danger. To achieve this, it is believed that the visual system takes advantage of the existence of a priori knowledge in the structure of visual information, such as the regularity in the shape and motion of visual objects. As such, the predictive coding coding framework offers a unified theory to explain many of the mechanisms at the different levels of the visual system and which were unveiled by decades of study in neurophysiology and psychophysics.},
    author = {Boutin, Victor and Franciosini, Angelo and Perrinet, Laurent U},
    bdsk-url-1 = {https://laurentperrinet.github.io/2019-03-25_HDR_RobinBaures},
    booktitle = {HDR Robin Baurès, Toulouse (France)},
    date = {2019-03-25},
    date-modified = {2020-08-10 11:44:25 +0200},
    grants = {anr-horizontal-v1},
    location = {Toulouse (France)},
    time_start = {2019-03-25T14:30:00},
    title = {From the retina to action: Predictive processing in the visual system},
    url = {https://laurentperrinet.github.io/2019-03-25_HDR_RobinBaures},
    url_code = {https://github.com/laurentperrinet/2019-03-25_HDR_RobinBaures/},
    url_slides = {https://laurentperrinet.github.io/2019-03-25_HDR_RobinBaures},
    year = {2019}
}

@inproceedings{2019-04-03_a_course_on_vision_and_modelization,
    abstract = {Visual areas are essential in transforming the raw luminous signal into a representation which efficiently conveys information about the environment. This process is constrained by various factors such as a wide variety of changes in the characteristics of the visual image but also by the necessity to be able to respond as quickly as possible to the incoming sensory stream, for instance to drive a movement of the eyes to the location of a potential danger. To achieve this, it is believed that the visual system takes advantage of the existence of a priori knowledge in the structure of visual information, such as the regularity in the shape and motion of visual objects. We will review different models around the predictive coding coding framework to offer a unified theory to explain many of the mechanisms at the different levels of the visual system and which were unveiled by decades of study in neurophysiology and psychophysics.},
    author = {Perrinet, Laurent U},
    bdsk-url-1 = {https://laurentperrinet.github.io/talk/2019-04-03-a-course-on-vision-and-modelization},
    booktitle = {Licence Sciences et Humanité},
    date = {2019-04-03},
    date-modified = {2020-08-10 11:44:25 +0200},
    grants = {anr-horizontal-v1},
    location = {Marseille (France)},
    projects = {courses},
    time_end = {2019-04-03T18:00:00},
    time_start = {2019-04-03T16:00:00},
    title = {From the retina to action: Understanding visual processing},
    url = {https://laurentperrinet.github.io/talk/2019-04-03-a-course-on-vision-and-modelization},
    url_code = {https://github.com/laurentperrinet/2019-04-03_a_course_on_vision_and_modelization/},
    url_slides = {https://laurentperrinet.github.io/2019-04-03_a_course_on_vision_and_modelization},
    year = {2019}
}

@inproceedings{2019-04-05_BBCP_causal_kickoff,
    abstract = {Animal behavior has to constantly adapt to changes, for instance when unexpectedly switching the state of an environmental context. For an agent interacting with this kind of volatile environment, it is important to respond to such switches accurately and with the shortest delay. However, this operation has in general to be performed in presence of noisy sensory inputs and solely based on the accumulated information. It has already been shown that human observers can accurately anticipate the motion direction of a visual target with their eye movements when this random sequence of rightward/leftward motions is defined by a bias in direction probability. Here, we generalized the capacity of these observers to anticipate different random biases within random-length contextual blocks. Experimental results were compared to those of a probabilistic agent which is optimal with respect to this switching model. We found a better fit between the behaviorally observed anticipatory response with that of the probabilistic agent compared to other models such as a leaky integrator model. Moreover, we could similarly fit the level of confidence reported by human observers with that provided by the model and derive a common marker for subject inter-variability, titrating their level of preference between exploration and exploitation. Such results provide evidence that in such a volatile environment human observers may still efficiently represent an internal belief, along with its precision, and use this representation for sensorimotor control as well as for explicit judgments. This work proposes a novel approach to more generically test human cognitive abilities in uncertain and dynamic environments.},
    author = {Perrinet, Laurent U},
    bdsk-url-1 = {https://laurentperrinet.github.io/talk/2019-04-05-bbcp-causal-kickoff},
    booktitle = {CausaL Kick-off},
    date = {2019-04-05},
    date-modified = {2020-08-10 11:44:25 +0200},
    grants = {anr-causal},
    location = {INT, Marseille (France)},
    time_start = {2019-04-05T15:45:00},
    title = {Should I stay or should I go? Adaption of human observers to the volatility of visual inputs},
    url = {https://laurentperrinet.github.io/talk/2019-04-05-bbcp-causal-kickoff},
    url_code = {https://github.com/laurentperrinet/2019-04-05_BBCP_causal_kickoff/},
    url_slides = {https://laurentperrinet.github.io/2019-04-05_BBCP_causal_kickoff},
    year = {2019}
}

@inproceedings{2019-04-18_JNLF,
    abstract = {Les illusions visuelles sont des créations d'artistes, de scientifiques et plus récemment, grâce aux réseaux sociaux, du grand public qui proposent des situations souvent incongrues, dans lesquelles l'eau remonte une cascade, les personnes volent dans les airs ou des serpents se mettent à tourner. Au-delà de leur indéniable coté ludique, ces illusions nous apprennent beaucoup sur le fonctionnement du cerveau, notamment quand celles-ci se transforment en hallucinations visuelles, dépassant ainsi les limites des capacités de notre perception. En tant que chercheur en Neurosciences à l'Institut de Neurosciences de la Timone à Marseille, je vous dévoilerai des aspects du fonctionnement du cerveau qui sont souvent méconnus. En particulier, nous verrons pourquoi un magicien peut tromper nos sens ou comment des objets peuvent voyager dans le temps. Surtout nous essaierons de comprendre le fonctionnement de notre perception visuelle sur les bases d'une théorie de la vision non pas comme une simple caméra qui enregistre des images mais comme un processus actif en relation avec le monde qui nous entoure.},
    author = {Perrinet, Laurent U},
    bdsk-url-1 = {https://laurentperrinet.github.io/talk/2019-04-18_jnlf},
    booktitle = {JNLF 2019, Revue Neurologique, Volume 175, Supplement 1, Page S165},
    date-modified = {2020-08-10 11:44:25 +0200},
    doi = {10.1016/j.neurol.2019.01.031},
    event_url = {https://www.jnlf.fr/agenda/jnlf-lille-2019},
    grants = {anr-horizontal-v1},
    location = {Lille, France},
    preprint = {https://www.em-consulte.com/e-tap/1283936/ftafhrsrftfxjyjaaumj},
    projects = {tout-public},
    summary = {Les objectifs sont : -- mieux comprendre la fonction de la perception visuelle en explorant certaines limites ; -- mieux comprendre l'importance de l'aspect dynamique de la perception ; -- mieux comprendre le rôle de l'action dans la perception.},
    time_start = {2019-04-18T13:00:00},
    title = {Des illusions aux hallucinations visuelles: une porte sur la perception},
    url = {https://laurentperrinet.github.io/talk/2019-04-18-jnlf},
    url_code = {https://github.com/laurentperrinet/2019-04-18_JNLF/},
    url_slides = {https://laurentperrinet.github.io/2019-04-18_JNLF},
    year = {2019}
}

@inproceedings{2019-05-23_Neurofrance,
    abstract = {Animal behavior must constantly adapt to changes, for example when the state of an environmental context changes unexpectedly. For an agent that interacts with this volatile setting, it is important to react accurately and as quickly as possible. For example, it has already been shown that when a random sequence of directions of motion to the right or left of a visual target is suddenly biased to one direction, human observers adapt to accurately anticipate it with their eye movements. Here, we prove that this ability extends to a volatile environment where probability biases could change at random switching times. In addition, we also recorded the level of confidence reported by human observers. These results were compared to those of a probabilistic agent that is optimal in relation to the event switching generating model. Compared to other models such as the leaky integrator, we found a better match between the behavioral response observed and that given by this agent. Furthermore, we were also able to fit the experimental data with different levels of switching volatility in the model and derive a common marker for the inter-variability of participants, by titrating their level of preference between exploration and exploitation. Such results prove that in such an unstable environment, human observers can still effectively represent an internal belief, and use this representation in their sensory-motor control system and for explicit judgments. This work offers an innovative approach to more generically test human cognitive abilities in uncertain and dynamic environments.},
    author = {Perrinet, Laurent U},
    bdsk-url-1 = {https://laurentperrinet.github.io/talk/2019-05-23-neurofrance},
    booktitle = {Colloque international de la Société Française des Neurosciences 2019},
    date = {2019-05-23},
    date-modified = {2020-08-10 11:44:25 +0200},
    grants = {pace-itn},
    location = {Marseille (France)},
    time_start = {2019-05-23T1:30:00},
    title = {Should I stay or should I go? Humans adapt to the volatility of visual motion properties, and know about it},
    url = {https://laurentperrinet.github.io/talk/2019-05-23-neurofrance},
    url_code = {https://github.com/invibe/2019-05-23_Neurofrance/},
    url_pdf = {https://github.com/invibe/2019-05-23_Neurofrance/raw/master/2019-05-23_Neurofrance.pdf},
    url_slides = {https://invibe.github.io/2019-05-23_Neurofrance},
    year = {2019}
}

@inproceedings{2019-07-15_CNS,
    abstract = {In computer vision, the visual search task consists in extracting a scarce and specific visual information (the target) from a large and crowded visual display. This task is usually implemented by scanning the different possible target identities at all possible spatial positions, hence with strong computational load. The human visual system employs a different strategy, combining a foveated sensor with the capacity to rapidly move the center of fixation using saccades. Saccade-based visual exploration can be idealized as an inference process, assuming that the target position and category are independently drawn from a common generative process. Knowing that process, visual processing is then separated in two specialized pathways, the where pathway mainly conveying information about target position in peripheral space, and the what pathway mainly conveying information about the category of the target. We consider here a dual neural network architecture learning independently where to look and then at what to see. This allows in particular to infer target position in retinotopic coordinates, independently to its category. This framework was tested on a simple task of finding digits in a large, cluttered image. Simulation results demonstrate the benefit of specifically learning where to look before actually knowing the target category. The approach is also energy-efficient as it includes the strong compression rate performed at the sensor level, by retina and V1 encoding, which is preserved up to the action selection level, highlighting the advantages of bio-mimetic strategies with regards to traditional computer vision when computing resources are at stake.},
    author = {Daucé, Emmanuel and Albigès, Pierre and Perrinet, Laurent U},
    bdsk-url-1 = {https://laurentperrinet.github.io/talk/2019-07-15-cns},
    booktitle = {CNS*2019 Barcelona, Spain},
    date-added = {2019-06-18 10:28:31 +0200},
    date-modified = {2020-08-10 11:44:35 +0200},
    grants = {spikeai},
    keywords = {Active Inference,Deep Learning,Object localization,Visual search,Visuomotor control},
    time_start = {2019-07-15T12:20:00},
    title = {Learning where to look: a foveated visuomotor control model},
    url = {https://bmcneurosci.biomedcentral.com/articles/10.1186/s12868-019-0538-0#Sec73},
    url_code = {https://github.com/SpikeAI/2019-07-15_CNS/},
    url_pdf = {https://github.com/SpikeAI/2019-07-15_CNS/raw/master/2019-07-15_CNS.pdf},
    url_slides = {https://SpikeAI.github.io/2019-07-15_CNS},
    year = {2019}
}

@inproceedings{2020-01-20_atelier_sciences_cinema,
    abstract = {Les illusions visuelles sont des créations d'artistes, de scientifiques et plus récemment, grâce aux réseaux sociaux, du grand public qui proposent des situations souvent incongrues, dans lesquelles l'eau remonte une cascade, les personnes volent dans les airs ou des serpents se mettent à tourner. Au-delà de leur indéniable coté ludique, ces illusions nous apprennent beaucoup sur le fonctionnement du cerveau, notamment quand celles-ci se transforment en hallucinations visuelles, dépassant ainsi les limites des capacités de notre perception. En tant que chercheur en Neurosciences à l'Institut de Neurosciences de la Timone à Marseille, je vous dévoilerai des aspects du fonctionnement du cerveau qui sont souvent méconnus. En particulier, nous verrons pourquoi un magicien peut tromper nos sens ou comment des objets peuvent voyager dans le temps. Surtout nous essaierons de comprendre le fonctionnement de notre perception visuelle sur les bases d'une théorie de la vision non pas comme une simple caméra qui enregistre des images mais comme un processus actif en relation avec le monde qui nous entoure.},
    author = {Perrinet, Laurent U},
    bdsk-url-1 = {https://laurentperrinet.github.io/talk/2020-01-20-atelier-sciences-cinema},
    booktitle = {Cinéma et sciences : rencontre avec les élèves du lycée des métiers},
    date = {2020-01-20},
    date-modified = {2020-08-10 11:44:25 +0200},
    event_url = {http://www.pollymaggoo.org/},
    location = {Lycée Professionnel Domaine Eguille, Vedène (France)},
    projects = {tout-public},
    time_start = {2020-01-20T10:00:00},
    title = {Des illusions aux hallucinations visuelles: une porte sur la perception},
    url = {https://laurentperrinet.github.io/talk/2020-01-20-atelier-sciences-cinema},
    url_code = {https://github.com/laurentperrinet/2020-01-20_atelier_sciences_cinema/},
    url_slides = {https://laurentperrinet.github.io/2020-01-20_atelier_sciences_cinema},
    year = {2020}
}

@inproceedings{2020-04_UE-neurosciences-computationnelles,
    abstract = {Visual areas are essential in transforming the raw luminous signal into a representation which efficiently conveys information about the environment. This process is constrained by various factors such as a wide variety of changes in the characteristics of the visual image but also by the necessity to be able to respond as quickly as possible to the incoming sensory stream, for instance to drive a movement of the eyes to the location of a potential danger. To achieve this, it is believed that the visual system takes advantage of the existence of a priori knowledge in the structure of visual information, such as the regularity in the shape and motion of visual objects. We will review different models around the predictive coding coding framework to offer a unified theory to explain many of the mechanisms at the different levels of the visual system and which were unveiled by decades of study in neurophysiology and psychophysics.},
    author = {Perrinet, Laurent U},
    bdsk-url-1 = {https://laurentperrinet.github.io/talk/2019-04-03-a-course-on-vision-and-modelization},
    booktitle = {Master Neurosciences et Sciences Cognitives},
    date = {2020-04-03},
    date-added = {2020-04-03 13:06:24 +0200},
    date-modified = {2020-08-10 11:44:25 +0200},
    grants = {anr-horizontal-v1},
    location = {Marseille (France)},
    projects = {courses},
    time_end = {2020-04-03T18:00:00},
    time_start = {2020-04-03T16:00:00},
    title = {From the retina to action: Understanding visual processing},
    url_code = {https://github.com/laurentperrinet/2020-04_UE-neurosciences-computationnelles},
    url_link = {https://laurentperrinet.github.io/talk/2020-04_UE-neurosciences-computationnelles},
    year = {2020}
}

@inproceedings{2020-09-14_IWAI,
    abstract = {Visual search is an essential cognitive ability, offering a prototypical control problem to be addressed with Active Inference. Under a Naive Bayes assumption, the maximization of the information gain objective is consistent with the separation of the visual sensory flow in two independent pathways, namely the "What" and the "Where" pathways. On the "What" side, the processing of the central part of the visual field (the fovea) provides the current interpretation of the scene, here the category of the target. On the "Where" side, the processing of the full visual field (at lower resolution) is expected to provide hints about future central foveal processing given the potential realization of saccadic movements. A map of the classification accuracies, as obtained by such counterfactual saccades, defines a utility function on the motor space, whose maximal argument prescribes the next saccade. The comparison of the foveal and the peripheral predictions finally forms an estimate of the future information gain, providing a simple and resource-efficient way to implement information gain seeking policies in active vision. This dual-pathway information processing framework is found efficient on a synthetic visual search task and we show here quantitatively the role of the precision encoded within the accuracy map. More importantly, it is expected to draw connections toward a more general actor-critic principle in action selection, with the accuracy of the central processing taking the role of a value (or intrinsic reward) of the previous saccade.},
    author = {Daucé, Emmanuel and Perrinet, Laurent},
    bdsk-url-1 = {https://laurentperrinet.github.io/talk/2019-07-15-cns},
    booktitle = {IWAI*2020},
    date = {2020-09-14},
    date-added = {2020-08-28 10:23:26 +0200},
    date-modified = {2020-08-28 10:23:58 +0200},
    location = {Ghent (Belgium), gone virtual},
    projects = {laurentperrinet},
    time_start = {2020-09-14T12:40:00},
    title = {Visual search as active inference},
    url_code = {https://github.com/laurentperrinet/2020-09-14_IWAI/},
    url_slides = {https://laurentperrinet.github.io/2020-09-14_IWAI},
    year = {2020}
}

@inproceedings{template,
    date-added = {2019-02-25 09:54:59 +0100},
    date-modified = {2020-04-03 12:55:53 +0200},
    grants = {anr-bala-v1,anr-causal,anr-horizontal-v1,anr-predicteye,anr-rem,anr-speed,anr-trajectory,brain-scales,codde,doc-2-amu,facets,facets-itn,pace-itn,phd-icn},
    keywords = {active inference,Aperture problem,area-v1,association field,Bayesian model,Biologically Inspired Computer vision,center-surround interactions,coding decoding,computational neuroscience,dynamics,eye movements,feed-forward_inhibition,free energy,gain control,homeostasis,Image texture,inhibition,large-scale_networks,lateral connections,log-gabor,matching pursuit,motion detection,motion prediction,motion-clouds,Object motion,predictive coding,psychophysics,pynn,rank-order-coding,receptive field,recursive inference,Retina,Smooth pursuit eye movement,sparse coding,sparse hebbian learning,sparselets,spike,spikeai,staistics of natural images,stdp,Temporal evolution.,unsupervised learning,visual perception},
    projects = {open-science},
    time_start = {2019-04-18T13:00:00},
    year = {2019}
}

