%% This BibTeX bibliography file was created using BibDesk.
%% http://bibdesk.sourceforge.net/


%% Created for Laurent Perrinet at 2019-02-25 23:36:16 +0100 


%% Saved with string encoding Unicode (UTF-8) 



@article{template,
	Date-Added = {2019-02-25 09:54:59 +0100},
	Date-Modified = {2019-02-25 23:17:47 +0100},
	Keywords = {sparselets,Aperture problem,dynamics,unsupervised learning,stdp,staistics of natural images,pynn,association field,motion-clouds,receptive field,active inference,lateral connections,log-gabor,large-scale_networks,sparse hebbian learning,recursive inference,computational neuroscience,Object motion,homeostasis,area-v1,Image texture,psychophysics,sparse coding,center-surround interactions,Smooth pursuit eye movement,rank-order-coding,motion prediction,Biologically Inspired Computer vision,eye movements,predictive coding,feed-forward_inhibition,free energy,visual perception,Retina,matching pursuit,gain control,inhibition,motion detection,coding decoding,spike,Bayesian model,Temporal evolution.},
	Projects = {anr-bala-v1; brain-scales; facets; facets-itn; anr-causal; anr-horizontal-v1; anr-predicteye; anr-rem; anr-speed; doc-2-amu; anr-trajectory; phd-icn; facets-itn; brain-scales; facets; phd-icn; codde; pace-itn},
	Time_Start = {2019-04-18T13:00:00},
	Year = {2019}}

@inproceedings{2016-07-07_EDP-proba,
	Author = {Perrinet, Laurent U},
	Booktitle = {Summer School: PDE and Probability for Life Sciences},
	Date-Modified = {2019-02-25 23:17:47 +0100},
	Event_Url = {http://scientific-events.weebly.com/prog-1426.html},
	Location = {CIRM, Marseille},
	Projects = {anr-bala-v1; brain-scales},
	Time_Start = {2016-07-07T13:00:00},
	Title = {Modelling the dynamics of cognitive processes: from the Bayesian brain to particles},
	Url = {http://invibe.net/LaurentPerrinet/Presentations/2016-07-07_EDP-proba},
	Url_Slides = {https://laurentperrinet.github.io/sciblog/files/2016-07-07_EDP-proba},
	Year = {2016},
	Bdsk-Url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2016-07-07_EDP-proba}}

@inproceedings{2011-10-05_BrainScalesESS,
	Author = {Perrinet, Laurent U},
	Booktitle = {Using the ESS + Neuromorphic hardware Workshop},
	Date-Modified = {2019-02-25 23:17:47 +0100},
	Event_Url = {https://brainscales.kip.uni-heidelberg.de/jss/AttendMeeting?m=showAgenda&meetingID=15},
	Keywords = {sparse coding},
	Location = {TU Dresden, Germany},
	Projects = {brain-scales},
	Time_Start = {2011-10-05T13:00:00},
	Title = {Demo 1, Task4: Implementation of models showing emergence of cortical fields and maps},
	Url = {http://invibe.net/LaurentPerrinet/Presentations/2011-10-05_BrainScalesESS},
	Url_Slides = {http://invibe.net/LaurentPerrinet/Presentations/2011-10-05_BrainScalesESS?action=AttachFile&do=get&target=perrinet11brainscales_talk.pdf},
	Year = {2011},
	Bdsk-Url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2011-10-05_BrainScalesESS}}

@inproceedings{2018-01-25_meetup-neuronautes,
	Author = {Perrinet, Laurent U and Rey, Etienne},
	Booktitle = {Meetup Art et Neurosciences, Association NeuroNautes},
	Date-Modified = {2019-02-25 10:27:44 +0100},
	Event_Url = {https://www.facebook.com/events/211121069456116/},
	Keywords = {Biologically Inspired Computer vision},
	Location = {Salle des voutes campus Saint Charles},
	Time_Start = {2018-01-25T13:00:00},
	Title = {Exp{\'e}riences autour de la perception de la forme en art et science},
	Url = {https://laurentperrinet.github.io/talk/2018-01-25-meetup-neuronautes/},
	Url_Slides = {https://laurentperrinet.github.io/sciblog/files/2018-01-25_meetup-neuronautes.html},
	Year = {2018},
	Bdsk-Url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2018-01-25_meetup-neuronautes}}

@inproceedings{2017-11-15_ColloqueMaster,
	Abstract = {This seminar is an exercise to introduce the AMU masters into the format of international conferences. As such, we will try to introduce new concepts and results which will not be found in textbooks.},
	Author = {Perrinet, Laurent U},
	Booktitle = {Colloque : "CODAGES ET REPRESENTATIONS", MASTER DE NEUROSCIENCES 2{\`e}me ann{\'e}e; Comit{\'e} d'organisation: Francesca SARGOLINI, Christian B{\'e}nar, Paolo GUBELLINI, Christian GESTREAU},
	Date-Modified = {2019-02-25 22:16:13 +0100},
	Location = {Aix-Marseille Universit{\'e}, Campus Saint-Charles, Salle des vo{\^u}tes},
	Note = {References:: <<BR>> - unsupervised learning : [[Publications/Perrinet10shl|Perrinet (2010)]] <<BR>> - [[Publications/CristobalPerrinetKeil15bicv|Biologically inspired computer vision]] <<BR>> - supervised learning : https://www.nature.com/articles/srep11400 ([[http://invibe.net/LaurentPerrinet/Publications/PerrinetBednar15|more info]] ) <<BR>> - dynamics: Khoei et al (2017) - http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005068 ( [[Publications/KhoeiMassonPerrinet17|more info]] )},
	Time_Start = {2017-11-15T13:00:00},
	Title = {What dynamic neural codes for efficient visual processing},
	Url = {http://invibe.net/LaurentPerrinet/Presentations/2017-11-15_ColloqueMaster},
	Url_Slides = {https://laurentperrinet.github.io/sciblog/files/2017-11-15_ColloqueMaster.html},
	Year = {2017},
	Bdsk-Url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2017-11-15_ColloqueMaster}}

@inproceedings{2016-11-03_SIGMA,
	Author = {Perrinet, Laurent U},
	Booktitle = {Workshop SIGMA'2016: Signal, Image, Geometry, Modelling, Approximation},
	Date-Modified = {2019-02-25 23:35:53 +0100},
	Location = {CIRM},
	Projects = {pace-itn},
	Time_Start = {2016-11-03T13:00:00},
	Title = {The flash-lag effect as a motion-based predictive shift},
	Url = {http://invibe.net/LaurentPerrinet/Presentations/2016-11-03_SIGMA},
	Url_Slides = {https://laurentperrinet.github.io/sciblog/files/2016-11-03_SIGMA.html},
	Year = {2016},
	Bdsk-Url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2016-11-03_SIGMA}}

@inproceedings{2012-01-12_VisionAtUcl,
	Abstract = {In low-level sensory systems, it is still unclear how the noisy information collected locally by neurons may give rise to a coherent global percept. This is well demonstrated for the detection of motion in the aperture problem: as luminance of an elongated line is symmetrical along its axis, tangential velocity is ambiguous when measured locally. Here, we develop the hypothesis that motion-based predictive coding is sufficient to infer global motion. Our implementation is based on a context-dependent diffusion of a probabilistic representation of motion. We observe in simulations a progressive solution to the aperture problem similar to psychophysics and behavior. We demonstrate that this solution is the result of  two underlying mechanisms. First, we demonstrate the formation of a tracking behavior favoring temporally coherent features independently of their texture. Second, we observe that incoherent features are explained away while coherent information diffuses progressively to the global scale. Most previous models included ad-hoc mechanisms such as end-stopped cells or a selection layer to track specific luminance-based features. Here, we have proved that motion-based predictive coding, as it is  implemented in this functional model, is sufficient to solve the aperture problem. This simpler solution may give insights in the role of prediction underlying a large class of sensory computations.},
	Author = {Perrinet, Laurent U},
	Booktitle = {Vision@UCL seminar},
	Date-Modified = {2019-02-25 23:17:47 +0100},
	Keywords = {motion prediction, Bayesian model, dynamics,motion detection, motion detection,eye movements, center-surround interactions},
	Location = {Malet Place Eng Bldg 1.03 (first floor).},
	Projects = {brain-scales},
	Time_Start = {2012-01-12T17:00:00},
	Title = {Motion-based prediction is sufficient to solve the aperture problem},
	Url = {http://invibe.net/LaurentPerrinet/Presentations/2012-01-12_VisionAtUcl},
	Url_Slides = {http://invibe.net/LaurentPerrinet/Presentations/2012-01-12_VisionAtUcl?action=AttachFile&do=get&target=perrinet12ucl_handout.pdf},
	Year = {2012},
	Bdsk-Url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2012-01-12_VisionAtUcl}}

@inproceedings{2015-10-07_GDR-BioComp,
	Abstract = {We stand at a point in history where our phones have become smart but lack a feature which prevails in most forms of living intelligence: vision. The ability to see is indeed an essential facet of intelligence which is developed in an autonomous manner even in young human infants. I will focus here on a particular problem: how do we estimate motion in a visual image? I will explain why for this problem, it is crucial to understand how the visual system might overcome temporal delays and will demonstrate at different levels of description ---from probabilistic models to neuromorphic hardware---  a surprising solution: The visual system models the world and uses the eye to probe this model.},
	Author = {Perrinet, Laurent U},
	Booktitle = {First GDR BioComp workshop},
	Date-Modified = {2019-02-25 23:17:47 +0100},
	Event_Url = {http://gdr-biocomp.fr/colloque/},
	Location = {Saint-Paul de Vence},
	Projects = {brain-scales},
	Time_Start = {2015-10-07T13:00:00},
	Title = {Motion-based prediction with neuromorphic hardware},
	Url = {http://invibe.net/LaurentPerrinet/Presentations/2015-10-07_GDR-BioComp},
	Url_Slides = {http://invibe.net/LaurentPerrinet/Presentations/2015-10-07_GDR-BioComp?action=AttachFile&do=view&target=Perrinet15biocomp_slides.pdf},
	Year = {2015},
	Bdsk-Url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2015-10-07_GDR-BioComp}}

@inproceedings{2013-07-05_Cerco,
	Author = {Perrinet, Laurent U and Fitzpatrick, David and Bednar, James A.},
	Booktitle = {CerCo 20th anniversary},
	Date-Modified = {2019-02-25 23:17:47 +0100},
	Keywords = {Biologically Inspired Computer vision},
	Location = {CerCo, Toulouse},
	Projects = {brain-scales},
	Time_Start = {2013-07-05T13:00:00},
	Title = {Edge co-occurrences and categorizing natural images},
	Url = {http://invibe.net/cgi-bin/index.cgi/Presentations/2013-07-05_Cerco},
	Url_Slides = {http://invibe.net/LaurentPerrinet/Presentations/2013-07-05_Cerco?action=AttachFile&do=get&target=perrinet13cerco.pdf},
	Year = {2013},
	Bdsk-Url-1 = {http://invibe.net/cgi-bin/index.cgi/Presentations/2013-07-05_Cerco}}

@inproceedings{2014-03-20_Manchester,
	Abstract = {The question how the visual system is able to create a coherent representation of a rapidly changing environment in the presence of neural delays is not fully resolved. In this paper we use an abstract probabilistic framework and a spiking neural network (SNN) implementation to investigate the role of motion-based prediction in estimating motion trajectories with delayed information sampling. In particular, we investigate how anisotropic diffusion of information may explain the development of anticipatory response in neural populations to an approaching stimulus. Inspired by a mechanism proposed by Nijhawan [2009], we use a Bayesian particle filter framework and introduce a diagonal motion-based prediction model which extrapolates the estimated response to delayed stimulus in the direction of the trajectory. In the SNN implementation, we have used anisotropic recurrent connections between excitatory cells as mechanism for motion-extrapolation. Consistent with recent experimental data collected in extracellular recordings of macaque primary visual cortex [Benvenuti et al 2011], we have simulated different trajectory lengths and have explored how anticipatory response may be dependent to the information accumulated along the trajectory. We show that both our probabilistic framework and the SNN can replicate the experimental data qualitatively. Most importantly, we highlight requirements for the development of a trajectory-dependent anticipatory response, and in particular the anisotropic nature of the diagonal motion extrapolation mechanism.},
	Author = {Perrinet, Laurent U and Kaplan, Bernhard A and Khoei, Mina A. and Lansner, Anders and Masson, Guillaume S},
	Booktitle = {4th BrainScaleS Plenary meeting},
	Date-Modified = {2019-02-25 23:17:47 +0100},
	Event_Url = {https://brainscales.kip.uni-heidelberg.de/internal/jss/AttendMeeting?m=showAgenda&meetingID=45},
	Location = {Manchester (UK)},
	Projects = {brain-scales},
	Time_Start = {2014-03-20T13:00:00},
	Title = {WP5 - Demo 1.3 : Spiking model of motion-based prediction},
	Url = {http://invibe.net/LaurentPerrinet/Presentations/2014-03-20_Manchester},
	Url_Slides = {http://invibe.net/LaurentPerrinet/Presentations/2014-03-20_Manchester?action=AttachFile&do=get&target=14-03-20_BK_LP_MK_handout.pdf},
	Year = {2014},
	Bdsk-Url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2014-03-20_Manchester}}

@inproceedings{2016-10-26_FillatreBarlaudPerrinet16EUVIP,
	Author = {Fillatre, Lionel and Barlaud, Michel and Perrinet, Laurent U},
	Booktitle = {EUVIP Session 7: Biologically Inspired Computer Vision (Special Session)},
	Date-Modified = {2019-02-25 10:27:44 +0100},
	Event_Url = {http://invibe.net/LaurentPerrinet/Events/2016-10-26_EUVIP_BICV},
	Keywords = {Biologically Inspired Computer vision},
	Location = {Ecole Centrale Marseille},
	Time_Start = {2016-10-26T13:00:00},
	Title = {Categorization of microscopy images using a biologically inspired edge co-occurrences descriptor},
	Url = {http://invibe.net/LaurentPerrinet/Presentations/2016-10-26_FillatreBarlaudPerrinet16EUVIP},
	Url_Code = {https://hal-amu.archives-ouvertes.fr/hal-01461404},
	Url_Slides = {https://laurentperrinet.github.io/sciblog/files/2016-10-26_FillatreBarlaudPerrinet16EUVIP_talk.html},
	Year = {2016},
	Bdsk-Url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2016-10-26_FillatreBarlaudPerrinet16EUVIP}}

@inproceedings{2016-10-26_Perrinet16EUVIP,
	Author = {Perrinet, Laurent U},
	Booktitle = {EUVIP Session 7: Biologically Inspired Computer Vision (Special Session)},
	Date-Modified = {2019-02-25 10:27:44 +0100},
	Event_Url = {http://invibe.net/LaurentPerrinet/Events/2016-10-26_EUVIP_BICV},
	Keywords = {Biologically Inspired Computer vision},
	Location = {Ecole Centrale Marseille},
	Note = {Conference paper http://invibe.net/LaurentPerrinet/Presentations/2016-10-26_Perrinet16EUVIP},
	Time_Start = {2016-10-26T13:00:00},
	Title = {Biologically-inspired characterization of sparseness in natural images},
	Url = {http://invibe.net/LaurentPerrinet/Presentations/2016-10-26_Perrinet16EUVIP},
	Url_Code = {https://hal-amu.archives-ouvertes.fr/hal-01461404},
	Url_Slides = {https://laurentperrinet.github.io/sciblog/files/2016-10-26_Perrinet16EUVIP_talk.html},
	Year = {2016},
	Bdsk-Url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2016-10-26_Perrinet16EUVIP}}

@inproceedings{2015-11-05_Chile,
	Abstract = {
We stand at a point in history where our phones have become smart but
lack a feature which prevails in most forms of living intelligence:
vision. The ability to see is indeed an essential facet of intelligence
which is developed in an autonomous manner even in young human infants.
I will focus here on a particular problem: how do we estimate motion in
a visual image? I will explain why for this problem, it is crucial to
understand how the visual system might overcome temporal delays and will
demonstrate at different levels of description ---from probabilistic
models to neuromorphic hardware---  a surprising solution: The visual
system models the world and uses the eye to probe this model},
	Author = {Perrinet, Laurent U},
	Booktitle = {Charla},
	Date-Modified = {2019-02-25 22:46:46 +0100},
	Event_Url = {http://www.eventos.usm.cl/evento/charla-motion-based-prediction-with-neuromorphic-hardware/},
	Location = {Universidad T{\'e}cnica Federico Santa Marı́a, Valpara\{\'s}o, Chile},
	Projects = {anr-bala-v1},
	Time_Start = {2015-11-05T13:00:00},
	Title = {Motion-based prediction with neuromorphic hardware},
	Url = {http://invibe.net/LaurentPerrinet/Presentations/2015-11-05_Chile},
	Year = {2015},
	Bdsk-Url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2015-11-05_Chile}}

@inproceedings{2012-03-22_Juelich,
	Author = {Perrinet, Laurent U},
	Booktitle = {Second BrainScaleS plenary Meeting - WP4},
	Date-Modified = {2019-02-25 23:17:47 +0100},
	Location = {Forschungszentrum J{\"u}lich},
	Projects = {brain-scales},
	Time_Start = {2012-03-22T14:00:00},
	Title = {Motion Clouds: Model-based stimulus synthesis of natural-like random textures for the study of motion perception},
	Url = {http://invibe.net/LaurentPerrinet/Presentations/2012-03-22_Juelich},
	Url_Slides = {http://invibe.net/LaurentPerrinet/Presentations/2012-03-22_Juelich?action=AttachFile&do=get&target=perrinet12wp4_handout.pdf},
	Year = {2012},
	Bdsk-Url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2012-03-22_Juelich}}

@inproceedings{2012-03-23_Juelich,
	Author = {Perrinet, Laurent U},
	Booktitle = {Second BrainScaleS plenary Meeting - WP5},
	Date-Modified = {2019-02-25 23:17:47 +0100},
	Location = {Forschungszentrum J{\"u}lich},
	Projects = {brain-scales},
	Time_Start = {2012-03-23T13:00:00},
	Title = {Apparent motion in V1 - Probabilistic approaches},
	Url = {http://invibe.net/LaurentPerrinet/Presentations/2012-03-23_Juelich},
	Url_Slides = {http://invibe.net/LaurentPerrinet/Presentations/2012-03-23_Juelich?action=AttachFile&do=get&target=perrinet12wp5_handout.pdf},
	Year = {2012},
	Bdsk-Url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2012-03-23_Juelich}}

@inproceedings{2017-06-28_Telluride,
	Author = {Perrinet, Laurent U},
	Booktitle = {Workshop on Computational Neuroscience entitled "Neuromorphic Event-based Compound Eyes and Vision""},
	Date-Modified = {2019-02-25 09:53:02 +0100},
	Event_Url = {http://telluride.iniforum.ch/2017/workgroups/neuromorphic-event-based-compound-eyes-and-vision/},
	Location = {Telluride, CO},
	Time_Start = {2017-06-28T13:00:00},
	Title = {Back to the present: dealing with delays in biological and neuromorphic systems},
	Url = {https://laurentperrinet.github.io/talk/2017-06-28-telluride},
	Url_Slides = {https://laurentperrinet.github.io/sciblog/files/2017-06-28_Telluride.html},
	Year = {2017},
	Bdsk-Url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2017-06-28_Telluride}}

@inproceedings{2017-06-30_Telluride,
	Author = {Perrinet, Laurent U},
	Booktitle = {Telluride Neuromorphic Workshop, Workgroup on Compound Eyes and Event-based Vision},
	Date-Modified = {2019-02-25 09:53:02 +0100},
	Event_Url = {http://telluride.iniforum.ch/2017/workgroups/neuromorphic-event-based-compound-eyes-and-vision/},
	Location = {Telluride, CO},
	Time_Start = {2017-06-28T13:00:00},
	Title = {Tutorial on predictive coding},
	Url = {https://laurentperrinet.github.io/talk/2017-06-30-telluride},
	Url_Slides = {https://laurentperrinet.github.io/sciblog/files/2017-06-30_Telluride.html},
	Year = {2017},
	Bdsk-Url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2017-06-30_Telluride}}

@inproceedings{2018-04-05_BCP_talk,
	Author = {Perrinet, Laurent U and Pasturel, Chlo{\'e} and Anna Montagnini, INT},
	Booktitle = {Probabilities and Optimal Inference to Understand the Brain},
	Date-Modified = {2019-02-25 23:35:53 +0100},
	Event_Url = {http://invibe.net/cgi-bin/index.cgi/Events/2018-04-05_OptInferBrainWorkshop},
	Location = {INT, Marseille (France)},
	Projects = {pace-itn},
	Time_Start = {2018-04-05T14:00:00},
	Title = {Principles and psychophysics of Active Inference in anticipating a dynamic, switching probabilistic bias},
	Url = {http://invibe.net/LaurentPerrinet/Presentations/2018-04-05_BCP_talk},
	Url_Code = {https://github.com/laurentperrinet/2018-04-05_BCP_talk/},
	Url_Slides = {https://laurentperrinet.github.io/2018-04-05_BCP_talk/},
	Year = {2018},
	Bdsk-Url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2018-04-05_BCP_talk}}

@inproceedings{2017-11-24_NeurosciencesRobotique,
	Author = {Boutin, Victor and Ruffier, Franck and Perrinet, Laurent U},
	Date-Modified = {2019-02-25 10:33:10 +0100},
	Event_Url = {http://www.isir.upmc.fr/index.php?op=view_page&id=1463&menuid=17},
	Keywords = {sparse coding},
	Location = {IMERA (Aix-Marseille Universit{\'e})},
	Note = {## http://www.laconeu.cl/images/Afiche_Workshop.jpg||align=right,width=50% Time:: November 24th, 2017 Venue:: Journee du GT 8 (Neurosciences - Robotique) Location:: Programme::},
	Projects = {doc-2-amu},
	Time_Start = {2017-11-24T13:00:00},
	Title = {Unsupervised learning applied to robotic vision},
	Url = {http://invibe.net/LaurentPerrinet/Presentations/2017-11-24_NeurosciencesRobotique},
	Year = {2017},
	Bdsk-Url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2017-11-24_NeurosciencesRobotique}}

@inproceedings{2016-10-13_LAW,
	Author = {Perrinet, Laurent U},
	Booktitle = {Lyon Active inference Workshop (LAW)},
	Date-Modified = {2019-02-25 23:35:53 +0100},
	Event_Url = {https://law2016.sciencesconf.org/},
	Location = {Lyon, France},
	Projects = {anr-rem; pace-itn},
	Time_Start = {2016-10-13T10:00:00},
	Title = {Eye movements as a model for active inference},
	Url = {https://laurentperrinet.github.io/talk/2016-10-13-law/},
	Url_Slides = {https://laurentperrinet.github.io/sciblog/files/2016-10-13_LAW.html},
	Year = {2016},
	Bdsk-Url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2016-10-13_LAW}}

@inproceedings{2018-03-26_cours-NeuroComp_FEP,
	Author = {Perrinet, Laurent U},
	Booktitle = {Course in Computational Neuroscience @ PhD program},
	Date-Modified = {2019-02-25 09:53:02 +0100},
	Event_Url = {http://invibe.net/LaurentPerrinet/Presentations/2018-03-26_cours-NeuroComp},
	Location = {INT, Marseille},
	Time_Start = {2018-03-26T13:00:00},
	Title = {Probabilities, Bayes and the Free-energy principle},
	Url = {https://laurentperrinet.github.io/talk/2018-03-26-cours-neuro-comp-fep/},
	Url_Code = {https://github.com/laurentperrinet/2018-03-26_cours-NeuroComp_FEP},
	Url_Slides = {https://laurentperrinet.github.io/2018-03-26_cours-NeuroComp_FEP},
	Year = {2018},
	Bdsk-Url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2018-03-26_cours-NeuroComp_FEP}}

@inproceedings{2014-04-25_kaplan-beijing,
	Author = {Kaplan, Bernhard A and Khoei, Mina A. and Lansner, Anders and Perrinet, Laurent U},
	Booktitle = {2014 International Joint Conference on Neural Networks (IJCNN)},
	Date-Modified = {2019-02-25 09:53:02 +0100},
	Doi = {10.1109/IJCNN.2014.6889847},
	Isbn = {978-1-4799-1484-5},
	Keywords = {Biologically Inspired Computer vision, dynamics,Bayesian model,motion detection},
	Location = {Beijing, China},
	Note = {* see the corresponding [[Publications/KaplanKhoei14|paper]] ## from},
	Pages = {3205--3212},
	Posted-At = {2014-04-25 08:53:37},
	Priority = {2},
	Publisher = {IEEE},
	Title = {Signature of an anticipatory response in area V1 as modeled by a probabilistic model and a spiking neural network},
	Url = {http://invibe.net/LaurentPerrinet/Publications/KaplanKhoei14},
	Year = {2014},
	Bdsk-Url-1 = {http://invibe.net/LaurentPerrinet/Publications/KaplanKhoei14},
	Bdsk-Url-2 = {https://doi.org/10.1109/IJCNN.2014.6889847}}

@inproceedings{2014-01-10_INTFest,
	Abstract = {Moving objects generate sensory information that may be noisy and ambiguous, yet it is important to be able to reconstruct object speed as fast as possible. One unsolved question is to understand how the brain pools motion information to give an efficient response. I will present computational models of motion detection in the visual system that try to answer this question. First, sensory information is grabbed by pooling the information from different sensory neurons. This pooling is modulated by the precision of information and we will present some recent model-based behavioural results. Then I will focus on a novel model of motion-based prediction that allows to track objects on smooth trajectories. This model gives an economical description of neural mechanisms associated with the processing underlying motion detection. Finally, we will propose an exploratory hypothesis such that eye movements may be understood as the prospective response to this dynamical sensory response knowing oculomotor constraints such as delays. This line of research aims at showing that through the convergent use of models, electrophysiology or behavioural responses, the study of motion detection is an essential tool in our understanding of neural computations.},
	Author = {Perrinet, Laurent U},
	Booktitle = {Marseille INT Fest, January 10th, 2014},
	Date-Modified = {2019-02-25 23:17:47 +0100},
	Keywords = {Bayesian model, dynamics, motion detection,predictive coding,eye movements, free energy},
	Note = {= ||<tablestyle="width: 40%; float: right; margin-left:20px; margin-right:20px; border-style: 0px; font-size: 8pt;"> [[MotionPerception|attachment:tsonga.png|Problem statement: optimal motor control under axonal delays.|width=100%,align="left"]] <<BR>> ''Problem statement: optimal motor control under axonal delays.'' The central nervous system has to contend with axonal delays, both at the sensory and the motor levels. For instance, in the human visuo-oculomotor system, it takes approximately $τ_s=50~\ms$ for the retinal image to reach the visual areas implicated in motion detection, and a further $τ_m=40~\ms $ to reach the oculomotor muscles. As a consequence, for a tennis player trying to intercept a ball at a speed of $20~\m· \s^-1$, the sensed physical position is $1~\m$ behind the true position (as represented here by $τ_s · {\v e}cV$), while the position at the moment of emitting the motor command will be $.8~\m$ ahead of its execution ($τ_m · ̧̌V$). Note that while the actual position of the ball when its image hits photoreceptors on the retina is approximately at $45$ degrees of eccentricity (red dotted line), the player's gaze is directed to the ball at its \emphpresent position (red line), in anticipatory fashion. Optimal control directs action (future motion of the eye) to the expected position (red dashed line) of the ball in the future --- and the racket (black dashed line) to the expected position of the ball when motor commands reach the periphery (muscles). || Time:: January 10th, 2014, 11:30am Location:: CAV/LPP - 45 rue des Saints P{\`e}res - salle H432},
	Projects = {brain-scales},
	Title = {Axonal delays and on-time control of eye movements},
	Url = {http://invibe.net/cgi-bin/index.cgi/Presentations/2014-01-10_INTFest},
	Year = {2014},
	Bdsk-Url-1 = {http://invibe.net/cgi-bin/index.cgi/Presentations/2014-01-10_INTFest}}

@inproceedings{2016-11-03_gdr,
	Author = {Damasse, Jean-Bernard and Perrinet, Laurent U and Jozefowiez, Jeremie and Madelain, Laurent and Montagnini, Anna},
	Booktitle = {GDR Vision, Toulouse, Nov 3rd, 2016},
	Date-Modified = {2019-02-25 23:35:53 +0100},
	Note = {Time:: Thursday, November 3rd, 2016 Location:: GDR-Vision 2016 - https://gdrvision2016.sciencesconf.org/ Abstract:: Natural environments potentially contain several interesting targets for goal-directed be- havior. Thus sensorimotor systems need to operate a competitive selection based on behav- iorally meaningful parameters. Recently, it has been observed that voluntary eye movements such as saccades and smooth pursuit can be considered as operant behaviors (Madelain et al, 2011). Indeed, parameters of saccades such as peak-velocity or latency (Montagnini et al, 2005) as well as smooth pursuit behavior during transient blanking (Madelain et al, 2003) or visually-guided pursuit of ambiguous stimuli (Sch ́'utz et al, 2015) can be modified by reinforcement contingencies. Here we address the question of whether expectancy-based anticipatory smooth pursuit can be modulated by reinforcement contingencies. When pre- dictive information is available, anticipatory smooth pursuit eye movements (aSPEM) is frequently observed before target appearance. Actions that occur at some distance in time from the reinforcement outcome, such as aSPEM -which occurs without any concurrent sen- sory feedback- suffer of the well-known credit assignment problem (Kaelbling et al, 1996). We designed a direction-bias task as a baseline and modified it by setting an implicit eye velocity criterion during anticipation. The nature of the following trial-outcome (reward or punishment) was contingent to the online criterion matching. We observed a dominant graded effect of motion-direction bias and a small modulational effect of reinforcement on aSPEM velocity. A yoked-control paradigm corroborated this result showing a strong reduc- tion in anticipatory behavior when the reward/punishment schedule was not contingent to behavior. An additional classical conditioning paradigm confirmed that reinforcement con- tingencies have to be operant to be effective and that they have a role in solving the credit assignment problem during aSPEM.},
	Projects = {anr-rem; pace-itn},
	Title = {Reinforcement contingencies modulate anticipatory smooth eye movements},
	Url = {http://invibe.net/LaurentPerrinet/Presentations/2016-11-03_gdr},
	Year = {2016},
	Bdsk-Url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2016-11-03_gdr}}

@inproceedings{2019-04-18_JNLF,
	Abstract = {Les illusions visuelles sont des cr{\'e}ations d'artistes, de scientifiques et plus r{\'e}cemment, gr{\^a}ce aux r{\'e}seaux sociaux, du grand public qui proposent des situations souvent incongrues, dans lesquelles l'eau remonte une cascade, les personnes volent dans les airs ou des serpents se mettent {\`a} tourner. Au-del{\`a} de leur ind{\'e}niable cot{\'e} ludique, ces illusions nous apprennent beaucoup sur le fonctionnement du cerveau, notamment quand celles-ci se transforment en hallucinations visuelles, d{\'e}passant ainsi les limites des capacit{\'e}s de notre perception. En tant que chercheur en Neurosciences {\`a} l'Institut de Neurosciences de la Timone {\`a} Marseille, je vous d{\'e}voilerai des aspects du fonctionnement du cerveau qui sont souvent m{\'e}connus. En particulier, nous verrons pourquoi un magicien peut tromper nos sens ou comment des objets peuvent voyager dans le temps. Surtout nous essaierons de comprendre le fonctionnement de notre perception visuelle sur les bases d'une th{\'e}orie de la vision non pas comme une simple cam{\'e}ra qui enregistre des images mais comme un processus actif en relation avec le monde qui nous entoure.},
	Author = {Perrinet, Laurent U},
	Booktitle = {JNLF 2019},
	Date-Modified = {2019-02-25 09:53:02 +0100},
	Event_Url = {https://www.jnlf.fr/agenda/jnlf-lille-2019},
	Location = {Lille, France},
	Note = {Summary: Mieux comprendre la fonction de la perception visuelle en explorant certaines limites; Mieux comprendre l'importance de l'aspect dynamique de la perception; Mieux comprendre le r{\^o}le de l'action dans la perception.},
	Projects = {anr-horizontal-v1},
	Time_Start = {2019-04-18T13:00:00},
	Title = {Des illusions aux hallucinations visuelles: une porte sur la perception},
	Url = {https://laurentperrinet.github.io/talk/2019-04-18_jnlf},
	Url_Code = {https://github.com/laurentperrinet/2019-01-14_LACONEU},
	Url_Slides = {https://laurentperrinet.github.io/2019-01-14_LACONEU},
	Year = {2019},
	Bdsk-Url-1 = {https://laurentperrinet.github.io/talk/2019-04-18_jnlf}}

@inproceedings{2019-01-14_LACONEU,
	Author = {Perrinet, Laurent U},
	Booktitle = {LACONEU 2019: 5th Latin-American Summer School in Computational Neuroscience},
	Date-Modified = {2019-02-25 22:52:33 +0100},
	Event_Url = {http://www.laconeu.cl},
	Location = {Valparaiso (Chile)},
	Projects = {anr-horizontal-v1},
	Time_Start = {2019-01-14T11:00:00},
	Title = {Modelling spiking neural networks using Brian, Nest and pyNN},
	Url = {http://invibe.net/LaurentPerrinet/Presentations/2019-01-14_LACONEU},
	Url_Code = {https://github.com/laurentperrinet/2019-01-14_LACONEU},
	Url_Slides = {https://laurentperrinet.github.io/2019-01-14_LACONEU},
	Year = {2019},
	Bdsk-Url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2019-01-14_LACONEU}}

@inproceedings{2011-07-02_NeuroMedTalk,
	Abstract = {Sensory informations such as visual images are inherently variable. We use probabilistic models to describe how the low-level visual system could describe superposed and ambiguous information. This allows to describe the interactions of neighboring populations of neurons as inference rules that dynamically build up the overall description of the visual scene. We focus here on temporal prediction, that is by the transport of information based on an estimate of local motion in the image.},
	Author = {Perrinet, Laurent U},
	Booktitle = {Atelier Neurosciences Computationnelles, 2-3 Juillet 2011 Khemisset, Maroc},
	Date-Modified = {2019-02-25 09:53:02 +0100},
	Keywords = {motion prediction, Bayesian model, dynamics, motion detection,motion prediction,eye movements},
	Note = {= * La finalit{\'e} de cette manifestation est de permettre {\`a} nos chercheurs de se r{\'e}unir en groupes de travail et en ateliers afin de d{\'e}couvrir la th{\'e}matique des neurosciences et son interdisciplinarit{\'e}. La manifestation se tient dans le cadre des activit{\'e}s du laboratoire LAMS, de ABC MATHINFO, du GDRI NeurO et du r{\'e}seau m{\'e}diterran{\'e}en [[http://www.neuromedproject.eu/|NeuroMed]]. ## * une manifestation sponsoris{\'e}e par le projet [[http://www.neuromedproject.eu/|NeuroMed]] * t{\'e}l{\'e}chargez la [[attachment:perrinet11khemisset.pdf|pr{\'e}sentation|&do=get]] (150 Mo with movies) * ou un [[Publications/Khoei10tauc|poster]] * en savoir plus : * sur la [[MotionPerception| perception du mouvement]] * sur la [[MotionParticles| solution particulaire]] ##||<width="50%"> attachment:sequence_DCBAline.gif||width=30%|| ##||<width="50%"> attachment:sequence_ABCDline.gif||width=30%|| ##|||| '''A predictive sequence is essential in resolving the aperture problem.''' ''(Top)'' In order to demonstrate that, I show in this sequence different apertures; for the aperture problem, motions are segregated (appear to be part of different objects) and still appear to be diagonal. ''(Right)'' However, if the same apertures are arranged in an order which is compatible with a predictive sequence, the horizontal motion appears as the most probable: prediction rotates the perception of the direction... ||},
	Title = {Propri{\'e}t{\'e}s {\'e}mergentes d'un mod{\`e}le de pr{\'e}diction probabiliste utilisant un champ neural},
	Url = {http://invibe.net/LaurentPerrinet/Presentations/2011-07-02_NeuroMedTalk},
	Year = {2011},
	Bdsk-Url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2011-07-02_NeuroMedTalk}}

@inproceedings{2017-01-20_LACONEU,
	Author = {Perrinet, Laurent U},
	Booktitle = {LACONEU 2017: 4th Latin-American Summer School in Computational Neuroscience},
	Date-Modified = {2019-02-25 23:10:19 +0100},
	Event_Url = {http://www.laconeu.cl},
	Location = {Valparaiso (Chile)},
	Projects = {anr-trajectory},
	Time_Start = {2017-01-20T10:45:00},
	Title = {Tutorial: Active inference for eye movements: Bayesian methods, neural inference, dynamics},
	Url = {http://invibe.net/LaurentPerrinet/Presentations/2017-01-20_LACONEU},
	Url_Slides = {https://laurentperrinet.github.io/sciblog/files/2017-01-20_LACONEU.html},
	Year = {2017},
	Bdsk-Url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2017-01-20_LACONEU}}

@inproceedings{2006-01-01_neurocomp,
	Abstract = {The quality of the representation of an object's motion is limited
by the noise in the sensory input as well as by an intrinsic ambiguity
due to the spatial limi- tation of the visual motion analyzers (aperture
prob- lem). Perceptual and oculomotor data demonstrate that motion
processing of extended ob jects is initially dominated by the local
1D motion cues orthogonal to the ob ject's edges, whereas 2D information
takes pro- gressively over and leads to the final correct represen-
tation of global motion. A Bayesian framework ac- counting for the
sensory noise and general expectancies for ob ject velocities has
proven successful in explaining several experimental findings concerning
early motion processing [1, 2, 3]. However, a complete functional
model, encompassing the dynamical evolution of ob- ject motion perception
is still lacking. Here we outline several experimental observations
concerning human smooth pursuit of moving ob jects and more particu-
larly the time course of its initiation phase. In addi- tion, we
propose a recursive extension of the Bayesian model, motivated and
constrained by our oculomotor data, to describe the dynamical integration
of 1D and 2D motion information.},
	Author = {Perrinet, Laurent U and Barth{\'e}lemy, Fr{\'e}d{\'e}ric V. and Masson, Guillaume S},
	Booktitle = {1{\`e}re conf{\'e}rence francophone NEUROsciences COMPutationnelles - NeuroComp},
	Date-Modified = {2019-02-25 09:53:36 +0100},
	Keywords = {Bayesian model, Temporal evolution., Aperture problem,Object motion, recursive inference, Smooth pursuit eye movement},
	Note = {## from . Follows [[Publications/Perrinet06fens]] . See also [[Publications/Perrinet07neurocomp]] and [[Publications/Perrinet08areadne]]},
	Rating = {5},
	Title = {Input-output transformation in the visuo-oculomotor loop: modeling the ocular following response to center-surround stimulation in a probabilistic framework},
	Topic = {edge},
	Url = {http://invibe.net/LaurentPerrinet/Presentations/2006_neurocomp},
	Year = {2006},
	Bdsk-Url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2006_neurocomp}}

@inproceedings{2010-12-17_TaucTalk,
	Abstract = {Sensory informations such as visual images are inherently variable. We use probabilistic models to describe how the low-level visual system could describe superposed and ambiguous information. This allows to describe the interactions of neighboring populations of neurons as inference rules that dynamically build up the overall description of the visual scene. We focus here on temporal prediction, that is by the transport of information based on an estimate of local motion in the image.},
	Author = {Perrinet, Laurent U},
	Booktitle = {LADISLAV TAUC & GDR MSPC NEUROSCIENCES CONFERENCE, From Mathematical Image Analysis to Neurogeometry of the Brain},
	Date-Modified = {2019-02-25 09:53:02 +0100},
	Keywords = {motion prediction, Bayesian model, dynamics,motion detection, motion detection,eye movements, center-surround interactions},
	Note = {= * http://www.conftauc.cnrs-gif.fr/programme.php * watch the [[attachment:perrinet10tauc.pdf|presentation|&do=get]] (150 Mo with movies) * see the accompanying [[Publications/Khoei10tauc|poster]] * see this more recent [[Presentations/2012-01-12_VisionAtUcl|talk]] * see more : * on MotionPerception * on MotionParticles ||<width="50%"> attachment:sequence_DCBAline.gif||width=100%||<width="50%"> attachment:sequence_ABCDline.gif||width=100%|| |||| '''A predictive sequence is essential in resolving the aperture problem.''' ''(Top)'' In order to demonstrate that, I show in this sequence different apertures; for the aperture problem, motions are segregated (appear to be part of different objects) and still appear to be diagonal. ''(Right)'' However, if the same apertures are arranged in an order which is compatible with a predictive sequence, the horizontal motion appears as the most probable: prediction rotates the perception of the direction... ||},
	Title = {Probabilistic models of the low-level visual system: the role of prediction in detecting motion},
	Url = {http://invibe.net/LaurentPerrinet/Presentations/2010-12-17_TaucTalk},
	Year = {2010},
	Bdsk-Url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2010-12-17_TaucTalk}}

@inproceedings{2019-01-16_LACONEU,
	Author = {Perrinet, Laurent U},
	Booktitle = {LACONEU 2019: 5th Latin-American Summer School in Computational Neuroscience},
	Date-Modified = {2019-02-25 22:52:33 +0100},
	Event_Url = {http://www.laconeu.cl},
	Location = {Valparaiso (Chile)},
	Projects = {anr-horizontal-v1},
	Time_Start = {2019-01-16T10:45:00},
	Title = {Efficient coding of visual information in neural computations},
	Url = {http://invibe.net/LaurentPerrinet/Presentations/2019-01-16_LACONEU},
	Url_Code = {https://github.com/laurentperrinet/2019-01-16_LACONEU/},
	Url_Slides = {https://laurentperrinet.github.io/2019-01-16_LACONEU/},
	Year = {2019},
	Bdsk-Url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2019-01-16_LACONEU}}

@inproceedings{2010-01-08_facets,
	Author = {Perrinet, Laurent U and Masson, Guillaume S},
	Date-Modified = {2019-02-25 09:53:36 +0100},
	Keywords = {motion prediction, Bayesian model, dynamics,motion detection, motion detection,eye movements, center-surround interactions},
	Note = {* see this more recent [[Presentations/2012-01-12_VisionAtUcl|talk]] * see more : * on MotionPerception * on MotionParticles * watch the [[attachment:perrinet10facets_talk.pdf|presentation|&do=get]]},
	Title = {Models of low-level vision: linking probabilistic models and neural masses},
	Url = {http://invibe.net/LaurentPerrinet/Presentations/2010-01-08_facets},
	Year = {2010},
	Bdsk-Url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2010-01-08_facets}}

@inproceedings{2007-12-01_rankprize,
	Author = {Perrinet, Laurent U},
	Booktitle = {The Rank Prize Funds, Mini-Symposium on Representations of the Visual World in the Brain},
	Date-Modified = {2019-02-25 09:53:02 +0100},
	Note = {* see SparseHebbianLearning * watch the [[attachment:perrinet07rankprize.pdf|presentation]]},
	Title = {What efficient code for adaptive spiking representations?},
	Url = {http://invibe.net/LaurentPerrinet/Presentations/2007-12_rankprize},
	Year = {2007},
	Bdsk-Url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2007-12_rankprize}}

@inproceedings{2009-11-30_vss,
	Abstract = {Short presentation of a large moving pattern elicits an ocular following response that exhibits many of the properties attributed to low-level motion processing such as spatial and temporal integration, contrast gain control and divisive interaction between competing motions. Similar mechanisms have been demonstrated in V1 cortical activity in response to center-surround gratings patterns measured with real-time optical imaging in awake monkeys (see poster of Reynaud et al., VSS09). Based on a previously developed Bayesian framework, we have developed an optimal statistical decoder of such an observed cortical population activity as recorded by optical imaging. This model aims at characterizing the statistical dependance between early neuronal activity and ocular responses and its performance was analyzed by comparing this neuronal read-out and the actual motor responses on a trial-by-trial basis. First, we show that relative performance of the behavioral contrast response function is similar to the best estimate obtained from the neural activity. In particular, we show that the latency of ocular response increases with low contrast conditions as well as with noisier instances of the behavioral task as decoded by the model. Then, we investigate the temporal dynamics of both neuronal and motor responses and show how motion information as represented by the model is integrated in space to improve population decoding over time. Lastly, we explore how a surrounding velocity non congruous with the central excitation information shunts the ocular response and how it is topographically represented in the cortical activity. Acknowledgement: European integrated project FACETS IST-15879.},
	Author = {Perrinet, Laurent U and Reynaud, Alexandre and Chavane, Fr{\'e}d{\'e}ric and Masson, Guillaume S},
	Booktitle = {Macroscopic aspects of neuronal activity: ''Macroscopic models, LFP models and VSD models'' a FACETS workshop in Marseille, Nov. 30th /Dec. 1st},
	Date-Modified = {2019-02-25 23:30:49 +0100},
	Note = {* see previous [[Publications/Perrinet09vss|poster]] <<EmbedObject(perrinet09vsd_talk.pdf,width=100%)>>},
	Projects = {facets},
	Title = {Reading out the dynamics of lateral interactions in the primary visual cortex from VSD data},
	Url = {http://invibe.net/LaurentPerrinet/Publications/Perrinet09vss},
	Year = {2009},
	Bdsk-Url-1 = {http://invibe.net/LaurentPerrinet/Publications/Perrinet09vss}}

@inproceedings{2013-11-26_BrainScalesDemos,
	Author = {Kaplan, Bernhard and Perrinet, Laurent U},
	Booktitle = {Demo 1-3: Apparent Motion in V1/ MT/MST: Neural Implementation of Probabilistic Approaches},
	Date-Modified = {2019-02-25 23:17:47 +0100},
	Note = {* Together with Bernhard Kaplan, we talked about how we aim at "compiling" a predictive motion-based approach as a spiking neural networks and then as a parallel wafer systems in the BrainscaleS project (Demo 1, Task4). * [[attachment:KaplanPerrinet13brainscales_talk.pdf|slides]] * (private to the consortium: [[https://brainscales.kip.uni-heidelberg.de/internal/jss/AttendMeeting?m=showMeetingInfoPage&meetingID=52|meeting info]] &[[https://brainscales.kip.uni-heidelberg.de/internal/jss/AttendMeeting?m=showAgenda&meetingID=52|Agenda]], including copies of the slides)},
	Projects = {brain-scales},
	Title = {Demo 1, Task4: Implementation of models showing emergence of cortical fields and maps},
	Url = {http://invibe.net/LaurentPerrinet/Presentations/2013-11-26_BrainScalesDemos},
	Year = {2013},
	Bdsk-Url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2013-11-26_BrainScalesDemos}}

@inproceedings{2012-01-27_FIL,
	Abstract = {Moving objects generate sensory information that may be noisy and ambiguous, yet it is important to be able to reconstruct object speed as fast as possible. One unsolved question is to understand how the brain pools motion information to give an efficient response. I will present computational models of motion detection in the visual system that try to answer this question. First, sensory information is grabbed by pooling the information from different sensory neurons. This pooling is modulated by the precision of information and we will present some recent model-based behavioural results. Then I will focus on a novel model of motion-based prediction that allows to track objects on smooth trajectories. This model gives an economical description of neural mechanisms associated with the processing underlying motion detection. Finally, we will propose an exploratory hypothesis such that eye movements may be understood as the prospective response to this dynamical sensory response knowing oculomotor constraints such as delays. This line of research aims at showing that through the convergent use of models, electrophysiology or behavioural responses, the study of motion detection is an essential tool in our understanding of neural computations.},
	Author = {Perrinet, Laurent U},
	Booktitle = {Brain meeting at FIL, London - Friday, January 27th, 2012},
	Date-Modified = {2019-02-25 23:17:47 +0100},
	Keywords = {Bayesian model, dynamics, motion detection,predictive coding,eye movements, free energy},
	Note = {= Time:: Jan 27, 2012, from 16:15 am to 17:00 pm Location:: Seminar room @ FIL, Queen's square, 4th floor.},
	Projects = {brain-scales},
	Title = {Grabbing, tracking and sniffing as models for motion detection and eye movements},
	Url = {Presentations/2012-01-27_FIL},
	Year = {2012},
	Bdsk-Url-1 = {Presentations/2012-01-27_FIL}}

@inproceedings{2018-02-01_BCP_INVIBE_fest,
	Author = {Perrinet, Laurent U and Pasturel, Chlo{\'e} and Montagnini, Anna},
	Booktitle = {Visual motion Fest - Invibe Team -- INT / Marseille February 1 & 2, 2018},
	Date-Modified = {2019-02-25 09:53:02 +0100},
	Note = {Quoi:: Visual motion Fest - Invibe Team -- INT / Marseille February 1 & 2, 2018 Quand:: 1/2/2018 O{\`u}:: INT Support visuel:: https://laurentperrinet.github.io/sciblog/files/2018-02-01_BCP_INVIBE_fest.html},
	Title = {Estimating and anticipating a dynamic probabilistic bias in visual motion direction},
	Url = {http://invibe.net/LaurentPerrinet/Presentations/2018-02-01_BCP_INVIBE_fest},
	Year = {2018},
	Bdsk-Url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2018-02-01_BCP_INVIBE_fest}}

@inproceedings{2009-04-01_INT,
	Abstract = {
Moving the eyes rapidly to track a visual object moving in a cluttered environment is an essential
function. However, doing so rapidly and efficiently is constrained by a number of noise sources in the
visual system and by the fact that information is collected locally before giving raise to a global signal.
After reviewing some results made in the modeling of low-level sensory areas, I will expose a method
to decode low-level neural information as describing visual information using a probabilistic
representation. Decisions will therefore correspond to statistical inferences which are dynamically
resolving the veridical speed of a moving object. We will illustrate this method by showing how
ambiguous local information can be merged to give raise to a global response which resolves the
aperture problem. Using this theoretical approach "in computo", we will illustrate how we may better
understand results which are observed "in vivo" (optical imaging) as a neural code linking actively
sensation and behavior.},
	Author = {Perrinet, Laurent U and Masson, Guillaume S},
	Date-Modified = {2019-02-25 23:30:49 +0100},
	Note = {* see more : * on MotionPerception * in [[Publications/Perrinet08areadne]] and [[Publications/Perrinet09cosyne]] * watch the [[attachment:perrinet09int.pdf|presentation|&do=get]] * LaTeX source code for the presentation: [[attachment:perrinet09int.tex||&do=get]], [[attachment:Context.tex||&do=get]], [[attachment:Motion.tex||&do=get]], [[attachment:Annex.tex||&do=get]] and glued by a [[attachment:Makefile||&do=get]]},
	Projects = {facets},
	Title = {Decoding low-level neural information to track visual motion},
	Url = {http://invibe.net/LaurentPerrinet/Presentations/09-04_INT},
	Year = {2009},
	Bdsk-Url-1 = {http://invibe.net/LaurentPerrinet/Presentations/09-04_INT}}

@inproceedings{2008-04-01_incm,
	Abstract = {Computational Neuroscience is a synthetic, inter-disciplinary approach aiming at
understanding cognition by analyzing the mechanisms underlying neural computations. We
present in this seminar our attempt in modeling low-level vision by bridging different
integration levels, from neural spiking activity to behavior. At the behavioral level, the Ocular
Following Response recorded in the laboratory reveals how the brain may integrate local
information (moving images on visual receptive fields) to produce a single behavioral
response (the movement of the eye). Using a probabilistic representation, we provide a
simple integrative mechanism that gives the ''ideal'' response to possibly noisy and
ambiguous information, similarly to a Bayesian approach. This fits well the performance
revealed by behavioral data and may act as a generic cortical ''module''. At the population
level, these mechanisms may indeed be implemented for the coding of natural images and
we will show the particular importance of spiking representations and lateral interactions for
efficient and rapid responses. In particular, we will present an original unsupervised learning
algorithm that we applied to a model of the primary visual cortex. Finally, at the neuronal
level, I will present work done in the team showing how certain mechanisms at the level of
the synapse and of the neuron are essential at the population level and how we may
understand these mechanisms at the population level. This illustrates the importance of
dynamical processes, distributed activity and recurrent connections to produce a cortical gain
control mechanism. As a conclusion, this approach provides useful applications for image
processing and possible valorization in future computer architectures. More generally, it
proves that the use of a probabilistic representation is a particularly efficient method for
bridging biological versus computational neuroscience and illustrates the advantage of such
an interdisciplinary approach.},
	Author = {Perrinet, Laurent U},
	Booktitle = {S{\'e}minaires de l'INCM, April 11th, 2008},
	Date-Modified = {2019-02-25 23:30:49 +0100},
	Projects = {facets},
	Title = {From neural activity to behavior: computational neuroscience as a synthetic approach for understanding the neural code.},
	Url = {http://invibe.net/LaurentPerrinet/Presentations/2008-04_incm},
	Year = {2008},
	Bdsk-Url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2008-04_incm}}

@inproceedings{2008-06-01_Ulm,
	Abstract = {The machinery behind the visual perception of motion and the subsequent
sensorimotor transformation, such as in Ocular Following Response (OFR),
is confronted to uncertainties which are efficiently resolved in the
primate's visual system. We may understand this response as an ideal
observer in a probabilistic framework by using Bayesian theory (Weiss et
al., 2002) which we previously proved to be successfully adapted to
model the OFR for different levels of noise with full field gratings or
with disk of various sizes and the effect of a flickering surround
(Perrinet and Masson, 2007).
More recent experiments of OFR have used disk gratings and bipartite
stimuli which are optimized to study the dynamics of center-surround
integration. We quantified two main characteristics of the global
spatial integration of motion from an intermediate map of possible local
translation velocities: (i) a finite optimal stimulus size for driving
OFR, surrounded by an antagonistic modulation and (ii) a direction
selective suppressive effect of the surround on the contrast gain
control of the central stimuli (Barthelemy et al., 2006, 2007).
Herein, we extended in the dynamical domain the ideal observer model to
simulate the spatial integration of the different local motion cues
within a probabilistic representation. We present analytical results
which show that the hypothesis of independence of local measures can
describe the initial segment of spatial integration of motion signal.
Within this framework, we successfully accounted for the dynamical
contrast gain control mechanisms observed in the behavioral data for
center-surround stimuli. However, another inhibitory mechanism had to be
added to account for suppressive effects of the surround. We explore
here an hypothesis where this could be understood as the effect of a
recurrent integration of information in the velocity map.

F. Barthelemy, L. U. Perrinet, E. Castet, and G. S. Masson. Dynamics of
distributed 1D and 2D motion representations for short-latency ocular
following. Vision Research, 48(4):501--22, feb 2007. doi:
10.1016/j.visres.2007.10.020.

F. V. Barthelemy, I. Vanzetta, and G. S. Masson. Behavioral receptive
field for ocular following in humans: Dynamics of spatial summation and
center-surround interactions. Journal of Neurophysiology,
(95):3712--26, Mar 2006. doi: 10.1152/jn.00112.2006.

L. U. Perrinet and G. S. Masson. Modeling spatial integration in the
ocular following response using a probabilistic framework. Journal of
Physiology (Paris), 2007. doi: 10.1016/j.jphysparis.2007.10.011.

Y. Weiss, E. P. Simoncelli, and E. H. Adelson. Motion illusions as
optimal percepts. Nature Neuroscience, 5(6):598--604, Jun 2002. doi:
10.1038/nn858.},
	Author = {Perrinet, Laurent U and Masson, Guillaume S},
	Date-Modified = {2019-02-25 23:30:49 +0100},
	Note = {* see more : * on MotionPerception * in [[Publications/Perrinet08areadne]] * watch the [[attachment:perrinet08ulm.pdf|presentation]]},
	Projects = {facets},
	Title = {Decoding the population dynamics underlying ocular following response using a probabilistic framework},
	Url = {http://invibe.net/LaurentPerrinet/Presentations/2008-06_Ulm},
	Year = {2008},
	Bdsk-Url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2008-06_Ulm}}

@inproceedings{2019-01-17_LACONEU,
	Author = {Perrinet, Laurent U},
	Booktitle = {LACONEU 2019: 5th Latin-American Summer School in Computational Neuroscience},
	Date-Modified = {2019-02-25 22:52:33 +0100},
	Event_Url = {http://www.laconeu.cl},
	Location = {Valparaiso (Chile)},
	Projects = {anr-horizontal-v1},
	Time_Start = {2019-01-17T10:45:00},
	Title = {Role of dynamics in neural computations underlying visual processing},
	Url = {http://invibe.net/LaurentPerrinet/Presentations/2019-01-17_LACONEU},
	Url_Code = {https://github.com/laurentperrinet/2019-01-17_LACONEU/},
	Url_Slides = {https://laurentperrinet.github.io/2019-01-17_LACONEU/},
	Year = {2019},
	Bdsk-Url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2019-01-17_LACONEU}}

@inproceedings{2018-04-05_ActiveInference,
	Author = {Perrinet, Laurent U and Pasturel, Chlo{\'e} and Anna Montagnini, INT},
	Booktitle = {Probabilities and Optimal Inference to Understand the Brain, INT, Marseille (France)},
	Date-Modified = {2019-02-25 23:35:53 +0100},
	Note = {Quoi:: [[https://opt-infer-brain.sciencesconf.org/|Probabilities and Optimal Inference to Understand the Brain]] Qui:: Laurent Perrinet and Chlo{\'e} Pasturel and Anna Montagnini, INT Quand:: 5/4/2018 O{\`u}:: INT, Marseille (France) Support visuel:: https://laurentperrinet.github.io/sciblog/files/2018-04-05_BCP_talk.html},
	Projects = {pace-itn},
	Title = {Principles and psychophysics of Active Inference},
	Url = {http://invibe.net/LaurentPerrinet/Presentations/2018-04-05_ActiveInference},
	Year = {2018},
	Bdsk-Url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2018-04-05_ActiveInference}}

@inproceedings{2007-09-01_mipm,
	Abstract = {I will illustrate in this talk how computational neuroscience may inspire and be inspired by mathematical image processing. Focusing on efficiently representing natural images in the primary visual cortex, we derive an event-based adaptive algorithm inspired by statistical inference, Matching Pursuit and Hebbian learning. This algorithm allows to learn efficient "edge-like" receptive fields similarly to Independent Components Analysis. The correlation-based inhibition has been shown to be a necessary condition for the fomation of this type of receptive fields and shows the putative functional role of lateral propagation of information in cortical layers. I'll first present state-of-the-art neural algorithms for this task, the results of a detailed analysis of this Sparse Hebbian Learning algorithm and finally draw a comparison with similar strategies.},
	Author = {Perrinet, Laurent U},
	Booktitle = {Mathematical image processing meeting (Marseille, France) September 5},
	Date-Added = {2007-10-29 16:22:21 +0100},
	Date-Modified = {2019-02-25 09:53:02 +0100},
	Note = {* [[http://www.math.univ-paris13.fr/~malgouy/MIPM/Abstracts.html#Perrinet|advertisement]]},
	Title = {Neural Codes for Adaptive Sparse Representations of Natural Images},
	Url = {http://invibe.net/LaurentPerrinet/Presentations/2007-09_mipm},
	Year = {2007},
	Bdsk-Url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2007-09_mipm}}

@inproceedings{2017-01-19_LACONEU,
	Author = {Perrinet, Laurent U},
	Booktitle = {LACONEU 2017: 4th Latin-American Summer School in Computational Neuroscience},
	Date-Modified = {2019-02-25 23:10:19 +0100},
	Event_Url = {http://www.laconeu.cl},
	Keywords = {Biologically Inspired Computer vision},
	Location = {Valparaiso (Chile)},
	Projects = {anr-trajectory},
	Time_Start = {2017-01-19T10:45:00},
	Title = {Tutorial: Sparse optimization in neural computations},
	Url = {http://invibe.net/LaurentPerrinet/Presentations/2017-01-19_LACONEU},
	Url_Slides = {https://laurentperrinet.github.io/sciblog/files/2017-01-19_LACONEU.html},
	Year = {2017},
	Bdsk-Url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2017-01-19_LACONEU}}

@inproceedings{2017-01-18_LACONEU,
	Author = {Perrinet, Laurent U},
	Booktitle = {Workshop on Computational Neuroscience "New trends and challenges for 2030"},
	Date-Modified = {2019-02-25 23:10:19 +0100},
	Event_Url = {http://cinv.uv.cl/laconeu-workshop},
	Location = {Valparaiso (Chile)},
	Note = {http://laconeu.cl/wp-content/uploads/2018/04/Valparaiso-3.jpg},
	Projects = {anr-trajectory},
	Time_Start = {2017-01-18T09:00:00},
	Title = {Back to the present: how neurons deal with delays},
	Url = {http://invibe.net/LaurentPerrinet/Presentations/2017-01-18_LACONEU},
	Url_Slides = {https://laurentperrinet.github.io/sciblog/files/2017-01-18_LACONEU.html},
	Year = {2017},
	Bdsk-Url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2017-01-18_LACONEU}}

@inproceedings{2009-07-18_Kremkow09cnstalk,
	Author = {Kremkow, Jens and Perrinet, Laurent U and Monier, Cyril and Fregnac, Yves and Masson, Guillaume S and Aertsen, Ad},
	Booktitle = {Eighteenth Annual Computational Neuroscience Meeting: CNS*2009 Berlin, Germany. 18--23 July 2009},
	Date-Modified = {2019-02-25 23:30:49 +0100},
	Doi = {doi:10.1186/1471-2202-10-S1-O21},
	Note = {## from},
	Pages = {Oral presentation, 10(Suppl 1):O21},
	Projects = {facets},
	Title = {Control of the temporal interplay between excitation and inhibition by the statistics of visual input},
	Url = {http://invibe.net/LaurentPerrinet/Publications/Kremkow09cnstalk},
	Year = {2009},
	Bdsk-Url-1 = {http://invibe.net/LaurentPerrinet/Publications/Kremkow09cnstalk},
	Bdsk-Url-2 = {https://doi.org/10.1186/1471-2202-10-S1-O21}}

@inproceedings{2008-02-01_toledo,
	Author = {Perrinet, Laurent U},
	Booktitle = {Prisma workshop, Toledo (Spain), February 7, 2008},
	Date-Modified = {2019-02-25 09:53:02 +0100},
	Note = {* see [[Publications/Perrinet08spie]] * get the [[attachment:perrinet08toledo.pdf|presentation (8.8 Mo)]]},
	Title = {Modeling of spikes, sparseness and adaptation in the primary visual cortex: applications to imaging},
	Url = {http://invibe.net/LaurentPerrinet/Presentations/2008-02_toledo},
	Year = {2008},
	Bdsk-Url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2008-02_toledo}}

@inproceedings{2013-03-21_Marseille,
	Abstract = {This session aims at presenting new ideas that emerged during the first years of BrainScaleS. Indeed,
the collaborations that were initiated within the consortium led to the creation of novel tools as
planned in the proposal but also some of which were unforeseen, like the Motion Clouds that we
presented previously. We present here some prototypical and inspiring examples of such
collaborative work on: 1) tool chains from experimental (Davison), computational (Antolik) or integrative (Petrovici)
perspectives, 2) original methods inspired by novel types of analysis for propagating waves (Schmidt, Muller) or by
novel magnetrodes (Pannetier Lecoeur).},
	Author = {Perrinet, Laurent U},
	Booktitle = {3rd BrainScaleS Plenary Meeting - Friday, March 21st, 2013},
	Date-Modified = {2019-02-25 23:17:47 +0100},
	Note = {= Time:: March 21st, 2013 Location:: INT, Marseille.},
	Projects = {brain-scales},
	Title = {Why methods and tools are the key to artificial brain-like systems},
	Url = {http://invibe.net/LaurentPerrinet/Presentations/2013-03-21_Marseille},
	Year = {2013},
	Bdsk-Url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2013-03-21_Marseille}}

@inproceedings{2012-05-10_itwist,
	Abstract = {Oriented edges in images of natural scenes tend to be aligned in collinear or co-circular arrangements, with lines and smooth curves more common than other possible arrangements of edges (Geisler et al., Vis Res 41:711-24, 2001). The visual system appears to take advantage of this prior information, and human contour detection and grouping performance is well predicted by such an "association field" (Field et al., Vis Res 33:173-93, 1993). One possible candidate substrate for implementing an association field in mammals is the set of long-range lateral connections between neurons in the primary visual cortex (V1), which could act to facilitate detection of contours matching the association field, and/or inhibit detection of other contours (Choe and Miikkulainen, Biol Cyb 90:75-88, 2004). To fill this role, the lateral connections would need to be orientation specific and aligned along contours, and indeed such an arrangement has been found in tree shrew primary visual cortex (Bosking et al., J Neurosci 17:2112-27, 1997). However, it is not yet known whether these patterns develop as a result of visual experience, or are simply hard-wired to be appropriate for the statistics of natural scenes. To investigate this issue, we examined the properties of the visual environment of laboratory animals, to determine whether the observed connection patterns are more similar to the statistics of the rearing environment or of a natural habitat. Specifically, we analyzed the cooccurence statistics of edge elements in images of natural scenes, and compared them to corresponding statistics for images taken from within the rearing environment of the animals in the Bosking et al. (1997) study. We used a modified version of the algorithm from Geisler et al. (2001), with a more general edge extraction algorithm that uses sparse coding to avoid multiple responses to a single edge. Collinearity and co-circularity results for natural images replicated qualitatively the results from Geisler et al. (2001), confirming that prior information about continuations appeared consistently in natural images. However, we find that the largely man-made environment in which these animals were reared has a significantly higher probability of collinear edge elements. We thus predict that if the lateral connection patterns are due to visual experience, the patterns in wild-raised tree shrews would be very different from those measured by Bosking et al. (1997), with shorter-range correlations and less emphasis on collinear continuations. This prediction can be tested in future experiments on matching groups of animals reared in different environments.},
	Author = {Perrinet, Laurent U and Fitzpatrick, David and Bednar, James A.},
	Booktitle = {iTWIST '12 workshop},
	Date-Modified = {2019-02-25 10:33:10 +0100},
	Event_Url = {https://sites.google.com/site/itwist1st/home},
	Keywords = {sparse coding},
	Time_Start = {2012-05-10-18T13:00:00},
	Title = {Edge statistics in natural images versus laboratory animal environments: implications for understanding lateral connectivity in V1},
	Url = {https://laurentperrinet.github.io/talk/2012-05-10-itwist/},
	Url_Slides = {http://invibe.net/LaurentPerrinet/Presentations/2012-05-10?action=AttachFile&do=get&target=Perrinet12itwist.pdf},
	Year = {2012},
	Bdsk-Url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2012-05-10_itwist}}

@inproceedings{2012-01-24_Edinburgh,
	Abstract = {Oriented edges in images of natural scenes tend to be aligned in collinear or co-circular arrangements, with lines and smooth curves more common than other possible arrangements of edges (Geisler et al., Vis Res 41:711-24, 2001). The visual system appears to take advantage of this prior information, and human contour detection and grouping performance is well predicted by such an "association field" (Field et al., Vis Res 33:173-93, 1993). One possible candidate substrate for implementing an association field in mammals is the set of long-range lateral connections between neurons in the primary visual cortex (V1), which could act to facilitate detection of contours matching the association field, and/or inhibit detection of other contours (Choe and Miikkulainen, Biol Cyb 90:75-88, 2004). To fill this role, the lateral connections would need to be orientation specific and aligned along contours, and indeed such an arrangement has been found in tree shrew primary visual cortex (Bosking et al., J Neurosci 17:2112-27, 1997). However, it is not yet known whether these patterns develop as a result of visual experience, or are simply hard-wired to be appropriate for the statistics of natural scenes. To investigate this issue, we examined the properties of the visual environment of laboratory animals, to determine whether the observed connection patterns are more similar to the statistics of the rearing environment or of a natural habitat. Specifically, we analyzed the cooccurence statistics of edge elements in images of natural scenes, and compared them to corresponding statistics for images taken from within the rearing environment of the animals in the Bosking et al. (1997) study. We used a modified version of the algorithm from Geisler et al. (2001), with a more general edge extraction algorithm that uses sparse coding to avoid multiple responses to a single edge. Collinearity and co-circularity results for natural images replicated qualitatively the results from Geisler et al. (2001), confirming that prior information about continuations appeared consistently in natural images. However, we find that the largely man-made environment in which these animals were reared has a significantly higher probability of collinear edge elements. We thus predict that if the lateral connection patterns are due to visual experience, the patterns in wild-raised tree shrews would be very different from those measured by Bosking et al. (1997), with shorter-range correlations and less emphasis on collinear continuations. This prediction can be tested in future experiments on matching groups of animals reared in different environments.},
	Author = {Perrinet, Laurent U and Fitzpatrick, David and Bednar, James A.},
	Booktitle = {A seminar from the Institute for Adaptive and Neural Computation (ANC)},
	Date-Modified = {2019-02-25 23:17:47 +0100},
	Event_Url = {http://www.anc.ed.ac.uk/events/anc-dtc-seminar-laurent-perrinet},
	Location = {IF 4.31/4.33, Institute for Adaptive and Neural Computation (ANC) @ The University of Edinburgh},
	Projects = {brain-scales},
	Time_Start = {2012-01-24T13:00:00},
	Title = {Edge statistics in natural images versus laboratory animal environments: implications for understanding lateral connectivity in V1},
	Url = {http://invibe.net/cgi-bin/index.cgi/Presentations/2012-01-24_Edinburgh},
	Year = {2012},
	Bdsk-Url-1 = {http://invibe.net/cgi-bin/index.cgi/Presentations/2012-01-24_Edinburgh}}

@inproceedings{2011-09-28_ermites,
	Abstract = {Oriented edges in images of natural scenes tend to be aligned in collinear or co-circular arrangements, with lines and smooth curves more common than other possible arrangements of edges (Geisler et al., Vis Res 41:711-24, 2001). The visual system appears to take advantage of this prior information, and human contour detection and grouping performance is well predicted by such an "association field" (Field et al., Vis Res 33:173-93, 1993). One possible candidate substrate for implementing an association field in mammals is the set of long-range lateral connections between neurons in the primary visual cortex (V1), which could act to facilitate detection of contours matching the association field, and/or inhibit detection of other contours (Choe and Miikkulainen, Biol Cyb 90:75-88, 2004). To fill this role, the lateral connections would need to be orientation specific and aligned along contours, and indeed such an arrangement has been found in tree shrew primary visual cortex (Bosking et al., J Neurosci 17:2112-27, 1997). However, it is not yet known whether these patterns develop as a result of visual experience, or are simply hard-wired to be appropriate for the statistics of natural scenes. To investigate this issue, we examined the properties of the visual environment of laboratory animals, to determine whether the observed connection patterns are more similar to the statistics of the rearing environment or of a natural habitat. Specifically, we analyzed the cooccurence statistics of edge elements in images of natural scenes, and compared them to corresponding statistics for images taken from within the rearing environment of the animals in the Bosking et al. (1997) study. We used a modified version of the algorithm from Geisler et al. (2001), with a more general edge extraction algorithm that uses sparse coding to avoid multiple responses to a single edge. Collinearity and co-circularity results for natural images replicated qualitatively the results from Geisler et al. (2001), confirming that prior information about continuations appeared consistently in natural images. However, we find that the largely man-made environment in which these animals were reared has a significantly higher probability of collinear edge elements. We thus predict that if the lateral connection patterns are due to visual experience, the patterns in wild-raised tree shrews would be very different from those measured by Bosking et al. (1997), with shorter-range correlations and less emphasis on collinear continuations. This prediction can be tested in future experiments on matching groups of animals reared in different environments.},
	Author = {Perrinet, Laurent U and Fitzpatrick, David and Bednar, James A.},
	Booktitle = {Proceedings of SfN, 2011},
	Date-Modified = {2019-02-25 23:17:47 +0100},
	Event_Url = {http://glotin.univ-tln.fr/ERMITES11/index.xhtml},
	Keywords = {sparse coding},
	Location = {Porquerolles la Perle des Iles d'Or - Var (France)},
	Projects = {brain-scales},
	Time_Start = {2011-09-28T13:00:00},
	Title = {Edge statistics in natural images versus laboratory animal environments: implications for understanding lateral connectivity in V1},
	Url = {http://invibe.net/LaurentPerrinet/Presentations/2011-09-28_ermites},
	Year = {2011},
	Bdsk-Url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2011-09-28_ermites}}

@inproceedings{2011-11-15_sfn,
	Abstract = {Oriented edges in images of natural scenes tend to be aligned in collinear or co-circular arrangements, with lines and smooth curves more common than other possible arrangements of edges (Geisler et al., Vis Res 41:711-24, 2001). The visual system appears to take advantage of this prior information, and human contour detection and grouping performance is well predicted by such an "association field" (Field et al., Vis Res 33:173-93, 1993). One possible candidate substrate for implementing an association field in mammals is the set of long-range lateral connections between neurons in the primary visual cortex (V1), which could act to facilitate detection of contours matching the association field, and/or inhibit detection of other contours (Choe and Miikkulainen, Biol Cyb 90:75-88, 2004). To fill this role, the lateral connections would need to be orientation specific and aligned along contours, and indeed such an arrangement has been found in tree shrew primary visual cortex (Bosking et al., J Neurosci 17:2112-27, 1997). However, it is not yet known whether these patterns develop as a result of visual experience, or are simply hard-wired to be appropriate for the statistics of natural scenes. To investigate this issue, we examined the properties of the visual environment of laboratory animals, to determine whether the observed connection patterns are more similar to the statistics of the rearing environment or of a natural habitat. Specifically, we analyzed the cooccurence statistics of edge elements in images of natural scenes, and compared them to corresponding statistics for images taken from within the rearing environment of the animals in the Bosking et al. (1997) study. We used a modified version of the algorithm from Geisler et al. (2001), with a more general edge extraction algorithm that uses sparse coding to avoid multiple responses to a single edge. Collinearity and co-circularity results for natural images replicated qualitatively the results from Geisler et al. (2001), confirming that prior information about continuations appeared consistently in natural images. However, we find that the largely man-made environment in which these animals were reared has a significantly higher probability of collinear edge elements. We thus predict that if the lateral connection patterns are due to visual experience, the patterns in wild-raised tree shrews would be very different from those measured by Bosking et al. (1997), with shorter-range correlations and less emphasis on collinear continuations. This prediction can be tested in future experiments on matching groups of animals reared in different environments.},
	Author = {Perrinet, Laurent U and Fitzpatrick, David and Bednar, James A.},
	Booktitle = {Society for Neuroscience Abstracts},
	Date-Modified = {2019-02-25 09:53:02 +0100},
	Editor = {Society for Neuroscience, www.sfn.org},
	Location = {Washington, DC},
	Note = {Abstract Control Number: 17671 * Presentation Number: 530.04 * Presentation Time: 8:45am - 9:00am * session: * Session Type: Nanosymposium * Session Number: 530 * Session Title: Development of Motor and Sensory Systems},
	Number = {Program No. 530.04},
	Time_Start = {2011-11-15T08:45:00},
	Title = {Edge statistics in natural images versus laboratory animal environments: implications for understanding lateral connectivity in V1},
	Url = {http://invibe.net/LaurentPerrinet/Presentations/2011-11-15_sfn},
	Year = {2011},
	Bdsk-Url-1 = {http://invibe.net/LaurentPerrinet/Presentations/2011-11-15_sfn}}
